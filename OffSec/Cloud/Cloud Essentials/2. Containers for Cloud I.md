Containers are the backbone of many modern technologies, and have significantly changed the way applications and tools are developed and used. To work with solutions such as Docker and Kubernetes, we must understand how containerization technology works.

Containerization is often compared with virtualization, a comparison that often causes more confusion. Containerization is not meant to replace virtualization; in fact, it enhances already virtualized deployments.

In a more traditional architecture, a business would run all necessary applications directly on bare metal. To scale, this means a system administrator would need to buy and install a new server.

Virtualization revolutionizes this process by allowing a single robust server to be split into multiple virtualized servers. With virtualization, _hypervisors_[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1391-1) virtualize components including the CPU, GPU, and RAM, and assign the virtualized hardware to _virtual machines_ (VMs). This means that the bare-metal hardware is shared among the VMs, but the kernel, operating system, and applications run separately. While the VMs share a physical server, each runs independently from the rest.

While virtualization doesn't eliminate the need for bare-metal servers, it adds a layer of abstraction so that servers can be spun up much more quickly while still maintaining the security separation of bare-metal servers. Because virtualization significantly reduces the cost of adding new servers, more organizations can separate their applications between individual servers. A web application might run on one server, for example, and the database on another.

Although virtualization lowers the cost of running a server, each VM still needs to run its own kernel and operating system. This adds significant overhead when running many virtual machines.

Next, let's explore containerization, an even _more_ modern architecture. Using containerization, multiple containers share the hardware (as in virtualization), but they _also_ share the kernel. The hardware is not virtualized with containerization; instead, the kernel creates boundaries between the network, process, filesystem, and more. This results in much faster spin-up time, smaller images, and more efficient resource use. While containerization still maintains some security segmentation, it won't ever be as strong as that of virtualization, and especially not as much as bare-metal architecture.

Since the cost of running additional containers is negligible, however, organizations are further able to separate an application. For example, it was typical with VMs to have an application server and a separate database server. Using containers, individual components of the application could be split up, such as separating the search engine functionality from the login functionality.

This segmentation also means that each container only needs to include the dependencies required to run. This is different from bare-metal and virtualized servers, where it's common for components such as python, wget, ifconfig, etc. to be included in every server. Alternatively, for containers only running PHP applications, there is no reason to include the other tools. This allows for images to be saved and shared between development team members that always use the same dependencies.

As we'll find, containers are not a single technology that was developed. Instead, they are the result of a culmination of multiple Linux primitives that were made easier to use by tools like Docker. In this Topic, when we mention "container", we are specifically referencing _Open Container Initiative_ (OCI)[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1391-2) containers. While other types of containers exist, for the sake of simplification, we will only discuss OCI containers.

In this Topic, we will cover the following Learning Units:

- Containers, The Easy Way
- Container Images

Each learner moves at their own pace, but this Topic should take approximately 5 hours to complete.

1

(Wikipedia, 2022), [https://en.wikipedia.org/wiki/Hypervisor](https://en.wikipedia.org/wiki/Hypervisor) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1391-1)

2

(OCI, 2022), [https://opencontainers.org/](https://opencontainers.org/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1391-2)

## 2.1. Containers, The Easy Way

In this Learning Unit, we'll explore how to start, stop, and use containers. Containers use a template called an _image_, which specifies the files within the container. We can think of the image as if it were the hard drive of a computer. We will not learn how to build images. Instead, we will be using pre-built ones.

Modern containerization is often synonymous with _Docker_, and for good reason. Docker has abstracted the containerization process so that it's relatively simple to start a container. This abstraction, however, has caused much confusion since multiple components, specifications, and technologies have been branded "Docker".

This Learning Unit covers the following Learning Objectives:

- Understand how to access the lab
- Interact with Docker to start and stop containers
- Interact with Podman to start and stop containers
- Understand the ecosystem of running containers

This Learning Unit will take approximately 2.5 hours to complete.

## 2.1.1. Accessing the Lab

In this Topic, we'll use a single server to learn about containers named _containers_. This is a bare-bones Ubuntu machine with Docker[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1393-1) and Podman[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1393-2) installed using default settings.

To access the server, we have created an **/etc/hosts** file entry on our Kali Linux VM.

```
kali@kali:~$ sudo mousepad /etc/hosts

kali@kali:~$ cat /etc/hosts
127.0.0.1       localhost
127.0.1.1       kali

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

192.168.121.131  containers
```

> Listing 1 - /etc/hosts entry

For now, we'll simply set up our **hosts** file on our Kali machine and start the virtual machine.

1

(Docker Inc, 2022), [https://www.docker.com/](https://www.docker.com/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1393-1)

2

(Podman, 2022), [https://podman.io/](https://podman.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1393-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

containers

## 2.1.2. Docker

Docker is one of the first tools that comes to mind when discussing containers. In this section, we'll start by running a CentOS container and interacting with it as if we were to SSH into a CentOS host. We'll explore several of the common flags used to interact with Docker containers. We'll also start an Apache container, mount a volume for the web root, and run the container on the host network. We'll then cover some drawbacks and shortcomings of Docker.

Let's start by connecting to the host via SSH.

```
student@kali:~$ ssh student@containers
student@containers's password: 
Welcome to Ubuntu 22.04 LTS (GNU/Linux 5.15.0-27-generic x86_64)
....

student@container:~$ 
```

> Listing 2 - Connecting to containers host via SSH

Although the host is running Ubuntu, we'll be starting a container from a different distribution. While different Linux distributions all use the Linux kernel, there can be different kernel versions between distributions. CentOS in a VM runs an older kernel version by default, while Kali runs a newer kernel version. Different distributions might also have different kernel features enabled or disabled by default.

Despite the differences in kernel versions, when a Linux operating system is put into an OCI container, whichever kernel is loaded by the underlying operating system that is running the OCI container is used. Other types of non-OCI containers may handle this differently. By running multiple distributions on the same kernel, we'll show that container features are indeed a Linux concept.

We'll use the **docker** binary to start the container. Let's run it using the **--help** option.

```
student@container:~$ docker --help

Usage:  docker [OPTIONS] COMMAND

A self-sufficient runtime for containers
...

Management Commands:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Manage builds
  buildx*     Docker Buildx (Docker Inc., v0.8.0-docker)
  config      Manage Docker configs
  container   Manage containers
  context     Manage contexts
  image       Manage images
...

Commands:
...
  rmi         Remove one or more images
  run         Run a command in a new container
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
...
```

> Listing 3 - Docker Help Page

Since we're starting a container, we'll use the **container** management command. If we were, for example, creating an image, we would use the **image** management command. Since we want to start a new container, we'll use the **run** command. Let's run this using **--help** to collect more information.

```
student@container:~$ docker container run --help

Usage:  docker container run [OPTIONS] IMAGE [COMMAND] [ARG...]

Run a command in a new container

Options:
...
      --init                           Run an init inside the container that forwards signals and reaps processes
  -i, --interactive                    Keep STDIN open even if not attached
      --ip string                      IPv4 address (e.g., 172.30.100.104)
...
      --rm                             Automatically remove the container when it exits
      --runtime string                 Runtime to use for this container
      --security-opt list              Security Options
      --shm-size bytes                 Size of /dev/shm
      --sig-proxy                      Proxy received signals to the process (default true)
      --stop-signal string             Signal to stop a container (default "SIGTERM")
      --stop-timeout int               Timeout (in seconds) to stop a container
      --storage-opt list               Storage driver options for the container
      --sysctl map                     Sysctl options (default map[])
      --tmpfs list                     Mount a tmpfs directory
  -t, --tty                            Allocate a pseudo-TTY
...
```

> Listing 4 - Help Page for docker container run

The help menu shows that we need to provide some options, including an image, command, and arguments. We'll be using CentOS 7 for this demo, meaning that the image will be **centos**[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1394-1) and the tag will be **7**. We can combine the image and tag into **centos:7**. Tags are often used to obtain different versions of the same image. While running an OS image, a tag could also be used to specify the version of an application. Almost all images have a "latest" tag pointing to the most recent build.

Next, let's use the **--interactive** flag to send commands into the container. We'll also use **--tty** to mimic a terminal for further interaction with the container. By default, Docker containers are designed to run in the background for applications like httpd (Apache) or nginx. However, we're using these two flags for a more interactive experience.

We'll also use the **--rm** flag to delete the container after we exit. Containers have a multi-stage lifecycle. Since the concept of "being powered on/off" is at the kernel level, containers do not truly power on and off. However, they can be started and stopped. When a container is exited, it is not deleted, which might cause issues with clutter. If we simply want a quick container to show a proof-of-concept, we will remove the container after we exit.

Finally, we need a command to run in the container. Since we want an interactive shell, we'll run **/bin/bash**.

Let's put this all together and start the container.

```
student@container:~$ docker container run --interactive --tty --rm centos:7 /bin/bash

[root@720eba0d9d9f /]# cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
...

[root@720eba0d9d9f /]# uname -a
Linux 720eba0d9d9f 5.15.0-27-generic #28-Ubuntu SMP Thu Apr 14 04:55:28 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

[root@720eba0d9d9f /]# exit
exit
```

> Listing 5 - Starting the CentOS container

When Docker starts a new container, the container is assigned an ID comprised of a SHA256 hash of its configuration. This hash is used throughout the container. The first 12 characters are used as the hostname, _720eba0d9d9f_ in this case.

Reviewing the contents of **/etc/os-release**, we'll find that we are currently running CentOS 7. However, after examining the uname output, we find that we are running an Ubuntu version of Linux. This is because the kernel is shared between the host and the container.

The Linux kernel is designed to be backwards-compatible, meaning operating systems that expect a very old kernel will still work. For example, we can still run CentOS 5, last released in 2017, using the newer kernel. We'll run CentOS 5 by replacing the tag with **5**.

We can also shorten our command and start the container by skipping the **container** management command. The **run** command is used often enough that Docker created a shortcut. We can further shorten it by replacing **--interactive** and **--tty** with the shortened version, **-it**.

```
student@container:~$ docker run -it --rm centos:5 bash

[root@4d52ca6973cb /]# rpm --query centos-release
centos-release-5-11.el5.centos

[root@4d52ca6973cb /]# uname -a
Linux 4d52ca6973cb 5.15.0-27-generic #28-Ubuntu SMP Thu Apr 14 04:55:28 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

[root@4d52ca6973cb /]# exit
exit
```

> Listing 6 - Running CentOS 5

Although CentOS 5 was released with kernel 2.6.18, it still runs using kernel 5.15.0 and newer.

Another interesting aspect of containers is that the process list is restarted, which means that the initial command runs as the first process. Let's start a new container and run **ps** to list the running processes.

```
student@container:/home/student$ docker container run --interactive --tty --rm centos:7 /bin/bash

[root@6715e0e7d4b0 /]# ps
    PID TTY          TIME CMD
      1 pts/0    00:00:00 bash
     15 pts/0    00:00:00 ps

[root@6715e0e7d4b0 /]# exit
```

> Listing 7 - Running ps in a Docker Container

The bash shell is running as the first process. This is unlike a virtual machine, for which the OS might have to start hundreds of processes. We'll cover these differences in more detail later.

While we might use an interactive TTY shell to debug or try a container out, in the real-world we usually use Docker containers to run a service like httpd (Apache). The httpd service creates an HTTP server on port 80 and serves HTML files. The **/usr/local/apache2/htdocs/** directory on the container is the web root.

Since we don't need to interact with Apache, we'll remove the **-it** option, replacing it with **-d** (or **--detach**) to run the container in the background.

The httpd container exposes port 80 to serve the HTML files. For this port to be accessible on our host, we'll need to map it using the **-p** (or **--publish**) option. This option creates routing rules that map a port on the host to the container and a specific port. We'll map port 80 on the container to port 8080 on the host by providing the argument **8080:80**.

![[OffSec/Cloud/Cloud Essentials/z. images/818cf17cfe259c3376c2af8140fc9c68_MD5.jpg]]

Figure 1: Mapping 8080 on Host to 80 on Container

Once the container starts, we'll use **curl** to verify that it's running.

```
student@container:~$ docker container run -d --rm -p 8080:80 httpd
e277a2fefb2c60181a5376534e645851bfd3d38ac123cee12d357925b6149a2a

student@container:~$ curl localhost:8080
<html><body><h1>It works!</h1></body></html>
```

> Listing 8 - Running a httpd Container

When we run the container, we receive the container ID instead of a shell. When we curl port 8080, we find that the HTTP service is running and returns an "It Works!" message.

However, this isn't very useful if we're hosting a generic web page. Let's explore how to mount a directory and replace the web root with something we control.

First, however, we'll need to stop the running container. Let's start by listing all the running containers using the **ls** command.

```
student@container:~$ docker container ls
CONTAINER ID   IMAGE     COMMAND              CREATED          STATUS          PORTS                                   NAMES
899bced9cb16   httpd     "httpd-foreground"   43 seconds ago   Up 42 seconds   0.0.0.0:8080->80/tcp, :::8080->80/tcp   condescending_vaughan
```

> Listing 9 - Listing Docker Containers

We often need to get a shell into a Docker container running in the background to debug an issue. We can do this by executing a new process that can start a shell for us, like **/bin/bash**. We'll use the **exec** command to do this, and once again specify the **-it** argument to create an interactive shell. Finally, we'll have to specify the Docker ID. However, the full Docker ID doesn't have to be provided; we only need to provide enough to identify the container. In this case, that could be as short as "8" or as long as the full ID. Let's use "899".

```
student@container:/home/student$ docker exec -it 899 /bin/bash

root@899bced9cb16:/usr/local/apache2# echo $$
119

root@899bced9cb16:/usr/local/apache2# exit
exit
```

> Listing 10 - Executing /bin/bash in Docker container

By running **echo $$**, we can retrieve the process ID of our bash shell (119 in this case). This is because Docker is executing a new process, /bin/bash, in the existing container. It is not starting a new container, nor are we using something like ssh to connect to the container.

We'll use the **stop** command to stop the container. Because we started this container with the **--rm** option, stopping the container will also delete it.

```
student@container:~$ docker container stop 899
899
```

> Listing 11 - Stopping the Container

Now that the container has stopped, we can start a new httpd container. This time, we'll mount the web root directory to the web root configured in httpd.

The files we want in the web root can be found in **/home/student/webroot**.

```
student@container:~$ ls -alh webroot/
total 12K
drwxrwxr-x 2 student student 4.0K Mar 22 17:03 .
drwxr-xr-x 4 student student 4.0K Mar 22 17:03 ..
-rw-r--r-- 1 student student   52 Mar 22 17:03 index.html
```

> Listing 12 - Listing the Files in /home/student/webroot

To mount the directory, we'll use **-v** (or **--volume**). Similarly to how we mapped the ports, we'll provide the path of the directory we want to map from the host to the path we want to mount it to in the container.

On the host filesystem, the full path is **/home/student/webroot**, and in the container the destination path is **/usr/local/apache2/htdocs/**. We'll separate these directories with a colon.

```
student@container:~$ docker container run -d --rm -p 8080:80 -v /home/student/webroot/:/usr/local/apache2/htdocs/ httpd
e906e90341c59e0b64c6c856d1ddc3a610d4c536959d6ceee321d35a6ce77851

student@container:~$ curl localhost:8080
<html><body><h1>Cloud 100 FTW!!!!</h1></body></html>
```

> Listing 13 - Mounting Host Directory to Container

The httpd container is now hosting the **index.html** file in our web root. Any changes we make to this file should also be reflected in the HTTP response.

```
student@container:~$ nano /home/student/webroot/index.html

student@container:~$ cat /home/student/webroot/index.html 
<html><body><h1>Hackity Hack Hack</h1></body></html>

student@container:~$ curl localhost:8080
<html><body><h1>Hackity Hack Hack</h1></body></html>
```

> Listing 14 - Modifying the index.html File

We might not always want to expose a port via mapping. In some situations, we might want the container to be able to open ports on the host dynamically or run on the same Layer 2 network as the host. For example, a container using _Multicast DNS_ (mDNS)[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1394-2) would need to run on the host network. Docker provides this option via **--network**.

The network option accepts a string as an argument. This string could be the name of a network we previously created, or it could be the value of **host**. The **--network host** argument instructs Docker to start the container on the same network as the host. This means that we don't have to map port 80 to 8080; instead, the httpd container will automatically open port 80 on the host. Let's stop the previous container, start the container with host network mode, and **curl** port 80.

```
student@container:~$ docker container ls
CONTAINER ID   IMAGE     COMMAND              CREATED          STATUS          PORTS                                   NAMES
e906e90341c5   httpd     "httpd-foreground"   40 seconds ago   Up 38 seconds   0.0.0.0:8080->80/tcp, :::8080->80/tcp   keen_leakey

student@container:~$ docker container stop e90
e90

student@container:~$ docker container run -d --rm --network host -v /home/student/webroot/:/usr/local/apache2/htdocs/ httpd 
72e9527b1e6f25e5e4195e7345ec7ed5f85b4223f56f97489585203484a532a5

student@container:~$ curl localhost
<html><body><h1>Hackity Hack Hack</h1></body></html>

student@container:~$ docker stop 72e9527b1 
72e9527b1
```

> Listing 15 - Starting a Container with Host Networking

The container is now running on port 80 and provides us with the HTML file in **/home/student/webroot/**.

Docker (and containerization in general) is very powerful, as we've observed so far in this section by starting multiple containers in matter of seconds. We changed the images used, volumes mounted, and network configurations. However, Docker is not perfect and has its own security concerns.

The Docker CLI tool that we've been using so far is a client to the Docker Daemon (_dockerd_). The daemon runs as _root_.

```
student@container:~$ ps aux | grep dockerd
root        5365  0.0  6.2 1382232 62444 ?       Ssl  Mar22   0:41 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
...
```

> Listing 16 - Docker Running as Root

While containerization does well at attempting to isolate processes to prevent container escapes, misconfigurations and other errors still might result in such vulnerabilities. Since Docker runs as root, if a container escape _is_ discovered, the escaped user would have root access to the system rather than being a lower-privileged user. Defense-in-depth dictates having multiple layers of security controls in place to prevent complete compromise.

In December 2020, Docker introduced a stable method of running the Docker Daemon in a _rootless mode_,[3](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1394-3) although it is rarely put into practice.

1

(Docker, 2022), [https://hub.docker.com/_/centos?tab=description](https://hub.docker.com/_/centos?tab=description) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1394-1)

2

(Wikipedia, 2022), [https://en.wikipedia.org/wiki/Multicast_DNS](https://en.wikipedia.org/wiki/Multicast_DNS) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1394-2)

3

(Docker, 2020), [https://www.docker.com/blog/introducing-docker-engine-20-10/](https://www.docker.com/blog/introducing-docker-engine-20-10/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1394-3)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

containers

#### Labs

1. Run a Docker container with the Ubuntu image. Execute the binary found in **/home/student/exercises/runtime_checker** in the container to receive the flag.

Answer

2. Run a new Docker container with the Ubuntu image but set the hostname of "containme". Execute the binary found in **/home/student/exercises/runtime_checker** in the container to receive the flag.

Answer

## 2.1.3. Podman

One Docker competitor that has been growing in popularity is _Podman_.[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1397-1) Podman was developed to be a drop-in replacement for Docker, meaning all its commands should map nearly identically to Docker. However, while Docker runs a daemon, Podman does not. Instead, all the commands are executed as the user running the command.

Let's connect to the containers host, if we're not already connected.

```
student@kali:~$ ssh student@containers
student@containers's password: 
...

student@container:~$ 
```

> Listing 2 - Connecting to containers host via SSH

Next, let's start a CentOS container, similarly to how we did with Docker. We'll use the **run** command to start a new container, pass **-it** for an interactive shell, remove the container filesystem after execution ends with **--rm**, specify the image and tag with **centos:7**, and finally start **/bin/bash**.

```
student@container:~$ podman run -it --rm centos:7 bash
[root@6f72d59f4004 /]# 
```

> Listing 17 - Starting CentOS 7 Container with Podman

Everything works as expected. As stated earlier, Podman is daemonless, meaning the container is running as the student user instead of root. In most scenarios, this won't cause an issue unless we attempt to run something requiring higher privileges than our current user carries.

An example of such privileged activity is opening any port below 1024. If we were to run the httpd container with host networking, we _should_ receive an error.

Ports under 1024 in Linux are considered privileged and require root privileges. However, this can be changed by recompiling the kernel. Privileged ports were designed to authenticate the server you are communicating with, assuming an adversary has not obtained root privileges. Using privileged ports is also intended to prevent a user from interfering with administrators. Both of these concepts come from legacy systems control and some operating systems, like macOS and Kali, have removed the need for root to run on ports below 1024.

Let's run **podman** again using the **run** command and the **--rm** flag to remove the container after it exits. We'll also specify that we want to run on the same network namespace as the host with **--network host**. We can use the **httpd** image. Because we want to receive the error, we won't run this container in detached mode.

```
student@container:~$ podman run --rm --network host httpd
AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globally to suppress this message
(13)Permission denied: AH00072: make_sock: could not bind to address [::]:80
(13)Permission denied: AH00072: make_sock: could not bind to address 0.0.0.0:80
no listening sockets available, shutting down
AH00015: Unable to open logs
```

> Listing 18 - Error When Using Host Network

When we run this command, we receive an error that port 80 wasn't able to be bound to. This happens because our user (student) is not the root user. We should note that the httpd container runs the httpd service as root, which we can verify by running the **whoami** command. This will overwrite the container's default command to start the httpd service.

```
student@container:~$ podman run --rm --network host httpd whoami
root
```

> Listing 19 - Whoami in httpd Container

This root user, however, only has the same permissions as the student user. If we were to start the httpd container with **sudo**, we'll find that the container starts. This time, we'll use **-d** to run the container in the background. Once the container is running, we'll use curl to check if the service is running. Finally, we'll stop the container.

```
student@container:~$ sudo podman run -d --rm --network host httpd
[sudo] password for student: 
38fb63bb205b25b61aab9b865c72ab8a5a2fc6679ba94ea9fab20fb981952472

student@container:~$ curl localhost
<html><body><h1>It works!</h1></body></html>

student@container:~$ sudo podman stop 38f
38f
```

> Listing 20 - Running the httpd Container with Sudo

Another unique feature that Podman offers is the ability to run Pods. Pods are a collection of multiple containers that share some namespaces. This is most commonly used for multiple containers to share the network namespace. Instead of a container having to expose a port on all interfaces, it can expose it on localhost and the other container in the pod will have access to the first container over localhost. Let's start a pod with two containers.

First, we can create an empty pod named **offsec**. We'll use **podman** and run in the **pod** command space. We'll specify the **create** command and use **--name** to name the pod.

```
student@container:~$ podman pod create --name offsec
01c7f21b7822bd05117af60fdb71b9b844e03c3a0a629b1f6c011eb867e8343c
```

> Listing 21 - Creating a pod

Next, we'll run the httpd container in the offsec pod. We'll use the **run** command again and run the container in detached mode with **-d**. We'll add this container to the pod by specifying **--pod offsec**. Finally, we'll select the **httpd** container.

```
student@container:~$ podman run -d --pod offsec httpd
ff0ca9620b291b157c676ce2bde6212c1087d1aecc3ac3b43387f81943dbc5b1
```

> Listing 22 - Starting Container in Pod

Next, we'll run another container in the same pod. We'll use the **alpine/curl** image since it contains the curl command. We'll again use the **run** command and specify the offsec pod. Finally, we'll run the command **/bin/ash**. This is not a typo: the Alpine Linux distribution does not come with bash by default, and instead uses _ash_.[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1397-2)

Once we have a shell, we'll use **curl** to send a request to **localhost**.

```
student@container:~$ podman run --pod offsec -it alpine/curl /bin/ash

/ # curl localhost
<html><body><h1>It works!</h1></body></html>
```

> Listing 23 - Starting Alpine Container in Pod

While this might seem ordinary, being able to send a request to localhost from another container is fairly impressive. For example, this allows one container in a pod to closely monitor the main container without adding bulk. Since containers share the same kernel with the host, they can also share a network namespace.

Podman also offers other flexibility options that Docker does not, such as making it easier to change the default repository for downloading images.

Podman, like Docker, is very useful for managing containers. Its flexibility and interoperability with Docker makes it a great tool in our arsenal.

1

(Podman, 2022), [https://podman.io/](https://podman.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1397-1)

2

(Wikipedia, 2022), [https://en.wikipedia.org/wiki/Almquist_shell](https://en.wikipedia.org/wiki/Almquist_shell) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1397-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

containers

#### Labs

1. Run a Podman container with the Ubuntu image. Execute the binary found in **/home/student/exercises/runtime_checker** in the container to receive the flag.

Answer

2. Run a new Podman container with the Ubuntu image, but set the hostname to "podme". Execute the binary found in **/home/student/exercises/runtime_checker** in the container to receive the flag.

Answer

## 2.1.4. Ecosystem

The interoperability between Podman and Docker is not a coincidence; it's possible because much of the containerization process is standardized. We won't get into the details of the specification in this section, but it's important to know that this standardization is called the _Open Container Initiative_ (OCI).

This specification makes it easier to create universal tooling. In this section, we'll discuss various parts of the container ecosystem including the CLI tools (Docker and Podman) that interact with the Container Runtime.

![[OffSec/Cloud/Cloud Essentials/z. images/1b73f75d0042a2ba8aa8250f0b94ffe7_MD5.jpg]]

Figure 2: Ecosystem Overview

At the top of this ecosystem is the tool we interact with. This might be a CLI tool like the Docker binary we've been running or Podman. This interface might also be more complex, as the OCI specification does not mandate how the interface must be designed. For example, the Docker CLI tool interacts with the Docker daemon. This entire flow can be considered part of the interface tool.

Next, let's examine the high-level runtime, which is what pulls images, configures the network, sets up storage, and interacts with the low-level runtime. Networking and storage are not part of the OCI specification, but the distribution of images and how images are designed _is_ included. Part of the need for this layer is to translate the non-OCI compliant interface layer to the low-level runtime, which is OCI compliant. By default, Docker uses _containerd_[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1400-1) for this layer, vanilla _Kubernetes_[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1400-2) (as of 1.24) uses CRI-O,[3](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1400-3) and Podman has this built-in.

Vanilla Kubernetes is the upstream Kubernetes project that other Kubernetes implementations and distributions reference. Kubernetes can use either containerd or CRI-O and has decidedly made CRI-O the default as of Kubernetes version 1.24.

Finally, we'll explore the low-level runtime that interfaces with the kernel to run the containers. All the relevant low-level runtimes are OCI compliant. This means that whether we're using Docker, Podman, or Kubernetes, the low-level runtime should be able to be switched without impacting functionality. The most popular runtime is _runc_, written in Go, but others exist such as _crun_, which is written in C.

Before the OCI specification existed, Docker used LXC.[4](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1400-4) The LXC[5](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1400-5) tool is yet another way of running containers. It was created in 2008, four years before Docker, and was very influential in the market. While LXC is still used today, it is not as popular as the alternatives. LXC has many security issues and should be carefully configured if used in production. It's important to note that LXC now supports part of the OCI specification, but since it was designed before the specification, its main functionality does not conform to OCI.

1

(Linux Foundation, 2022), [https://containerd.io/](https://containerd.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1400-1)

2

(Linux Foundation, 2022), [https://kubernetes.io/](https://kubernetes.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1400-2)

3

(CNCF, 2022), [https://cri-o.io/](https://cri-o.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1400-3)

4

(C4Media Inc, 2014), [https://www.infoq.com/news/2014/03/docker_0_9/#:~:text=LXC itself recently announced the,%2C Solaris%2C OpenSolaris and illumos](https://www.infoq.com/news/2014/03/docker_0_9/#:~:text=LXC%20itself%20recently%20announced%20the,%2C%20Solaris%2C%20OpenSolaris%20and%20illumos) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1400-4)

5

(Wikipedia, 2022), [https://en.wikipedia.org/wiki/LXC](https://en.wikipedia.org/wiki/LXC) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1400-5)

#### Labs

1. Is runc a low-level runtime, high-level runtime, or interface tool?

Answer

2. Is CRI-O a low-level runtime, high-level runtime, or interface tool?

Answer

3. What high-level runtime does Docker use by default?

Answer

## 2.2. Container Images

This Learning Unit covers the following Learning Objectives:

- Learn how to create a container image
- Understand how to use a registry to store and download images

Every computer (whether virtualized, containerized, or on bare metal) requires some form of storage to hold the operating system. On bare metal, a hard drive stores the contents of the operating system and the user's data. On a virtual machine, we create a virtual disk and install the operating system using an ISO. With containers, we use images that contain the operating system and all the application files required to run the application.

Essentially, a container image is simply the hard drive of a computer. However, containers are designed to be more lightweight and shareable. This means that ideally, container images should use operating systems with only the bare minimum installed. Unfortunately, this is often not the case.

Each learner moves at their own pace, but this Learning Unit should take approximately 2.5 hours to complete.

## 2.2.1. Creating an Image

To create images, we'll need a way to download a base operating system (like Ubuntu, CentOS, or Alpine) as well as the ability to run commands within that operating system for configuration. Using a base operating system image and running commands, we can create a custom container image with everything an application needs. This custom image can then be run on Docker, Podman, Kubernetes, or any architecture that will run a container.

Let's start by manually creating an image with _Buildah_.[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1405-1) Next, we'll try out the more automated and popular approach of creating a _Dockerfile_.[2](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1405-2) We're choosing Buildah first instead of using Docker natively because Buildah allows us to inspect the container as it's being built.

The image we'll create will run a web server with some custom HTML packaged into the container image.

Our first step in creating an image is to specify the initial template operating system. This could be CentOS, Ubuntu, or Alpine, for example, if we want a bare-bones standard image. It could be another container image that we want to modify or build upon. Alternatively, creating from "scratch" would be to build an image with nothing on the "hard drive".

As mentioned, we'll use the **buildah** command to build this image. We will need to select an image **from** which we want to build on top of. Let's select the **httpd:alpine**[3](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1405-3) image, which runs Apache on top of the Alpine operating system image. The section before the colon is the image name, while the remainder (after the colon) is called the tag. We'll also specify the **--pull-never** flag to ensure Buildah doesn't try to download a new image.

```
student@container:~$ buildah from --pull-never httpd:alpine
httpd-working-container
```

> Listing 24 - Beginning to Build a Container with Buildah

Buildah will return the name of the working container that we are building. We can list all the containers currently being created using the **buildah containers** command.

```
student@container:~$ buildah containers
CONTAINER ID  BUILDER  IMAGE ID     IMAGE NAME                       CONTAINER NAME
94bad5f04a45     *     5c2ee73209da docker.io/library/httpd:alpine   httpd-working-container
```

> Listing 25 - Listing Containers in Buildah

Next, we want to create an **index.html** file and transfer it into the container. We'll echo a short message into an **index.html** file in our working directory. We can then use the **copy** command in **buildah** to transfer the file. We'll have to specify the container we're targeting, which is **httpd-working-container**, as well as the file we want to transfer (**index.html**) and the location we want to transfer it to. In the httpd:alpine container, the web root is in **/usr/local/apache2/htdocs/**.

```
student@container:/home/student$ echo "<h1>Cloud100 - OffSec</h1>" > index.html

student@container:/home/student$ buildah copy httpd-working-container index.html /usr/local/apache2/htdocs/index.html
377a7e8f11396f0392307ff10d6d3b5622f3fab7ffb50b8acedad95048dd07c4
```

> Listing 26 - Copying index.html into Container

Let's briefly analyze what we have built so far. A unique aspect of container images is that every change we make in the image represents a new layer. A layer only holds the differences in the files changed from the original. In this example, we have the layers from httpd:alpine, and we've also created a new layer by transferring over the **index.html** file. Every image starts with an empty or "scratch" layer. From this point, additional layers are created to install packages, transfer files, configure the image, and more.

![[OffSec/Cloud/Cloud Essentials/z. images/8ca0c43be5b793dfcc951c863fc99edb_MD5.jpg]]

Figure 3: Layers Of an Image

Each layer has its own unique ID, a sha256 hash that will represent the layers within the container image.

The image above is over-simplified to show that each Docker layer is created on top of the previous layer. There are more layers needed to build the httpd image shown in this illustration.

Let's investigate the layer that we just created on the filesystem. The Buildah command builds the containers in **/home/student/.local/share/containers/storage/**. We can find the reference to the current container we're building in **overlay-containers/containers.json**. Here, we can discover the ID of the layer we're currently working on.

```
student@container:/home/student$ cat /home/student/.local/share/containers/storage/overlay-containers/containers.json | jq
[
  {
    "id": "94bad5f04a45f11d1b2161c6da01d1b91f05f57db0b972870377954fe96d3587",
    "names": [
      "httpd-working-container"
    ],
    "image": "5c2ee73209dacc502d2b3a27fb283de93bfbb2f7a64243bac8d8b36fd3f1a9df",
    "layer": "54a03bb8f7b1999c5827d2e9817d7bae0e84248b156ab2d52840db61657261b0",
    "created": "2022-05-20T18:04:11.571351547Z",
    "flags": {
      "MountLabel": "",
      "ProcessLabel": "",
      "Volatile": true
    }
  }
]
```

> Listing 27 - Discovering the Layer ID

After obtaining the layer ID, we can find the changes made in the layer within the **overlay/<container_id>/diff** directory.

```
student@container:/home/student$ ls -alh /home/student/.local/share/containers/storage/overlay/54a03bb8f7b1999c5827d2e9817d7bae0e84248b156ab2d52840db61657261b0/diff
total 12K
dr-xr-xr-x 3 student student 4.0K May 19 17:06 .
drwx------ 4 student student 4.0K May 19 17:18 ..
drwxr-xr-x 3 student student 4.0K Apr  5 03:00 usr

student@container:/home/student$ cat /home/student/.local/share/containers/storage/overlay/54a03bb8f7b1999c5827d2e9817d7bae0e84248b156ab2d52840db61657261b0/diff/usr/local/apache2/htdocs/index.html 
<h1>Cloud100 - OffSec</h1>
```

> Listing 28 - Reviewing the Layer Added with Buildah

The **diff** directory only contains the **usr** directory, since the only file that changed was in that directory. If we **cat** out the file, we'll find the contents that we entered.

Now that our container is configured as desired, let's **commit** the container to save it to our local registry. This will also enable us to run the container. For the commit tag, we'll need the container name, **httpd-working-container**, and the name we want to call the image, **custom_site**.

Once we commit the image, we'll use **podman** to run the image and **curl** to test that it's working. If everything is working, we'll stop the container.

```
student@container:/home/student$ buildah commit httpd-working-container custom_site
Getting image source signatures
Copying blob 4fc242d58285 [--------------------------------------] 0.0b / 0.0b
Copying blob 8940aab9b897 [--------------------------------------] 0.0b / 0.0b
Copying blob bd77b6802d25 [--------------------------------------] 0.0b / 0.0b
Copying blob 345ff19ed803 [--------------------------------------] 0.0b / 0.0b
Copying blob 5b32f8958da9 [--------------------------------------] 0.0b / 0.0b
Copying blob 6b37ade17a2d [--------------------------------------] 0.0b / 0.0b
Copying blob 0576aa8bd962 done  
Copying config d514501858 done  
Writing manifest to image destination
Storing signatures
d5145018586e6c5e03fee2429ba3c02ceefb3aec9f320d6b5b00f78db7447205

student@container:/home/student$ podman run -d --rm -p 8080:80 custom_site
3beb2422a921b4c90c940769cc281909ed39c43e79ebcaf4dbe8a50e6fd985ce

student@container:/home/student$ curl 127.0.0.1:8080
<h1>Cloud100 - OffSec</h1>

student@container:/home/student$ podman container stop 3beb2422a921
3beb2422a921
```

> Listing 29 - Committing the image and running it

In both Podman and Docker, we do not have to use the full sha256 ID to reference an image, container, or any other resources. Instead, we can use the smallest unique amount. This means that instead of referencing 3beb2422a921b4c90c940769cc281909ed39c43e79ebcaf4dbe8a50e6fd985ce each time, we can reference only the first twelve characters (3beb2422a921) or even just the first one (3) if there are no other containers.

So far, we've been using Buildah to demonstrate how to create images. More commonly, we would use Docker or Podman to build the images. We can create a **Dockerfile** containing everything we did in Buildah, but organized into a single centralized file.

Next, let's review a **Dockerfile** in the **/home/student/custom_site_docker** directory.

```
student@container:/home/student/custom_site_docker$ cat -n Dockerfile 
1  FROM httpd:alpine
2
3  COPY index.html /usr/local/apache2/htdocs/index.html
4
5  RUN addgroup -S offsec && adduser -S offsec -G offsec
6
```

> Listing 30 - Dockerfile

On the first line, we specify the image we want to build from. We did this with Buildah using the _from_ command. Next, on line three, we copy **index.html** to the web root. We also did this in Buildah with the _copy_ command. Finally, we'll run a command in the container image to add a group named _offsec_ and a user named _offsec_ without a password.

In Dockerfiles, we'll often find that in the RUN instruction, a developer uses _&&_ to chain multiple commands together. This is because the single RUN command that runs _addgroup_ and _adduser_ will be treated as a single layer. This makes the final image smaller and reduces the amount of layers used.

Using layers also allows Docker to cache and reuse parts of the image. If we were to add additional commands below line five, Docker wouldn't have to rebuild the first three steps because it can use the cache.

![[OffSec/Cloud/Cloud Essentials/z. images/8422b9f70e0432f80b49eca1ad23b4c5_MD5.jpg]]

Figure 4: Layers Of an Image - Cache

Next, let's build this image with Docker and run it. We'll build the image using the **build** command and pass it the directory with the Dockerfile. Since the Dockerfile is in the current directory, we'll use the period. Next, we'll use **-t** to specify the tag name we want to use. This time we'll name it **custom_site_docker**.

```
student@container:/home/student/custom_site_docker$ sudo docker build . -t custom_site_docker
Sending build context to Docker daemon  3.072kB
Step 1/3 : FROM httpd:alpine
 ---> 5c2ee73209da
Step 2/3 : COPY index.html /usr/local/apache2/htdocs/index.html
 ---> c0d59df16457
Step 3/3 : RUN addgroup -S offsec && adduser -S offsec -G offsec
 ---> Running in 72fafbbf09d9
Removing intermediate container 72fafbbf09d9
 ---> d2f80c622192
Successfully built d2f80c622192
Successfully tagged custom_site_docker:latest
```

> Listing 31 - Building from a Dockerfile

Finally, let's run the image in docker and ensure that it works.

```
student@container:/home/student/custom_site_docker$ docker run --rm -d -p 8080:80 custom_site_docker
a3d794f7bbb990e886998822203f9e59c0c64bf39090099dd58df18fba775e44

student@container:/home/student/custom_site_docker$ curl 127.0.0.1:8080
<h1>Hello Dockerfile builder!</h1>

student@container:/home/student/custom_site_docker$ docker stop a3d794f7bbb9
a3d794f7bbb9
```

> Listing 32 - Running the custom_site_docker Image

When we start the container, port 8080 on our host is opened and mapped to port 80 in the container. We confirmed this by running curl. Finally, in order to keep our VM clean, we stopped the container using the ID that we received when we started it.

At this point, we've confirmed our custom image works. We've created two similar images, one with Buildah and the other with Docker. Podman has this capability as well, but we did not show it since in the background, Podman uses the command **buildah bud** to create an image from a Dockerfile.

Let's explore additional configurations that might be useful.

In addition to COPY and RUN, there are many other instructions that we can use in a Dockerfile. While we won't explore all of them, let's examine CMD and ENTRYPOINT.

The CMD and ENTRYPOINT instructions have some overlap. The ENTRYPOINT and the CMD combined are the initial commands that will be executed to start the container. The difference is that the CMD can be more easily overwritten than the ENTRYPOINT. The CMD can be overwritten when starting the container at the end of the "docker run" command. Because of this, we can view the ENTRYPOINT as the "permanent" executable and the CMD as the arguments to the permanent instruction. The ENTRYPOINT always comes first and the CMD is tacked on.

```
/usr/bin/nmap  localhost
# ENTRYPOINT + CMD
```

> Listing 33 - Order of ENTRYPOINT and CMD

Above, we specify the ENTRYPOINT as **/usr/bin/nmap** and the CMD as **localhost**. Using this type of configuration ensures that the initial entry into the container is always nmap.

In fact, in the **instrumentisto/nmap** image this is the exact configuration for ENTRYPOINT. The CMD is empty by default, but we can specify **localhost** at the end of the **docker run** command.

```
student@container:/home/student$ docker run instrumentisto/nmap localhost
Starting Nmap 7.92 ( https://nmap.org ) at 2022-06-29 17:34 UTC
Nmap scan report for localhost (127.0.0.1)
Host is up (0.0000040s latency).
Other addresses for localhost (not scanned): ::1
All 1000 scanned ports on localhost (127.0.0.1) are in ignored states.
Not shown: 1000 closed tcp ports (reset)

Nmap done: 1 IP address (1 host up) scanned in 0.16 seconds
```

> Listing 34 - Setting the CMD to localhost

By specifying localhost at the end, we are overwriting the default CMD (which is empty) and setting it to localhost. While it is possible to overwrite the ENTRYPOINT at run time using the _--entrypoint_ argument, this is less intuitive and more difficult than overwriting the CMD.

Let's build a container image that sets the ENTRYPOINT and CMD configurations. A starting point can be found in the **/home/student/custom_entry** directory.

```
student@container:/home/student$ cd /home/student/custom_entry

student@container:/home/student/custom_entry$ cat Dockerfile
FROM ubuntu:latest

COPY shell.sh /shell.sh

RUN chmod +x /shell.sh

ENTRYPOINT ["/usr/bin/bash", "-c"]

CMD ["/shell.sh"]

student@container:/home/student/custom_entry$ cat shell.sh
echo "Running with the following shell:"
readlink /proc/$$/exe
```

> Listing 35 - Reviewing the Dockerfile and Shell Script in custom_entry

This folder contains two files, a Dockerfile and a shell script. The Dockerfile uses _ubuntu_ as the base image, copies over the shell command, ensures that the command is executable, and sets the ENTRYPOINT and CMD configurations. The ENTRYPOINT is set to execute with bash and the CMD is set to execute the shell script.

The shell script displays which shell was used to execute the script. Let's build the image and execute it.

```
student@container:/home/student/custom_entry$ docker image build . -t custom_entry
Sending build context to Docker daemon  3.072kB
Step 1/5 : FROM ubuntu:latest
 ---> d2e4e1f51132
...
Successfully tagged custom_entry:latest

student@container:/home/student/custom_entry$ docker run --rm custom_entry
Running with the following shell:
/usr/bin/bash
```

> Listing 36 - Running the custom_entry Image

When we execute it, we find that the shell used was **/usr/bin/bash**, as expected. If we change the entry point to **/usr/bin/dash**, we'll find that reflected in our output.

```
student@container:/home/student/custom_entry$ nano Dockerfile

student@container:/home/student/custom_entry$ docker image build . -t custom_entry
...

student@container:/home/student/custom_entry$ docker run --rm custom_entry
Running with the following shell:
/usr/bin/dash
```

> Listing 37 - Changing the ENTRYPOINT to Dash

We can overwrite the CMD completely to run a different command such as **hostname** by appending it to the end of the **docker run** command.

```
student@container:/home/student/custom_entry$ docker run --rm custom_entry hostname
65003ac406ab
```

> Listing 38 - Changing the CMD

There are many more instructions that can be set in Dockerfiles. While we don't discuss all of them in this Topic, subsequent Topics will provide a deeper dive on how containerization works. By developing our knowledge base, these additional instructions will become intuitive.

1

(Buildah, 2022), [https://buildah.io/](https://buildah.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1405-1)

2

(Docker, 2022), [https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1405-2)

3

(Docker, 2022), [https://hub.docker.com/_/httpd?tab=description](https://hub.docker.com/_/httpd?tab=description) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1405-3)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

containers

#### Labs

1. Build an image in Docker where the base image is _centos:7_, the CMD is set to **/bin/sh**, there is an environment variable called _SECRET_ set to "OFFSECFTW", and the name of the image is _dockermcdockface_. Run **/home/student/exercises/image_check -name dockermcdockface -runtime docker** to get the flag if everything is configured correctly. You may have to use the Dockerfile reference in the Docker documentation to build this container.

Answer

2. Build an image in Docker where the base image is _centos:7_, the entrypoint is set to **/bin/bash -c**, the CMD is set to **/usr/bin/ls -alh**, the working directory is set to **/app**, there are three layers (of any kind), and the name of the image is _lister_. Run **/home/student/exercises/image_check -name lister -runtime docker** to get the flag if everything is configured correctly. You may have to use the Dockerfile reference in the Docker documentation to build this container.

Answer

3. Build an image in Podman where the base image is _centos:7_, there is a volume named **data**, there are four layers (of any kind), and the name of the image is _podmanmcpodface_. Run **/home/student/exercises/image_check -name podmanmcpodface -runtime podman** to get the flag if everything is configured correctly. You may have to use the Dockerfile reference in the Docker documentation to build this container.

Answer

4. Build an image in Podman where the base image is _centos:7_, CMD is set to **/bin/bash -c "/usr/bin/echo $GREETING"**, there is an environment variable called _GREETING_ set to "Hello, student", and the name of the image is _greeter_. Run **/home/student/exercises/image_check -name greeter -runtime podman** to get the flag if everything is configured correctly. You may have to use the Dockerfile reference in the Docker documentation to build this container.

Answer

## 2.2.2. Image Registries

Now that we've explored container images, let's examine image registries. When an image is created, we need a way to share that image with others. A registry provides an API to save locally-created images and download images created by others.

Docker and Podman don't come with any images bundled. The images we've been using so far (CentOS, Ubuntu, Alpine, etc.) have been downloaded from the _Docker library_.[1](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fn-local_id_1414-1) In Docker and Podman, we can use the _pull_ command to download an image and the _push_ command to save an image to the registry. In order to push, we generally need some form of credentials.

In Docker, the URL of the registry is inferred. For example, if we were to run **docker pull ubuntu**, the Docker command defaults to **docker.io/**, meaning the command essentially becomes **docker pull docker.io/ubuntu**. Podman, on the other hand, supports the Docker registry, but allows the user to configure the default URL. Red Hat runs an image registry called quay.io, which also contains a large amount of images. In Docker, we would have to specify **quay.io** if we wanted to use it. While we can configure a mirror in Docker, it will always still check **docker.io** for an image. Alternatively, Podman can be configured to use any registry by default or search multiple and query which one to download from.

1

(Docker, 2022), [https://hub.docker.com/](https://hub.docker.com/) [↩︎](https://portal.offsec.com/learning-paths/cloud-essentials-167535/learning/containers-for-cloud-i-40052/container-images-40073/image-registries-40055#fnref-local_id_1414-1)

#### Labs

1. What is the command used to download an image from a registry?

Answer

2. What is the command used to upload an image to the registry?

Answer

3. What is the default domain that Docker uses when downloading an image?

Answer