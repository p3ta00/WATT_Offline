In this Module, we will cover the following Learning Units:

- Reconnaissance of Cloud Resources on the Internet
- Reconnaissance via Cloud Service Provider's API

_Reconnaissance_, also known as _information gathering_, is typically the first stage in _pen-testing methodologies_ or a [_cyber-attack kill chain_](https://en.wikipedia.org/wiki/Kill_chain). This is an important phase because it helps discover all the information we can find about the target to expand its attack surface.

During the reconnaissance phase, we can describe _enumeration_ as the process of identifying, categorizing, and listing components and resources within the target.

As we progress through the labs, we'll notice that this process has a recursive nature. While conducting the reconnaissance and enumeration phase, we might identify a vulnerability granting us further access to the environment. Once this happens, it becomes necessary to conduct the reconnaissance phase all over again for the newly-found assets.

In this Module, we'll focus on reconnaissance and enumeration of targets hosted on [_public cloud service providers_](https://csrc.nist.gov/glossary/term/cloud_provider) (CSPs). For our hands-on experience, we'll use [_Amazon Web Services_](https://en.wikipedia.org/wiki/Amazon_Web_Services) (AWS) as our lab environment.

In this first part, we'll take an external approach, meaning we'll analyze only what is publicly accessible. We'll learn how to identify whether a target has resources hosted on a cloud platform and move on to exploring techniques for enumerating cloud resources from the _outside_ perspective.

By understanding and simulating these techniques, we'll also gain valuable insights into how to safeguard cloud environments effectively.

## 1.1. About the Public Cloud Labs

Before we jump in, let's run through a standard disclaimer.

This module uses OffSec's Public Cloud Labs for challenges and walkthroughs. **OffSec's Public Cloud Labs** are a type of lab environment that will complement the learning experience with hands-on practice. In contrast to our more common VM labs found elsewhere in OffSec Learning materials (in which learners will connect to the lab through a VPN), learners using the Public Cloud Labs will interact directly with the cloud environment through the Internet.

OffSec believes strongly in the advantages of learning and practicing in a hands-on environment, and we believe that the OffSec Public Cloud Labs represent an excellent opportunity for both new learners and practitioners who want to stay sharp.

Please note the following:

1. The lab environment should not be used for activities not described or requested in the learning materials you encounter. It is not designed to serve as a playground to test additional items that are out of the scope of the learning module.
    
2. The lab environment should not be used to take action against any asset external to the lab. This is specifically noteworthy because some modules may describe or even demonstrate attacks against vulnerable cloud deployments for the purpose of describing how those deployments can be secured.
    
3. Existing rules and requirements against sharing OffSec training materials still apply. Credentials and other details of the lab are not meant to be shared. OffSec monitors activity in the Public Cloud Labs (including resource usage) and monitors for abnormal events that are not related to activities described in the learning modules.
    

Activities that are flagged as suspicious will result in an investigation. If the investigation determines that a student acted outside of the guidelines described above, or otherwise intentionally abused the OffSec Public Cloud Labs, OffSec may choose to rescind that learner's access to the OffSec Public Cloud Labs and/or terminate the learner's account.

Progress between sessions is not saved. Note that a Public Cloud Lab that is restarted will return to its original state. After an hour has elapsed, the Public Cloud Lab will prompt to determine if the session is still active. If there is no response, the lab session will end. Learners can continue to manually extend a session for up to ten hours. The learning material is designed to accommodate the limitations of the environment. No learner is expected or required to complete all of the activities in a module within a single lab session. Even so, learners may choose to break up their learning into multiple sessions with the labs. We recommend making a note of the series of commands and actions that were completed previously to facilitate the restoration of the lab environment to the state it was in when the learner left. This is especially important when working through complex labs that require multiple actions.

## 1.2. Reconnaissance of Cloud Resources on the Internet

This Learning Unit covers the following Learning Objectives:

- Perform domain and subdomain reconnaissance
- Identify service-specific domains

The first part of the [_NIST Definition of Cloud Computing Model_](https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-145.pdf) states:

Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources...

There is also an essential characteristic of this model that states:

Broad network access: Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous _thin_ or _thick client_ platforms (e.g., mobile phones, tablets, laptops, and workstations).

The terms "ubiquitous" and "convenient" in the description, coupled with the "Broad network access" characteristic, introduce an inherent aspect of public accessibility to cloud resources.

The cloud computing model has evolved since that initial definition. We can find cloud resources that are not meant to be publicly-accessible by default or at all, such as _network interfaces_, _virtual disks_, etc. These are internal components of bigger resources facing the internet but, nevertheless, we can consider them as cloud resources. Some of those components even have the ability to be shared between other users.

In this Module, the attacker's goal during discovery and reconnaissance is to find publicly-accessible resources as well as resources that weren't meant to be publicly-accessible (typically due to misconfigurations).

In this Learning Unit, we'll discuss techniques for discovering cloud resources accessible on the public network that don't require authenticated interaction with the CSP API.

## 1.2.1. Accessing the Lab

For the hands-on experience in this Module, we'll adopt the role of an _attacker_ during the reconnaissance phase, focusing on a single organization as target. Without any information but the domain name, our initial steps will be to collect all the information we can get.

There are some preparatory steps needed to set up our lab environment found at the end of this section. Deployment will take a few minutes to complete and, once complete, the additional services might take 5-10 minutes to start.

Once the lab finishes its deployment, we'll receive some pieces of information we'll need later while working in the lab.

- Public DNS IP Address
- Domain name of the target
- Credentials for the IAM user _attacker_
    - ACCESS_KEY_ID
    - SECRET_ACCESS_KEY

First, we need to configure the DNS in our local environment to use the public DNS set for this lab.

Because this is a simulated exercise, we will not conduct any action on a real published domain. Instead, we'll be targeting a custom public DNS deployed within the lab. The techniques and tools we'll use apply to any public domain, however. After the lab starts, it will take roughly five minutes for the custom DNS server to start responding. We can confirm that all services have started when we can successfully query the DNS server.

We should also keep in mind that the public IP address of the DNS server will change every time we restart the lab, and we'll need to run this configuration again.

In our _Kali_ machine, we can check our current DNS server by reading the **/etc/resolv.conf** file.

```
kali@kali:~$ cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 1.1.1.1
```

> Listing 1 - Getting DNS Servers in Our Kali Machine

We need to add a new _nameserver_ line at the beginning of the file so that our DNS queries first go to our lab DNS server. We'll use **nano** to modify the file, as shown below:

```
kali@kali:~$ sudo nano /etc/resolv.conf
[sudo] password for kali:

kali@kali:~$ cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 44.205.254.229
nameserver 1.1.1.1
```

> Listing 2 - Modifying /etc/resolv.conf to Add a New Nameserver

We can test the configuration with a CLI tool such as _host_, which is used for performing DNS lookups and is commonly installed by default on _Linux_.

Let's assume **www.offseclab.io** exists in our target domain. We'll first run a DNS lookup specifying the DNS server's public IP address. This will validate that the DNS server is responding as expected.

Next, we'll run a DNS lookup again without specifying a DNS server. The tool will use the system's DNS configuration. This will help confirm that our system configuration is also working as expected.

Some ISPs restrict customers from querying external DNS servers. If this occurs, the two commands of the listing below will fail. While not common, this can happen. As a workaround, using a mobile device as a hotspot to connect our lab to the internet is an option. In the worst-case scenario, this issue would only affect our ability to work on the 'Domain Reconnaissance' section.

```
kali@kali:~$ host www.offseclab.io 44.205.254.229
www.offseclab.io has address 52.70.117.69

kali@kali:~$ host www.offseclab.io 
www.offseclab.io has address 52.70.117.69
```

> Listing 3 - Testing DNS Configurations in Kali Using host Tool

Finally, we should keep in mind that the configuration we set up in the DNS will not be permanent. The default network configuration in _Kali_ uses _Network Manager_, and it will overwrite the content of the **resolv.conf** file every time we restart the network service or the whole operating system.

When we finish working in our lab, we need to reset our local Kali machine's DNS settings. To do this, we can again edit the **/etc/resolv.conf** file and remove the _nameserver_ entry that we set while configuring the lab. Another easier way is to restart the _NetworkManager_ service, which will return the file to the original state.

```
kali@kali:~$ sudo systemctl restart NetworkManager
[sudo] password for kali:

kali@kali:~$ cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 1.1.1.1
```

> Listing 4 - Resetting the DNS Settings

We can ensure everything is working as expected by navigating to any public site in the web browser.

For now, we'll start the lab to retrieve the DNS public IP address and configure the network in our local machine to use that secondary DNS server. We'll ignore the IAM user's credentials for the moment.

## 1.2.2. Domain and Subdomain Reconnaissance

Let's begin analyzing the target from the attacker's perspective. Currently, all we know about our target is its domain name: **offseclab.io**.

There are several things we can learn by analyzing the domain and the public IP. In this section, we'll focus mainly on cloud-related information.

Let's begin by getting the _authoritative_ DNS servers, i.e. the name servers that contain all records for this domain. We'll use the **host** command with the **-t ns** argument to query the _nameserver_ records of the **offseclab.io** domain.

```
kali@kali:~$ host -t ns offseclab.io
offseclab.io name server ns-1536.awsdns-00.co.uk.
offseclab.io name server ns-512.awsdns-00.net.
offseclab.io name server ns-0.awsdns-00.com.
offseclab.io name server ns-1024.awsdns-00.org.
```

> Listing 5 - Querying Nameserver Records of offseclab.io Domain

The names are very descriptive, and we can deduce the domain is managed by AWS. We can validate this by running the **whois** command to check the DNS registrar information of those domains. We'll pipe the output to the **grep** command to filter only the line that contains the organization name.

```
kali@kali:~$ whois awsdns-00.com | grep "Registrant Organization"
Registrant Organization: Amazon Technologies, Inc.
```

> Listing 6 - Getting the Registrar Information of awsdns-00.com Domain

Now, we are sure that the **offseclab.io** domain is managed by AWS, very likely using the [_Route53_](https://en.wikipedia.org/wiki/Amazon_Route_53) service. This doesn't mean the rest of the infrastructure is also hosted in AWS, so we need to keep digging.

Let's continue, using the **host** command again to get the public IP address of the website **www.offseclab.io**.

The public IP address in the listing below will be different every time we start the lab.

```
kali@kali:~$ host www.offseclab.io
www.offseclab.io has address 52.70.117.69
```

> Listing 7 - Getting the Public IP address of www.offseclab.io

In the same way as before, we can learn some things by querying the DNS and doing a _reverse_ DNS lookup. We'll use the **host** command again, but this time we'll query the public IP address. We'll also use **whois** to learn more details about the public IP address, paying special attention to the _OrgName_ value.

```
kali@kali:~$ host 52.70.117.69
69.117.70.52.in-addr.arpa domain name pointer ec2-52-70-117-69.compute-1.amazonaws.com

kali@kali:~$ whois 52.70.117.69 | grep "OrgName"
OrgName:        Amazon Technologies Inc.
```

> Listing 8 - Getting Details of the Public IP Address of the Website

With the whois lookup, we realize that the public IP belongs to Amazon and with the reverse lookup, we learn two things: it's a resource hosted in AWS (**amazonaws.com**) and the resource is an [_Amazon Elastic Compute Cloud_](https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud) (Amazon EC2) instance.

By doing some reconnaissance on the domain, we learned that the resource is hosted in a public CSP. This helps adapt our pentesting methodology and techniques to target the correct cloud environment.

While doing passive reconnaissance around the domain and public IP address, we should also include more [_OSINT_](https://osintframework.com/) research to collect more information about the target. The data we gather during this stage could be useful during later reconnaissance. Because the target in this lab is not a real organization, we won't find more data at this stage, so we'll skip this.

It's worth noticing that this phase should be executed recursively, meaning that we should do the same for other domains, subdomains and public IP addresses we find.

Finally, we will run an automated tool that will retrieve some information we already have, but will also perform a _dictionary attack_ to discover more subdomains. There are many tools that do this. In this lab, we'll use the _dnsenum_ tool that comes with Kali. The only required parameter is the domain name we are going to target, i.e. **offseclab.io**. We'll also add the **--threads 500** argument to increase the threads that will execute the requests to the DNS, thus speeding up the attack in case of any throttling.

```
kali@kali:~$ dnsenum offseclab.io --threads 500
dnsenum VERSION:1.2.6

-----   offseclab.io   -----


Host's addresses:
__________________

offseclab.io.                            60       IN    A        52.70.117.69

Name Servers:
______________

ns-1536.awsdns-00.co.uk.                 0        IN    A        205.251.198.0
ns-0.awsdns-00.com.                      0        IN    A        205.251.192.0
ns-512.awsdns-00.net.                    0        IN    A        205.251.194.0
ns-1024.awsdns-00.org.                   0        IN    A        205.251.196.0


Mail (MX) Servers:
___________________



Trying Zone Transfers and getting Bind Versions:
_________________________________________________

Trying Zone Transfer for offseclab.io on ns-512.awsdns-00.net ...
AXFR record query failed: corrupt packet

Trying Zone Transfer for offseclab.io on ns-1024.awsdns-00.org ...
AXFR record query failed: corrupt packet

Trying Zone Transfer for offseclab.io on ns-0.awsdns-00.com ...
AXFR record query failed: corrupt packet

Trying Zone Transfer for offseclab.io on ns-1536.awsdns-00.co.uk ...
AXFR record query failed: corrupt packet


Brute forcing with /usr/share/dnsenum/dns.txt:
_______________________________________________
mail.offseclab.io.                       60       IN    A        52.70.117.69
www.offseclab.io.                        60       IN    A        52.70.117.69
...
```

> Listing 9 - Using dnsenum to Automate DNS Reconnaissance of offseclab.io Domain

The output confirms the name servers and the public IP address we got before. We also discovered some subdomains. The other two sites are fictional for this lab and don't contain real vulnerabilities, so we don't need to analyze them further in this lab.

Let's wrap up this section by providing a glimpse of what we have learned about the target through reconnaissance:

- The domain service is hosted in AWS, so it's likely using AWS Route53 service.
- The domain name resolves to a public IP, which is also provided by AWS, specifically to the EC2 service.
- This public IP serves several websites including the main site **www.offseclab.io**, meaning they are running inside an EC2 instance.

In the next section, we'll analyze the main site while continuing to perform cloud-related reconnaissance.

#### Labs

1. Find the proof while gathering more info about the domain inside other commonly used DNS records.

Answer

## 1.2.3. Service-specific Domains

We already conducted some reconnaissance around the target's domain name. In this section, we'll search around service-specific domains to find cloud resources belonging to the target organization.

Public CSPs often use a specific domain name to address cloud resources. We already found an example of this in the previous section when we did a DNS reverse lookup to the public IP address and, through the response (_ec2-52-70-117-69.compute-1.amazonaws.com_), we discovered the domain **amazonaws.com** and that they are using the EC2 service. That is the custom naming that AWS uses to create the [_PTR records_](https://en.wikipedia.org/wiki/List_of_DNS_record_types#PTR) for their public IPs assigned to EC2 instances.

We can leverage these naming conventions in public cloud resources to enumerate cloud resources.

Let's continue with the lab to explore an example. We'll interact with the publicly-available resources we have found, starting with the website.

Before proceeding with the lab, we should ensure the lab is running and the public IP of the DNS is configured in our local OS.

We'll use a browser to start analyzing the site. Our main focus is to learn about the technologies behind it. After this, we can decide whether to use other tools for further analysis.

Let's open a web browser and navigate to [http://www.offseclab.io](http://www.offseclab.io).

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/1c66f5fee46bf56a120953360daa5e4a_MD5.jpg]]

Figure 1: Offseclab's Website

By interacting with the site, we can learn that **offseclab.io** is an organization hosting vulnerable lab environments for learning purposes.

We should be aware that the site is fictional for this lab; it doesn't really implement or give access to the projects displayed.

By visiting the domain, we're provided an HTML file. At this point, we're unsure which, or even if, server-side scripting languages are in use. To inspect this further, let's use the _Developer Tools_ to determine what assets the site loads when we browse it.

We'll use _Firefox_, since it's in the default installation of Kali Linux, and open _Developer Tools_ using the hotkey +. Other browsers also implement this hotkey for their own developer tools, although the UI appearance may be different.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/7361c53720caf44acca9b970f69c51ab_MD5.jpg]]

Figure 2: Opening the Developer Tools in Firefox

Inside the _Developer Tools_ window, we'll navigate to the _Network_ tab. This will show us all the requests that are made when loading the website. Once in the _Network_ tab, we can reload the current page.

We receive a table with several elements that the website loads. This includes _stylesheet files_ (.css), _script files_ (.js), _images_ (.png, .jpg), etc. The _File_ column identifies the filename of the element and the _Domain_ column identifies to which domain the browser requests it.

If we scroll through the list, we'll find that the browser requests elements coming from some domains, which include **offseclab.io**, some fonts from external domains, and more interestingly, some images from **s3.amazonaws.com**.

We can click on one of these images to retrieve more details of the request, including the full resource path of the element.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/5b7f64155ad14be3d878a776b17ca56e_MD5.gif]]

Figure 3: Getting the URL of the S3 Object

We can copy the URL or double-click on the row to open the image in another browser tab, then analyze the URL.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/d4986d744c207967b14d3a7a434ff92e_MD5.jpg]]

Figure 4: Analyzing the S3 URL

By identifying the domain in the URL **s3.amazonaws.com**, we can infer that the images are stored in an AWS S3 bucket.

If we have local issues communicating with the public DNS server, we can get the bucket name from AWS CLI by running the 's3 ls' subcommand with the _attacker_ profile.

From the path **offseclab-assets-public-axevtewi/sites/www/images/amethyst.png**, we can learn that the S3 bucket name is _offseclab-assets-public-axevtewi_ and the _object key_ is **sites/www/images/ruby-expanded.png**.

The URL format is documented in [Methods for accessing a bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-bucket-intro.html).

The documentation includes the _AWS Region_ in the URL. In this example, AWS internally redirects **s3.amazonaws.com** to **s3.us-east-1.amazonaws.com**. This behavior might not be the same for other services.

Before diving into enumeration, let's quickly check if we can list the content of the bucket. We can test this by browsing the URL of the bucket in the web browser.

We'll remove the _object key_ from the URL like the following: **http://domain/bucket_name**, then browse to that URL. Ideally, we should receive an _Access Denied_ error.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/db8d8f086022c531d41614216464f777_MD5.jpg]]

Figure 5: List the offseclab-assets-public Bucket

Instead of the _Access Denied_ error, we received an XML response containing all the key objects in the bucket. This is not a good practice in the bucket configuration. Unfortunately for us, besides the images, there aren't other objects in the bucket that can help us exploit the target further.

Objects can be public inside a bucket without setting public access to the bucket itself.

Next, let's analyze the bucket name: _offseclab-assets-public-axevtewi_. We can assume there is a naming convention in use that consists of the _org name_ followed by a _description_ of the bucket and a _random string_. Bucket names must be _unique_ across the region, so the random string might be used to ensure that the name won't be duplicated. It can also help to avoid discovery by enumeration.

Making some assumptions about the naming convention, let's try browsing for the buckets with the name _offseclab-assets-dev_. In the original URL, we'll replace the word "public" with "dev".

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/13b02de3ff42d6b5adc957a00807c659_MD5.jpg]]

Figure 6: List the offseclab-assets-dev Bucket

The XML response of _offseclab-assets-dev_ clearly states that the bucket does not exist.

Let's try again, this time using the name _offseclab-assets-private_.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/33261aef3a3158990e2cc6aff37ce128_MD5.jpg]]

Figure 7: List the offseclab-assets-private Bucket

This time we receive a different message. This code means that the bucket exists, although access is denied because it doesn't have _public read permission_. This is a good configuration for the bucket.

The random string should have helped avoid discovery by enumeration, but because the same random string was used, the effect was nullified. The practice of adding random strings or _hashes_ is normal, but in this case, it was poorly implemented.

This discovery required some creativity and assumptions, but shows an example of enumerating cloud resources. The process is also easy to automate by writing a script on our own or searching for an already-built tool like [_cloudbrute_](https://www.kali.org/tools/cloudbrute/) or [_cloud-enum_](https://www.kali.org/tools/cloud-enum/).

Just like the S3 service, other cloud services that are designed to be publicly-accessible typically use a custom URL or standard convention for displaying resources. This is true for other public CSPs, too. The table below lists some examples.

|AWS|Azure|GCP|
|---|---|---|
|s3.amazonaws.com|web.core.windows.net|appspot.com|
|awsapps.com|file.core.windows.net|storage.googleapis.com|
||blob.core.windows.net||
||azurewebsites.net||
||cloudapp.net||

> Table 1 - Custom URLs of All The Three Major CSPs

We can leverage these domains to search for resources in multiple clouds based on a _keyword_ related to our target. Multi-cloud deployment is out of the scope for this Module, but we'll use the tool [_cloud-enum_](https://www.kali.org/tools/cloud-enum/) to search for more buckets belonging to **offseclab.io**.

Even though this is a lab environment, we are interacting directly with the AWS API. We'll keep this environment controlled by running the enumeration with a small-sized dictionary.

Kali already includes cloud-enum in its official repository. Let's install it after updating the packages.

```
kali@kali:~$ sudo apt update
[sudo] password for kali:
...

kali@kali:~$ sudo apt install cloud-enum
[sudo] password for kali:
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
...
Unpacking cloud-enum (0.7-3) over (0.7-2) ...
Setting up cloud-enum (0.7-3) ...
Processing triggers for man-db (2.11.2-2) ...
Processing triggers for kali-menu (2023.1.7) ...
```

> Listing 10 - Updating the Packages and Installing cloud-enum in Kali Linux

Be aware that the package name of the tool is cloud-enum but the actual tool name to run in the command line is _cloud_enum_.

Once the installation completes, we can confirm it's installed by running **cloud_enum --help**. This will output the basic command usage.

```
kali@kali:~$ cloud_enum --help
usage: cloud_enum [-h] (-k KEYWORD | -kf KEYFILE) [-m MUTATIONS] [-b BRUTE]
                  [-t THREADS] [-ns NAMESERVER] [-l LOGFILE] [-f FORMAT]
                  [--disable-aws] [--disable-azure] [--disable-gcp] [-qs]

Multi-cloud enumeration utility. All hail OSINT!

options:
  -h, --help            show this help message and exit
  -k KEYWORD, --keyword KEYWORD
                        Keyword. Can use argument multiple times.
  -kf KEYFILE, --keyfile KEYFILE
                        Input file with a single keyword per line.
  -m MUTATIONS, --mutations MUTATIONS
                        Mutations. Default: /usr/lib/cloud-
                        enum/enum_tools/fuzz.txt
  -b BRUTE, --brute BRUTE
                        List to brute-force Azure container names. Default:
                        /usr/lib/cloud-enum/enum_tools/fuzz.txt
  -t THREADS, --threads THREADS
                        Threads for HTTP brute-force. Default = 5
  -ns NAMESERVER, --nameserver NAMESERVER
                        DNS server to use in brute-force.
  -l LOGFILE, --logfile LOGFILE
                        Appends found items to specified file.
  -f FORMAT, --format FORMAT
                        Format for log file (text,json,csv) - default: text
  --disable-aws         Disable Amazon checks.
  --disable-azure       Disable Azure checks.
  --disable-gcp         Disable Google checks.
  -qs, --quickscan      Disable all mutations and second-level scans
```

> Listing 11 - Getting the cloud_enum Tool Usage Options

The cloud-enum tool will search through several public CSPs for resources containing a keyword specified using the **--keyword KEYWORD** (**-k KEYWORD**) parameter. We can specify multiple keyword arguments, or we can specify a list with the **--keyfile KEYFILE** (**-kf KEYFILE**) parameter.

We can also use the **--mutations** (**-m**) option to specify a file to add extra words to the keyword. If we don't specify any file, the **/usr/lib/cloud-enum/enum_tools/fuzz.txt** file is used by default. We can disable this option using the **--quickscan** (**-qs**) parameter.

Let's first test this using the bucket name we already know. We'll run a quickscan with **cloud_enum -k offseclab-assets-private-axevtewi -qs**. We'll also only perform a check in AWS, disabling other CSPs with the **--disable-azure** and **--disable-gcp** parameters.

```
kali@kali:~$ cloud_enum -k offseclab-assets-public-axevtewi --quickscan --disable-azure --disable-gcp

...

Keywords:    offseclab-assets-public-axevtewi
Mutations:   NONE! (Using quickscan)
Brute-list:  /usr/lib/cloud-enum/enum_tools/fuzz.txt

[+] Mutated results: 1 items

++++++++++++++++++++++++++
      amazon checks
++++++++++++++++++++++++++

[+] Checking for S3 buckets
  OPEN S3 BUCKET: http://offseclab-assets-public-axevtewi.s3.amazonaws.com/
      FILES:
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/offseclab-assets-public-axevtewi
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/amethyst-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/amethyst.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/logo.svg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic02.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic05.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic13.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/ruby-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/ruby.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/saphire-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/saphire.jpg
                            
                            
 Elapsed time: 00:00:00

[+] Checking for AWS Apps
[*] Brute-forcing a list of 1 possible DNS names
                            
 Elapsed time: 00:00:00


[+] All done, happy hacking!
```

> Listing 12 - Running Quick Scan Against offseclab-assets-public-axevtewi Bucket Using cloud_enum in AWS

We can confirm that the tool works as expected. It found the bucket and also listed the content. Next, we'll try to enumerate with more keywords. Because we are testing a specific naming pattern, we'll benefit from building a custom key file.

There are many ways we could accomplish this. We'll use simple _Bash_ scripting to run a oneliner _for loop_ that iterates over some keywords and **echo** the keyword, inserting a prefix (_offseclab-assets_) and a suffix (_-axevtewi_) around it. Finally, we'll use the **tee** command to output the result to the console as well as the **/tmp/keyfile.txt** file. As a result, we have the key file with the names of buckets to validate if they exist.

```
kali@kali:~$ for key in "public" "private" "dev" "prod" "development" "production"; do echo "offseclab-assets-$key-axevtewi"; done | tee /tmp/keyfile.txt
offseclab-assets-public-axevtewi
offseclab-assets-private-axevtewi
offseclab-assets-dev-axevtewi
offseclab-assets-prod-axevtewi
offseclab-assets-development-axevtewi
offseclab-assets-production-axevtewi
```

> Listing 13 - Making a Dictionary of Keywords to Search S3 Buckets

Now, we can run cloud_enum again by specifying the key file we generated (**/tmp/keyfile.txt**) with the **--keyfile** (**-kf**) argument.

```
kali@kali:~$ cloud_enum -kf /tmp/keyfile.txt -qs --disable-azure --disable-gcp

...

Keywords:    offseclab-assets-public-axevtewi, offseclab-assets-private-axevtewi, offseclab-assets-dev-axevtewi, offseclab-assets-prod-axevtewi, offseclab-assets-development-axevtewi, offseclab-assets-production-axevtewi
Mutations:   NONE! (Using quickscan)
Brute-list:  /usr/lib/cloud-enum/enum_tools/fuzz.txt

[+] Mutated results: 6 items

++++++++++++++++++++++++++
      amazon checks
++++++++++++++++++++++++++

[+] Checking for S3 buckets
  OPEN S3 BUCKET: http://offseclab-assets-public-axevtewi.s3.amazonaws.com/
      FILES:
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/offseclab-assets-public-axevtewi
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/amethyst-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/amethyst.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/logo.svg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic02.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic05.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/pic13.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/ruby-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/ruby.jpg
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/saphire-expanded.png
      ->http://offseclab-assets-public-axevtewi.s3.amazonaws.com/sites/www/images/saphire.jpg
  Protected S3 Bucket: http://offseclab-assets-private-axevtewi.s3.amazonaws.com/
                            
 Elapsed time: 00:00:06

[+] Checking for AWS Apps
[*] Brute-forcing a list of 6 possible DNS names
                            
 Elapsed time: 00:00:00


[+] All done, happy hacking!
```

> Listing 14 - Running cloud_enum Against The Generated keyfile.txt File

From the output, we can confirm there is another bucket, but it's _Protected_, meaning that it's not publicly-readable.

We could also attempt to validate if there are other buckets using other information we found during the reconnaissance phase. For example, it could be buckets that include the name of the _offseclab_ projects like _offseclab-assets-ruby-axevtewi_ or _offseclab-ruby-axevtewi_. We'll leave this as an exercise.

Let's summarize what we learned in this section.

Some resources in the cloud are meant to be publicly-accessible, and to discover these resources is not precisely a problem. However, we may encounter some resources with misconfigurations that grant over-excessive permissions.

Hosting in the cloud is flexible, meaning that organizations can deploy resources in several clouds. Discovering that an organization is using one cloud provider doesn't mean they aren't using other CSP services.

#### Labs

1. Use the concepts we've learned to find other S3 buckets. We may want to build a dictionary around gemstones' names as it is the theme that the target uses to name the projects. Assume that the format follows the pattern _offseclab-[gemstone]-[lab_assigned_random_value]_. The proof resides in an object named **proof.txt**.

Answer

## 1.3. Reconnaissance via Cloud Service Provider's API

This Learning Unit covers the following Learning Objectives:

- Obtain information from publicly shared resources
- Obtain account IDs from public S3 buckets
- Enumerate IAM users in other accounts

Typically, public CSPs will enable at least two ways for customers to interact with their cloud environment.

One way is via a web application that acts as a portal for cloud services provided by the CSP. Access is protected by credentials (username, password, MFA, etc).

Another way is through APIs that allow customers to interact programmatically, integrating with custom solutions and even other cloud platforms. The API is publicly available, but requires authentication to interact with it.

In this section, we'll learn about some techniques that an attacker can use to discover more information about the target by interacting with the provider's API. In this case, the attacker creates an account in the cloud provider to receive credentials for interacting with the API.

We'll also review some examples of API abuse to obtain internal information about the target, i.e. users and roles.

## 1.3.1. Preparing the Lab - Configure AWS CLI

In the following sections of this Learning Unit, we'll interact with the AWS API from the command line using AWS CLI configured with the credentials that will be provided when we start the lab. Although the access keys belong to an IAM user inside the target account, we'll simulate that they belong to an attacker from an external account.

If AWS CLI is not already installed, we can easily do it in Kali using the package manager.

```
kali@kali:~$ sudo apt update
...

kali@kali:~$ sudo apt install -y awscli
...
The following NEW packages will be installed:
  awscli docutils-common python3-awscrt python3-docutils python3-jmespath python3-roman
(Reading database ... 461429 files and directories currently installed.)
...
```

> Listing 15 - Installing AWS CLI in Kali Linux

To configure the credentials in AWS CLI, we'll use a _named profile_ instead of the default. This is a good practice, since during the lab we might need to interact with AWS as other IAM users; using profiles will make it easier to differentiate one IAM from another.

We'll run the **aws --profile attacker configure** command in the terminal. This will create a profile named _attacker_. When prompted, we'll set the values of _attacker_access_key_id_ and _attacker_access_key_secret_ provided when starting the lab.

To use the profile, we'll need to add the **--profile attacker** argument to every AWS command we run. Let's test this by running the **aws --profile attacker sts get-caller-identity** command. A JSON response with the user information is proof that the credentials were valid and we are interacting with the AWS API as the _attacker_ IAM user.

```
kali@kali:~$ aws configure --profile attacker
AWS Access Key ID []: AKIAQO...
AWS Secret Access Key []: cOGzm...
Default region name []: us-east-1
Default output format []: json

kali@kali:~$ aws --profile attacker sts get-caller-identity
{
    "UserId": "AIDAQOMAIGYU5VFQCHOI4",
    "Account": "123456789012",
    "Arn": "arn:aws:iam::123456789012:user/attacker"
}
```

> Listing 16 - Configuring Profile and Validating Communication with AWS API

Once AWS CLI is properly configured with the _attacker_ profile, we can proceed with the following sections of the lab.

## 1.3.2. Publicly Shared Resources

Some cloud assets, given the nature of their function, are inherently designed to be published on the internet, such as standard operating system images (_Ubuntu_, _Debian_, etc.) that organizations use as a building block for their EC2 instance. CSPs normally provide user-friendly ways to access these.

Alternatively, some cloud resources are designed for internal use, for example, custom-built machine images or snapshots of virtual drives and databases. Despite this, large organizations might have multiple public cloud accounts and need to share these resources between accounts or even publicly.

Ideally, these publicly-shared resources won't contain sensitive data and customers should do their part of the shared responsibility model and protect their assets. However, this is not always the case.

In this section, we are going to search and discover publicly-shared resources from **offseclab.io**. We'll focus on the following commonly used resources:

- Publicly-shared [Amazon Machine Images](https://en.wikipedia.org/wiki/Amazon_Machine_Image) (AMIs)
- Publicly-shared [Elastic Block Storage](https://en.wikipedia.org/wiki/Amazon_Elastic_Block_Store) (EBS) snapshots
- [Relational Databases](https://en.wikipedia.org/wiki/Amazon_Relational_Database_Service) (RDS) snapshots

These shared resources commonly don't have a domain name or URL address to access them, so we'll need to use the CSP's API to request them.

Let's open the CLI, where we have the AWS CLI tool configured with the _attacker_'s credentials. We'll search "Publicly Shared AMIs" as an example.

AMIs are virtual machine images containing a pre-installed operating system along with software and files. To deploy an EC2 instance in AWS, we must specify an AMI. We normally choose one from the public _AMI Catalog_, which contains images publicly shared by AWS, third-party partners, community, and other accounts. Let's use AWS CLI to list all these AMIs.

Unless otherwise specified, we'll be using the _attacker_ profile, so we'll include in every command the **--profile attacker** argument.

The command **ec2 describe-images** will list all the images that the account can read. This will provide an extensive list of images as output. Let's include the **--owners amazon** argument to filter this list and show only AMIs provided by AWS.

Optionally, we can add the **--executable-users all** argument to ensure that all public AMIs will be listed, including any self-owned public AMIs.

Even filtering the results, the command below will take 30-60 seconds to complete.

```
kali@kali:~$ aws --profile attacker ec2 describe-images --owners amazon --executable-users all
{
    "Images": [
        {
            "Architecture": "x86_64",
            "CreationDate": "2022-06-29T09:46:55.000Z",
            "ImageId": "ami-0d4f490f4e62171b4",
            "ImageLocation": "amazon/Deep Learning Base AMI (Amazon Linux 2) Version 53.4",
            "ImageType": "machine",
            "Public": true,
            "OwnerId": "898082745236",
            "PlatformDetails": "Linux/UNIX",
            "UsageOperation": "RunInstances",
            "State": "available",
            "BlockDeviceMappings": [
                {
                    "DeviceName": "/dev/xvda",
                    "Ebs": {
                        "DeleteOnTermination": true,
                        "Iops": 3000,
                        "SnapshotId": "snap-0ce7f231ea72dd0ea",
                        "VolumeSize": 100,
...
```

> Listing 17 - Listing All Public AMIs Owned by Amazon AWS

Instead of **--owners amazon**, we can specify any other _Account ID_ to list all the AMIs owned by that account.

We don't know the account ID of our target. However, we can leverage the filtering feature of the API to find resources.

The structure of a _filter expression_ is as follows:

```
--filters "Name=filter-name,Values=filter-value1,filter-value2,..."
```

> Listing 18 - The Filter Expression Format

_Name_ refers to the attribute of the object we want to filter and _Values_ refers to the content of that attribute. Therefore, to filter for AMIs that include the word "offseclab" in the description attribute, we'll set:

```
    -\-filters "Name=description,Values=\*Offseclab\*"
```

> Listing 19 - The Filter Expression Format for offseclab Word

We'll note that the _*Offseclab*_ value is using the wildcard _*_. This means that it will match any number of characters (including _none_ characters) at the beginning and the end surrounding the word "Offseclab".

```
kali@kali:~$ aws --profile attacker ec2 describe-images --executable-users all --filters "Name=description,Values=*Offseclab*"
{
    "Images": []
}
```

> Listing 20 - Listing All Public AMIs After Filtering the List Using the Keyword "description"

We got a response with an empty list, meaning that there were no images that matched our filter.

Another input that the user controls when creating the image is the attribute _name_, so let's try filtering by that one.

```
kali@kali:~$ aws --profile attacker ec2 describe-images --executable-users all --filters "Name=name,Values=*Offseclab*"
{
    "Images": [
        {
            "Architecture": "x86_64",
            "CreationDate": "2023-08-05T19:43:29.000Z",
            "ImageId": "ami-0854d94958c0a17e6",
            "ImageLocation": "123456789012/Offseclab Base AMI",
            "ImageType": "machine",
            "Public": true,
            "OwnerId": "123456789012",
            "PlatformDetails": "Linux/UNIX",
            "UsageOperation": "RunInstances",
            "State": "available",
            "BlockDeviceMappings": [
                {
                    "DeviceName": "/dev/xvda",
                    "Ebs": {
                        "DeleteOnTermination": true,
                {
                    "DeviceName": "/dev/xvda",
                    "Ebs": {
                        "DeleteOnTermination": true,
                        "DeleteOnTermination": true,
                        "SnapshotId": "snap-098dc18c797e4f255",
                        "VolumeSize": 8,
                        "VolumeType": "gp2",
                        "Encrypted": false
                    }
                }
            ],
            "EnaSupport": true,
            "Hypervisor": "xen",
            "Name": "Offseclab Base AMI",
            "RootDeviceName": "/dev/xvda",
            "RootDeviceType": "ebs",
            "SriovNetSupport": "simple",
            "Tags": [
                {
                    "Key": "Name",
                    "Value": "Offseclab Base AMI"
                }
            ],
            "VirtualizationType": "hvm",
            "DeprecationTime": "2023-08-05T21:43:00.000Z"
        }
    ]
}
```

> Listing 21 - Listing All Public AMIs After Filtering the List Using the Keyword "name"

This time we got a match and found one AMI. We also got the account ID that most likely belongs to the target organization. With the account ID, we can search for more AMIs or other resources; we'll leave that as an exercise for the end of this section.

Similarly, we can seek publicly-shared _EBS snapshots_ using the **ec2 describe-snapshots** command.

```
kali@kali:~$ aws --profile attacker ec2 describe-snapshots --filters "Name=description,Values=*offseclab*"
{
    "Snapshots": []
}
```

> Listing 22 - Listing Public Snapshots After Filtering the List Using the Keyword "description"

We couldn't find any other resource, but we can get an idea of how to use the CSP's API features to search for publicly-shared resources.

There isn't a golden rule for this, though. The search will depend on the type of resource, the service API, the public CSP, etc. The best way to approach this is to investigate publicly-exposable resources in specific CSPs (e.g. [AWS](https://github.com/SummitRoute/aws_exposable_resources)) and consult the documentation for the services we want to try.

Finding these type of resources widens the attack surface and opens new attack vectors to try. For instance, with the AMI found in **offseclab.io**, we can try launching an EC2 instance with that image and searching for more sensitive data. Even if we don't find sensitive info that can give us direct access to the cloud infrastructure, we still can learn more about our target.

#### Labs

1. Use the _account ID_ to search for other publicly shared resources. You will find a 1 GB-sized snapshot (VoumeSize: 1). Copy the description of the newly found resource and paste it into the answer box. (This resource is not really publicly shared, but we should be able to list it with the provided credentials for the lab.)

Answer

## 1.3.3. Obtaining Account IDs from S3 Buckets

In the previous section, we discovered the AWS account ID of the target by finding publicly-shared resources through the AWS API. In this case, we'll assume that there are no publicly shared resources, so we can't get the account ID that way.

In this section, we'll learn a technique for how we can abuse the API features and capabilities to obtain the target's account ID from a publicly-shared S3 bucket or object.

We'll begin by creating an IAM user that, by default, won't have any permissions to execute actions. Then we'll add a policy to grant _read_ access to the bucket with the _Condition_ that the permission will only apply if the account ID that owns the bucket starts with the digit "x". If we can't read the bucket, we'll keep trying with other numbers until we are able to read the bucket, showing we've identified the first digit of the account ID where the bucket resides. We can iterate through the other digits until we retrieve all the account IDs.

First, we'll choose a publicly-readable bucket or object inside the target account. Because the bucket/object is publicly-readable, we should be able to list the content of it with any IAM user of any AWS account. In the lab, we'll choose one of the publicly-readable buckets.

Then, we'll create a new IAM user in our _attacker_ account. By default, IAM users don't have any permissions to execute any actions, so the new user won't be able to list the content of the public resource even when it's public.

Next, we'll create a policy that will grant permissions to _list buckets_ and _read objects_. However, we'll add the _Condition_ that the _read_ permission will only apply if the account ID that owns the bucket starts with the digit "x".

After we apply the policy to the new IAM user, let's test if we can list the bucket with the new user's credentials. We'll test the value _x_ from 0 to 9 until we can list the bucket, meaning that we found the first digit of the account.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/6a0d4545905de8be1e82b266fb887cb5_MD5.gif]]

Figure 8: Getting AccountID from a Public S3 Bucket or Object

This technique is tailored for AWS. However, it shows how APIs can be exploited to retrieve information beyond their intended purpose, a tactic that can be relevant in various platforms and contexts.

Let's check how this works in our lab. We can use the _offseclab-assets-public-..._ bucket, which is publicly-readable. If it wasn't readable, we could also use a publicly-readable object on the bucket, such as any of the images of the website.

To begin, let's retrieve the bucket name again.

The bucket name has a random string that changes every time we restart the lab. We need to check the new name every time we restart the lab.

We can browse the website [**www.offseclab.io**](http://www.offseclab.io) and get the bucket name from the URL of any of the images in the website as we did previously. This time, however, we will use _curl_ to perform this task.

First, we'll get the source code in HTML of the main site using **curl -s www.offseclab.io**. The **-s** flag will omit the loading statistic lines that curl outputs by default.

In our next step, we'll pipe the output to **grep** to filter out a particular string or pattern, aiming to extract the bucket's name. This bucket's name begins with the prefix "offseclab-assets-public-" and is followed by a random sequence of eight alphanumeric characters. This is represented as the regular expression offseclab-assets-public-\w{8}. The **-P** flag instructs grep to interpret the pattern using _perl-regexp_ syntax. Since the default behavior of grep is to display the entire line where the pattern is found, we'll use **-o** to display just the matched portion.

```
kali@kali:~$ curl -s www.offseclab.io | grep -o -P 'offseclab-assets-public-\w{8}'
offseclab-assets-public-kaykoour
offseclab-assets-public-kaykoour
offseclab-assets-public-kaykoour
offseclab-assets-public-kaykoour
```

> Listing 23 - Getting the Name of the Public Bucket with curl

The output shows four matches, one for every image in the homepage source code. We can copy the bucket name from the output.

Last time, we validated that the bucket was publicly-accessible by listing the content in the web browser. We'll use the AWS CLI tool this time. To list the content of the bucket, we can use the **s3 ls** command.

```
kali@kali:~$ aws --profile attacker s3 ls offseclab-assets-public-kaykoour
                           PRE sites/
```

> Listing 24 - Listing the Public Bucket as the attacker

Ideally, we are running this command from our own AWS account, so it's safe to assume that the bucket probably has an ACL or policy that grants _read_ access to all accounts.

Now, let's create a new IAM user with the **iam create-user --user-name enum** command. Let's keep in mind that this user resides in the _attacker-controlled_ AWS account.

Next, we'll also create access keys for the IAM user, so we can interact as this user with the AWS API through the AWS CLI tool. We'll run the **iam create-access-key --user-name enum** command and take note of the _AccessKeyId_ and _SecretAccessKey_ in the output.

```
kali@kali:~$ aws --profile attacker iam create-user --user-name enum
{
    "User": {
        "Path": "/",
        "UserName": "enum",
        "UserId": "AIDAQOMAIGYU4HTPEJ32K",
        "Arn": "arn:aws:iam::123456789012:user/enum",
    }
}

kali@kali:~$ aws --profile attacker iam create-access-key --user-name enum
{
    "AccessKey": {
        "UserName": "enum",
        "AccessKeyId": "AKIAQOMAIGYURE7QCUXU",
        "Status": "Active",
        "SecretAccessKey": "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",
    }
}
```

> Listing 25 - Creating the IAM User "enum" and Generating AccessKeyId and SecretAccessKey for that User

To interact as the new IAM user, we'll create a profile in the AWS CLI with the newly-created access keys. We'll run **aws configure --profile enum** and input the _Access Key ID_ and _Secret Access Key_.

Once the profile is created, we just need to add the **--profile enum** argument to every command we want to run as the _enum_ user. Let's try this by running **aws sts get-caller-identity --profile enum**. This will return the _UserId_, _Account_, and _ARN_ (Amazon Resource Name) of the identity interacting with the API.

```
kali@kali:~$ aws configure --profile enum
AWS Access Key ID [None]: AKIAQOMAIGYURE7QCUXU
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: json

kali@kali:~$ aws sts get-caller-identity --profile enum
{
    "UserId": "AIDAQOMAIGYU4HTPEJ32K",
    "Account": "123456789012",
    "Arn": "arn:aws:iam::123456789012:user/enum"
}
```

> Listing 26 - Configuring AWS CLI with Profile "enum"

Newly-created users with no policies attached are almost fully restricted from accessing any resource, even listing public buckets in other AWS accounts. However, we can provide access by creating a policy that allows a very specific action, such as listing a public bucket. If we add a condition that checks if the account number owning the S3 bucket starts with a specific number, we can enumerate and extract the account number.

Before proceeding, we need to address a key difference between our lab environment and a real attack. In a real attack, the _enum_ user resides in the attacker's AWS Account. In our lab environment, both the _enum_ user and the target bucket are on the same AWS account. We'll pretend that they are in different accounts. However, this forces us to slightly change the exploit. Instead of listing the public bucket, we'll list the private bucket. The reason for this is that even though an IAM user doesn't have a policy attached granting permission to list buckets, the user can still read the public buckets in the same account the user resides in. This is expected behavior with the AWS API.

The rest of the exploit works the same. We only need to list the private bucket instead of the public bucket. This will simulate an attacker enumerating from a different AWS account.

![[OffSec/Cloud/Cloud Attacks - Reconnaissance Skill Path/z. images/d3bc2bc9acbff9b848beea380746fc89_MD5.jpg]]

Figure 9: Getting AccountID from a Public S3 Bucket or Object. Lab Modification

Because the new _enum_ user has no policies yet, it will _Deny ALL actions_ by default. This means that if we try to list the content of the bucket again with this user, we'll receive an _AccessDenied_ error.

```
kali@kali:~$ aws --profile enum s3 ls offseclab-assets-private-kaykoour

An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied  
```

> Listing 27 - Listing the Private Bucket with the enum User

Now, let's write a policy that will allow for listing the content of the bucket and reading objects inside it.

We'll name the policy document **policy-s3-read.json**.

```
# policy-s3-read.json
{
     "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowResourceAccount",
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:GetObject"
            ],
            "Resource": "*",
            "Condition": {
                "StringLike": {"s3:ResourceAccount": ["0*"]}
            }
        }
    ]
}
```

> Listing 28 - Policy to Allow Listing Buckets and Reading Objects

We can use our favorite text editor to write the policy. In the example below, we use **nano**. After copying and pasting the content of the policy, we'll display it again and analyze it.

```
kali@kali:~$ nano policy-s3-read.json

kali@kali:~$ cat -n policy-s3-read.json 
     1  {
     2      "Version": "2012-10-17",
     3      "Statement": [
     4          {
     5              "Sid": "AllowResourceAccount",
     6              "Effect": "Allow",
     7              "Action": [
     8                  "s3:ListBucket",
     9                  "s3:GetObject"
    10              ],
    11              "Resource": "*",
    12              "Condition": {
    13                  "StringLike": {"s3:ResourceAccount": ["0*"]}
    14              }
    15          }
    16      ]
    17  }

```

> Listing 29 - Creating the policy document file

The policy allows (line 6) to _list buckets_ (line 8) and _read any object_ in the buckets (line 9). There is a _*_ wildcard in the _Resource_ attribute (line 11) meaning that the actions are allowed for any bucket and object in any account. On lines 12-14, we add a condition to make this policy valid only if the account ID hosting the resource (_ResourceAccount_) starts with "0" following "any other digits" (using the wildcard for this).

We'll associate this policy with the _enum_ IAM user with an inline policy using the **iam put-user-policy** command.

Using the **--user-name enum** argument, we can specify the name of the IAM user.

The **--policy-name** argument lets us set a name for the policy. This is just for reference. We'll name the policy _s3-read_.

The **--policy-document** argument expects a string with the policy in JSON format. The prefix **file://** instructs the tool to read the policy from **policy-s3-read.json**.

The command will not return output if the policy was successfully applied. However, we can verify it using the **iam list-user-policies --user-name enum** command.

```
kali@kali:~$ aws --profile attacker iam put-user-policy \
--user-name enum \
--policy-name s3-read \
--policy-document file://policy-s3-read.json

kali@kali:~$ aws --profile attacker iam list-user-policies --user-name enum
{
    "PolicyNames": [
        "s3-read"
    ]
}
```

> Listing 30 - Attaching the s3-read Inline Policy to the enum IAM User

According to the policy we set, the user will be able to read the content of the bucket only if the account ID where the bucket resides starts with "0". In our lab, our account is "123456789012". It doesn't start with "0", so we'll get an _AccessDenied_ error when trying to list the bucket.

If we change the policy in the file and apply it again to the _enum_ user, we'll be able to list the bucket. This time it works because our account starts with the digit "1".

Policies take a few seconds to be active after they are applied, so we might need to wait 10-15 seconds each time we test.

We can run **aws --profile attacker sts get-caller-identity** to retrieve the account ID of our lab. This will help us validate our technique.

```
kali@kali:~$ aws --profile enum s3 ls offseclab-assets-private-kaykoour

An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied  

kali@kali:~$ nano policy-s3-read.json

kali@kali:~$ cat -n policy-s3-read.json 
     1  {
     2      "Version": "2012-10-17",
     3      "Statement": [
     4          {
     5              "Sid": "AllowResourceAccount",
     6              "Effect": "Allow",
     7              "Action": [
     8                  "s3:ListBucket",
     9                  "s3:GetObject"
    10              ],
    11              "Resource": "*",
    12              "Condition": {
    13                  "StringLike": {"s3:ResourceAccount": ["1*"]}
    14              }
    15          }
    16      ]
    17  }

kali@kali:~$ aws --profile attacker iam put-user-policy \
--user-name enum \
--policy-name s3-read \
--policy-document file://policy-s3-read.json

kali@kali:~$ aws --profile enum s3 ls offseclab-assets-private-kaykoour
                           PRE sites/
```

> Listing 31 - Changing the Condition in the Policy and Testing Again

Once we know that the policy starts with a digit, we can move to the next one by modifying the condition of the policy like so:

```
- __"StringLike": {"s3:ResourceAccount": ["10*"]}__
- __"StringLike": {"s3:ResourceAccount": ["11*"]}__
...
- __"StringLike": {"s3:ResourceAccount": ["18*"]}__
- __"StringLike": {"s3:ResourceAccount": ["19*"]}__
```

> Listing 32 - Modifying the Policy Condition Statement to Brute Force the AccountID

We can automate this process programmatically and build an application to obtain the account ID from a publicly-accessible bucket or object.

Tools such as [_s3-account-search_](https://github.com/WeAreCloudar/s3-account-search) also implement this technique, although this one uses _roles_ instead of _users_ to link the policy to the condition.

As we can observe, there are several ways to implement this. The key concept is leveraging the "Condition" feature of the IAM policies to control the _cross-account_ access. We used S3 because it's more common to find publicly-readable S3 objects than other resources, but theoretically, we can use this technique with other services as well.

## 1.3.4. Enumerating IAM Users in Other Accounts

In the previous section, we examined a case where the API was misused to obtain the account ID of a target. In this section, we will continue to build upon the previous lab. We'll learn about another example of API abuse that enumerates _internal IAM identities_ when we know the AWS account ID of the target.

Previously, we leveraged resources that had either publicly accessible permissions or, at the very least, permissions that granted _read_ access to the _attacker's_ account. We need to be aware of the latter because an important concept in this case is that sometimes we want a cloud resource to be publicly available on the internet, but at other times, we may want a resource to be accessible only to specific accounts. In AWS, this is referred to as [**cross-account access**](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic-cross-account.html).

To configure cross-account access through IAM policies, we can specify both the account that will be granted access and the IAM identity (_User_, _Group_, or _Role_) within that account. If the identity does not exist, it will throw an _error_ when trying to apply that policy.

To grant access to an identity in a different account, we need to create a policy and configure the _Principal_ attribute, which will contain the IAM identity in a specific account. AWS will validate the existence of the identity and will return an _error_ if it doesn't exist.

Typically, we use the _AWS Resource Name_ (ARN) to specify an IAM identity, as shown below:

```
"Principal": {
  "AWS": ["arn:aws:iam::AccountID:user/user-name"]
}
```

> Listing 33 - Example of a Principal Definition Inside a policy

The identity's ARN follows a standard format. We can craft it by modifying the Account's ID and the IAM user's username. So, for example, if the attacker wants to test if the _cloudadmin_ user exists in the account 123456789012, then the _Principal_ definition of the policy should be:

```
"Principal": {
  "AWS": ["arn:aws:iam::123456789012:user/cloudadmin"]
}
```

> Listing 34 - Example of a Principal Definition Specifying the ARN of an IAM user

The attacker can then apply/attach this policy to a resource and if it fails, it means that the user doesn't exist.

Let's observe how this works in our lab.

In the previous section, we already retrieved the account ID of the target's AWS account. The account will change after restarting the lab. We can either repeat the technique or we can get the account in the info box after starting the lab.

First, let's create an S3 bucket inside our _attacker_'s account. The command **aws s3 mb s3://offseclab-dummy-bucket-$RANDOM-$RANDOM-$RANDOM** will create a bucket with the name _offseclab-dummy-bucket_, followed by random integer values to ensure that the bucket name is unique.

```
kali@kali:~$ aws --profile attacker s3 mb s3://offseclab-dummy-bucket-$RANDOM-$RANDOM-$RANDOM
make_bucket: offseclab-dummy-bucket-28967-25641-13328
```

> Listing 35 - Creating a S3 Bucket in the attacker's Account

By default, the newly-created bucket is _private_. Now we are going to define a policy document in which we'll grant _read_ permission only to a specific IAM user in the target account. We can use any text editor of our preference to write the policy. We'll use the ARN we crafted earlier to test if the _cloudadmin_ user exists in the account 123456789012.

```
kali@kali:~$ nano grant-s3-bucket-read.json

kali@kali:~$ cat grant-s3-bucket-read.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowUserToListBucket",
            "Effect": "Allow",
            "Resource": "arn:aws:s3:::offseclab-dummy-bucket-28967-25641-13328",
            "Principal": {
                "AWS": ["arn:aws:iam::123456789012:user/cloudadmin"]
            },
            "Action": "s3:ListBucket"

        }
    ]
}
```

> Listing 36 - Policy Granting Permission to List the Bucket to a Single IAM User

Now that we have our policy document, we are ready to attach it to the bucket using the **aws s3api put-bucket-policy** command.

The **--bucket** flag specifies the name of the S3 bucket to which the policy should be applied. In this case, the name of the bucket is _offseclab-dummy-bucket-28967-25641-13328_.

The **--policy file://grant-s3-bucket-read2.json** argument specifies the policy that will be attached. Because our policy is defined in **grant-s3-bucket-read2.json**, we must use the prefix **file://** to instruct AWS CLI to read the policy from that file.

If no error returns after running the command, our policy was applied successfully. This also means that the _cloudadmin_ user exists in the target account.

```
kali@kali:~$ aws --profile attacker s3api put-bucket-policy --bucket offseclab-dummy-bucket-28967-25641-13328 --policy file://grant-s3-bucket-read.json 

kali@kali:~$ 
```

> Listing 37 - Attaching the Resource Based Policy to the Test Bucket

Next, let's copy the policy to create a new one - but this time, we'll grant privileges to a _nonexistent principal_.

```
kali@kali:~$ cp grant-s3-bucket-read.json grant-s3-bucket-read-userDoNotExist.json

kali@kali:~$ nano grant-s3-bucket-read-userDoNotExist.json

kali@kali:~$ cat grant-s3-bucket-read-userDoNotExist.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowUserToListBucket",
            "Effect": "Allow",
            "Resource": "arn:aws:s3:::offseclab-dummy-bucket-28967-25641-13328",
            "Principal": {
                "AWS": ["arn:aws:iam::123456789012:user/nonexistant"]
            },
            "Action": "s3:ListBucket"

        }
    ]
}

kali@kali:~$ aws --profile attacker s3api put-bucket-policy --bucket offseclab-dummy-bucket-28967-25641-13328  --policy file://grant-s3-bucket-read-userDoNotExist.json 

An error occurred (MalformedPolicy) when calling the PutBucketPolicy operation: Invalid principal in policy
```

> Listing 38 - Editing the Policy Specifying a Non-existing User and Testing Again

When we tried to attach a _resource-based_ policy to a bucket granting permissions to a _Principal_ that does not exist, it returns an error message stating _'Invalid principal in policy'_. The error message may mislead one to think that there is something wrong with the definition of the principal in the policy, but this actually occurs because the API couldn't internally validate the existence of the principal.

We can automate this process to obtain a valid enumeration technique that will indicate whether a _Principal_ exists. In our example, we checked the existence of an IAM user, but we can also define other principals such as _groups_ and _roles_.

The concept of abusing the API to enumerate users in another account can be applied using _roles_ and the _AssumeRole_ action. When we create a role, we need to set a trust policy that specifies the principals that will have permission to assume that role. Similarly, as it happened with the resource-based policy of the S3 bucket, an error will occur if the _Principal_ does not exist.

Let's suppose we have a large list of potential role names we want to test by brute forcing this enumeration technique. For this lab, we'll limit our list to a few options. This approach not only saves time, but also considers that our demonstration is conducted against an authentic service provider. Let's create a list of 10 potential role names we want to try. Typically, we'd attempt to find roles related to the target activities. We can even use AI tools to help build a more extensive list.

```
kali@kali:~$ echo -n "lab_admin
security_auditor
content_creator
student_access
lab_builder
instructor
network_config
monitoring_logging
backup_restore
content_editor" > /tmp/role-names.txt
```

> Listing 39 - Creating a List of Roles to Search in the Account

In this case, we'll use a popular tool named [_pacu_](https://www.kali.org/tools/pacu/) that can automate this technique of user and role enumeration. This tool is available in Kali's official repositories and can be installed by running the following commands:

```
kali@kali:~$ sudo apt update

kali@kali:~$ sudo apt install pacu
```

> Listing 40 - Installing pacu in Kali Linux Using the Package Manager

After installation completes, we'll be ready to use the tool. We can run **pacu -h** to display the usage help. This will also verify that the tool is successfully installed.

```
kali@kali:~$ pacu -h                                     
usage: pacu [-h] [--session] [--activate-session] [--new-session] [--set-keys] [--module-name] [--data] [--module-args]
            [--list-modules] [--pacu-help] [--module-info] [--exec] [--set-regions  [...]] [--whoami]

options:
  -h, --help            show this help message and exit
  --session             <session name>
  --activate-session    activate session, use session arg to set session name
  --new-session         <session name>
  --set-keys            alias, access id, secrect key, token
  --module-name         <module name>
  --data                <service name/all>
  --module-args         <--module-args='--regions us-east-1,us-east-1'>
  --list-modules        List arguments
  --pacu-help           List the Pacu help window
  --module-info         Get information on a specific module, use --module-name
  --exec                exec module
  --set-regions  [ ...]
                        <region1 region2 ...> or <all> for all
  --whoami              Display information on current IAM user
```

> Listing 41 - Getting the pacu Usage Help

Next, we'll run **pacu** without any other argument to start it in interactive mode. Pacu separates the assessment in _sessions_. The first time we run pacu, it will prompt for a name to create a session. Let's create a session and name it _offseclab_.

Once the session is created, it will display a list of available commands and, eventually, we'll get a new command prompt showing that we are in interactive mode within the _offseclab_ session.

```
kali@kali:~$ pacu

....
Database created at /root/.local/share/pacu/sqlite.db

What would you like to name this new session? offseclab
Session offseclab created.

...

Pacu (offseclab:No Keys Set) > 
```

> Listing 42 - Starting pacu in Interactive Mode

First, we'll notice the message _No Keys Set_ in the prompt. We can quickly set keys from the AWS CLI credentials file with the **import-keys** command. We can specify the profile configured in AWS CLI. Let's import the _attacker_ profile. We can also check that the command prompt changed, showing that now we have available keys.

```
Pacu (offseclab:No Keys Set) > import_keys attacker
  Imported keys as "imported-attacker"
Pacu (offseclab:imported-attacker) > 

```

> Listing 43 - Importing the attacker Profile Credentials in pacu

Pacu implements modules to conduct different types of assessments against AWS accounts. We can list all the available modules with the **ls** command.

Most of the modules require credentials in the target account. We'll browse through the list of modules and search for the _Recon_UNAUTH_ category. We are interested in the one that seems related to enumerating roles.

```
Pacu (offseclab:imported-attacker) > ls
...
[Category: RECON_UNAUTH]

  iam__enum_roles
  iam__enum_users

...
```

> Listing 44 - Listing Modules in pacu

To display information about the module, we need to add the **help** command following the name of the module. Let's learn more about the _iam__enum_roles_ module.

```
Pacu (offseclab:imported-attacker) > help iam__enum_roles

iam__enum_roles written by Spencer Gietzen of Rhino Security Labs.

usage: pacu [--word-list WORD_LIST] [--role-name ROLE_NAME] --account-id
            ACCOUNT_ID

This module takes in a valid AWS account ID and tries to enumerate existing
IAM roles within that account. It does so by trying to update the
AssumeRole policy document of the role that you pass into --role-name if
passed or newlycreated role. For your safety, it updates the policy with an
explicit deny against the AWS account/IAM role, so that no security holes
are opened in your account during enumeration. NOTE: It is recommended to
use personal AWS access keys for this script, as it will spam CloudTrail
with "iam:UpdateAssumeRolePolicy" logs and a few "sts:AssumeRole" logs. The
target account will not see anything in their logs though, unless you find
a misconfigured role that allows you to assume it. The keys used must have
the iam:UpdateAssumeRolePolicy permission on the role that you pass into
--role-name to be able to identify a valid IAM role and the sts:AssumeRole
permission to try and request credentials for any enumerated roles.
...
```

> Listing 45 - Displaying Information About iam__enum_roles Module in pacu

The output returned more information about the module, including usage instructions and details of the arguments that we can send.

The **--account-id** is a required flag that specifies the target's _AccountID_ where we'll enumerate the roles.

The **--word-list** flag let us specifies the wordlist of roles to try. We'll use the list that we already created in **/tmp/role-names.txt**.

This module requires an existing role in the _attacker_'s account. If we don't specify a role, the tool will create a temporary role (assuming that the credentials in the _attacker_ account have the permissions to run that action). We'll let the tool create a role for us, therefore we won't use the **--role-name** flag.

We can use a module with the **run** command, followed by the name of the module and any other argument that we need to pass.

```
Pacu (offseclab:imported-attacker) > run iam__enum_roles --word-list /tmp/role-names.txt --account-id 123456789012
  Running module iam__enum_roles...
...

[iam__enum_roles] Targeting account ID: 123456789012

[iam__enum_roles] Starting role enumeration...


[iam__enum_roles]   Found role: arn:aws:iam::123456789012:role/lab_admin

[iam__enum_roles] Found 1 role(s):

[iam__enum_roles]     arn:aws:iam::123456789012:role/lab_admin

[iam__enum_roles] Checking to see if any of these roles can be assumed for temporary credentials...

[iam__enum_roles]   Role can be assumed, but hit max session time limit, reverting to minimum of 1 hour...

[iam__enum_roles]   Successfully assumed role for 1 hour: arn:aws:iam::123456789012:role/lab_admin

[iam__enum_roles] {
  "Credentials": {
    "AccessKeyId": "ASIAQOMAIGYUWZXRMMO2",
    "SecretAccessKey": "2UU80dtizqx3DUa9mn6033AjXKb13GXOMCy+tOUt",
    "SessionToken": "FwoGZXIvYXdzEO///////////wEaDCv5...",
    "Expiration": "2023-08-18 22:07:49+00:00"
  },
  "AssumedRoleUser": {
    "AssumedRoleId": "AROAQOMAIGYUR5KMGWT7V:dCkQ0O1y6n9KSQmGBaKJ",
    "Arn": "arn:aws:sts::123456789012:assumed-role/lab_admin/dCkQ0O1y6n9KSQmGBaKJ"
  }
}
Cleaning up the PacuIamEnumRoles-XbsIV role.
```

> Listing 46 - Running the enum_roles Module in pacu

Excellent! The tool not only helped enumerate and discover a role, it also checked if the role had enough permissions for us to use it via _assumeRole_.

We are now in the state of an _"Initial Compromise"_ and the next step will be scoping what we can achieve with our new level of access.

These examples show how an attacker can leverage the API to obtain information beyond their intended purpose. Furthermore, since these interactions with the API occur within the _attacker_'s account, all related events are logged there, leaving no trace in the target's account.

#### Labs

1. Enumerate other roles by creating a new list with the keywords: "saphire", "ruby", and "amethyst" following a dash and one of the custom name roles we created before. For example:

```
ruby-lab_admin
ruby-security_auditor
ruby-content_creator
...
amethyst-backup_restore
amethyst-content_editor
```

Write the name of the role we can assume.

Answer

2. Assume the role you found in the previous exercise and list (_describe_) all available _VPCs_ using the role privileges. You will find the proof in a tag of one of the VPCs.

Answer

## 1.4. Wrapping Up

Reconnaissance is an important stage that let us gather information from the target. By interacting with publicly available services and resources, we learn about the service provider and cloud resources the target uses.

We also explored some examples in AWS about how to abuse the public CSP API to gather information about the target from an external account.

Using the information from reconnaissance we can identify potential weaknesses in the target's infrastructure and services. This analysis allows us to tailor our attack vectors and devise social engineering tactics aimed at infiltrating the target's systems more effectively and efficiently.